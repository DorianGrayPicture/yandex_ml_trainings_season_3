{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorianGrayPicture/yandex_ml_trainings_season_3/blob/main/hw01_classification/01_hw_mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT6AZ6-iKZY3"
      },
      "source": [
        "## Классификация MNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-NzUxhWNKZY7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTPY35Q6KZY-"
      },
      "source": [
        "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
        "\n",
        "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WpKxzQ_dKZY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "2ad9c498-1c2d-4ade-eeda-fd274787aaff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 342kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.19MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.21MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 8')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2654ZnFSKZY_"
      },
      "source": [
        "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
        "\n",
        "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
        "\n",
        "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Device for Training"
      ],
      "metadata": {
        "id": "YtcNCz7GMqJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX_2O9i3MpmE",
        "outputId": "125c0d78-c1a5-463b-b544-3588e92e5a76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a model"
      ],
      "metadata": {
        "id": "ltZQYnAmdhsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.fc_stack(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "EXbgVatsMRaX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UKG0w8dRKZZA"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model = Net().to(\"cpu\") # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCSE69pIKZZA"
      },
      "source": [
        "Ниже доступны локальные тесты для проверки вашей модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8CseLTyVKZZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0581d7f5-fe47-4e26-e9f0-79b7d1bf1ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkXTNh0YKZZC"
      },
      "source": [
        "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OxadUrhnKZZD",
        "collapsed": true,
        "outputId": "2f993bc6-3154-4b7e-c74f-0e6cc36bc424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1/100] Loss: 2.295640  [   32/60000]\n",
            "[Epoch: 1/100] Loss: 2.298311  [ 3232/60000]\n",
            "[Epoch: 1/100] Loss: 2.292135  [ 6432/60000]\n",
            "[Epoch: 1/100] Loss: 2.291490  [ 9632/60000]\n",
            "[Epoch: 1/100] Loss: 2.275540  [12832/60000]\n",
            "[Epoch: 1/100] Loss: 2.267735  [16032/60000]\n",
            "[Epoch: 1/100] Loss: 2.281090  [19232/60000]\n",
            "[Epoch: 1/100] Loss: 2.271599  [22432/60000]\n",
            "[Epoch: 1/100] Loss: 2.268077  [25632/60000]\n",
            "[Epoch: 1/100] Loss: 2.260222  [28832/60000]\n",
            "[Epoch: 1/100] Loss: 2.249169  [32032/60000]\n",
            "[Epoch: 1/100] Loss: 2.260745  [35232/60000]\n",
            "[Epoch: 1/100] Loss: 2.256165  [38432/60000]\n",
            "[Epoch: 1/100] Loss: 2.239237  [41632/60000]\n",
            "[Epoch: 1/100] Loss: 2.237786  [44832/60000]\n",
            "[Epoch: 1/100] Loss: 2.232569  [48032/60000]\n",
            "[Epoch: 1/100] Loss: 2.236360  [51232/60000]\n",
            "[Epoch: 1/100] Loss: 2.204077  [54432/60000]\n",
            "[Epoch: 1/100] Loss: 2.203706  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.0%, Avg loss: 2.198249 \n",
            "\n",
            "[Epoch: 2/100] Loss: 2.194691  [   32/60000]\n",
            "[Epoch: 2/100] Loss: 2.204371  [ 3232/60000]\n",
            "[Epoch: 2/100] Loss: 2.188920  [ 6432/60000]\n",
            "[Epoch: 2/100] Loss: 2.179820  [ 9632/60000]\n",
            "[Epoch: 2/100] Loss: 2.164298  [12832/60000]\n",
            "[Epoch: 2/100] Loss: 2.147878  [16032/60000]\n",
            "[Epoch: 2/100] Loss: 2.162221  [19232/60000]\n",
            "[Epoch: 2/100] Loss: 2.123653  [22432/60000]\n",
            "[Epoch: 2/100] Loss: 2.159104  [25632/60000]\n",
            "[Epoch: 2/100] Loss: 2.110061  [28832/60000]\n",
            "[Epoch: 2/100] Loss: 2.094535  [32032/60000]\n",
            "[Epoch: 2/100] Loss: 2.068283  [35232/60000]\n",
            "[Epoch: 2/100] Loss: 2.032075  [38432/60000]\n",
            "[Epoch: 2/100] Loss: 2.063166  [41632/60000]\n",
            "[Epoch: 2/100] Loss: 2.026118  [44832/60000]\n",
            "[Epoch: 2/100] Loss: 2.023802  [48032/60000]\n",
            "[Epoch: 2/100] Loss: 2.014440  [51232/60000]\n",
            "[Epoch: 2/100] Loss: 2.038340  [54432/60000]\n",
            "[Epoch: 2/100] Loss: 1.990979  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 1.922332 \n",
            "\n",
            "[Epoch: 3/100] Loss: 2.028604  [   32/60000]\n",
            "[Epoch: 3/100] Loss: 1.931242  [ 3232/60000]\n",
            "[Epoch: 3/100] Loss: 1.826972  [ 6432/60000]\n",
            "[Epoch: 3/100] Loss: 1.774851  [ 9632/60000]\n",
            "[Epoch: 3/100] Loss: 1.891300  [12832/60000]\n",
            "[Epoch: 3/100] Loss: 1.877709  [16032/60000]\n",
            "[Epoch: 3/100] Loss: 1.753178  [19232/60000]\n",
            "[Epoch: 3/100] Loss: 1.771307  [22432/60000]\n",
            "[Epoch: 3/100] Loss: 1.755924  [25632/60000]\n",
            "[Epoch: 3/100] Loss: 1.760032  [28832/60000]\n",
            "[Epoch: 3/100] Loss: 1.732815  [32032/60000]\n",
            "[Epoch: 3/100] Loss: 1.592641  [35232/60000]\n",
            "[Epoch: 3/100] Loss: 1.530020  [38432/60000]\n",
            "[Epoch: 3/100] Loss: 1.466268  [41632/60000]\n",
            "[Epoch: 3/100] Loss: 1.495962  [44832/60000]\n",
            "[Epoch: 3/100] Loss: 1.534419  [48032/60000]\n",
            "[Epoch: 3/100] Loss: 1.450787  [51232/60000]\n",
            "[Epoch: 3/100] Loss: 1.418704  [54432/60000]\n",
            "[Epoch: 3/100] Loss: 1.302653  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.1%, Avg loss: 1.325836 \n",
            "\n",
            "[Epoch: 4/100] Loss: 1.513199  [   32/60000]\n",
            "[Epoch: 4/100] Loss: 1.202205  [ 3232/60000]\n",
            "[Epoch: 4/100] Loss: 1.315561  [ 6432/60000]\n",
            "[Epoch: 4/100] Loss: 1.153424  [ 9632/60000]\n",
            "[Epoch: 4/100] Loss: 1.235027  [12832/60000]\n",
            "[Epoch: 4/100] Loss: 1.240186  [16032/60000]\n",
            "[Epoch: 4/100] Loss: 1.133737  [19232/60000]\n",
            "[Epoch: 4/100] Loss: 1.088345  [22432/60000]\n",
            "[Epoch: 4/100] Loss: 0.947534  [25632/60000]\n",
            "[Epoch: 4/100] Loss: 1.031483  [28832/60000]\n",
            "[Epoch: 4/100] Loss: 1.013817  [32032/60000]\n",
            "[Epoch: 4/100] Loss: 1.038970  [35232/60000]\n",
            "[Epoch: 4/100] Loss: 0.969441  [38432/60000]\n",
            "[Epoch: 4/100] Loss: 1.166222  [41632/60000]\n",
            "[Epoch: 4/100] Loss: 0.944853  [44832/60000]\n",
            "[Epoch: 4/100] Loss: 0.775006  [48032/60000]\n",
            "[Epoch: 4/100] Loss: 0.929044  [51232/60000]\n",
            "[Epoch: 4/100] Loss: 0.870029  [54432/60000]\n",
            "[Epoch: 4/100] Loss: 0.865945  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.6%, Avg loss: 0.872379 \n",
            "\n",
            "[Epoch: 5/100] Loss: 0.674891  [   32/60000]\n",
            "[Epoch: 5/100] Loss: 1.064539  [ 3232/60000]\n",
            "[Epoch: 5/100] Loss: 0.956918  [ 6432/60000]\n",
            "[Epoch: 5/100] Loss: 0.975058  [ 9632/60000]\n",
            "[Epoch: 5/100] Loss: 0.736518  [12832/60000]\n",
            "[Epoch: 5/100] Loss: 0.813588  [16032/60000]\n",
            "[Epoch: 5/100] Loss: 0.776202  [19232/60000]\n",
            "[Epoch: 5/100] Loss: 0.823502  [22432/60000]\n",
            "[Epoch: 5/100] Loss: 0.789582  [25632/60000]\n",
            "[Epoch: 5/100] Loss: 0.887565  [28832/60000]\n",
            "[Epoch: 5/100] Loss: 0.727307  [32032/60000]\n",
            "[Epoch: 5/100] Loss: 0.735568  [35232/60000]\n",
            "[Epoch: 5/100] Loss: 0.766088  [38432/60000]\n",
            "[Epoch: 5/100] Loss: 0.756502  [41632/60000]\n",
            "[Epoch: 5/100] Loss: 0.670799  [44832/60000]\n",
            "[Epoch: 5/100] Loss: 0.851633  [48032/60000]\n",
            "[Epoch: 5/100] Loss: 0.906673  [51232/60000]\n",
            "[Epoch: 5/100] Loss: 0.887086  [54432/60000]\n",
            "[Epoch: 5/100] Loss: 0.739212  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.662801 \n",
            "\n",
            "[Epoch: 6/100] Loss: 0.669644  [   32/60000]\n",
            "[Epoch: 6/100] Loss: 0.477611  [ 3232/60000]\n",
            "[Epoch: 6/100] Loss: 0.667547  [ 6432/60000]\n",
            "[Epoch: 6/100] Loss: 0.799479  [ 9632/60000]\n",
            "[Epoch: 6/100] Loss: 0.667628  [12832/60000]\n",
            "[Epoch: 6/100] Loss: 0.544657  [16032/60000]\n",
            "[Epoch: 6/100] Loss: 0.379833  [19232/60000]\n",
            "[Epoch: 6/100] Loss: 0.655800  [22432/60000]\n",
            "[Epoch: 6/100] Loss: 0.521126  [25632/60000]\n",
            "[Epoch: 6/100] Loss: 0.484802  [28832/60000]\n",
            "[Epoch: 6/100] Loss: 0.772147  [32032/60000]\n",
            "[Epoch: 6/100] Loss: 0.534854  [35232/60000]\n",
            "[Epoch: 6/100] Loss: 0.457268  [38432/60000]\n",
            "[Epoch: 6/100] Loss: 0.573389  [41632/60000]\n",
            "[Epoch: 6/100] Loss: 0.483230  [44832/60000]\n",
            "[Epoch: 6/100] Loss: 0.645212  [48032/60000]\n",
            "[Epoch: 6/100] Loss: 0.746968  [51232/60000]\n",
            "[Epoch: 6/100] Loss: 0.560530  [54432/60000]\n",
            "[Epoch: 6/100] Loss: 0.586842  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.553284 \n",
            "\n",
            "[Epoch: 7/100] Loss: 0.516732  [   32/60000]\n",
            "[Epoch: 7/100] Loss: 0.520073  [ 3232/60000]\n",
            "[Epoch: 7/100] Loss: 0.593972  [ 6432/60000]\n",
            "[Epoch: 7/100] Loss: 0.600886  [ 9632/60000]\n",
            "[Epoch: 7/100] Loss: 0.441202  [12832/60000]\n",
            "[Epoch: 7/100] Loss: 0.430223  [16032/60000]\n",
            "[Epoch: 7/100] Loss: 0.324933  [19232/60000]\n",
            "[Epoch: 7/100] Loss: 0.529154  [22432/60000]\n",
            "[Epoch: 7/100] Loss: 0.455262  [25632/60000]\n",
            "[Epoch: 7/100] Loss: 0.605841  [28832/60000]\n",
            "[Epoch: 7/100] Loss: 0.527396  [32032/60000]\n",
            "[Epoch: 7/100] Loss: 0.506181  [35232/60000]\n",
            "[Epoch: 7/100] Loss: 0.553242  [38432/60000]\n",
            "[Epoch: 7/100] Loss: 0.640319  [41632/60000]\n",
            "[Epoch: 7/100] Loss: 0.526605  [44832/60000]\n",
            "[Epoch: 7/100] Loss: 0.728844  [48032/60000]\n",
            "[Epoch: 7/100] Loss: 0.512864  [51232/60000]\n",
            "[Epoch: 7/100] Loss: 0.411183  [54432/60000]\n",
            "[Epoch: 7/100] Loss: 0.277279  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.487361 \n",
            "\n",
            "[Epoch: 8/100] Loss: 0.543144  [   32/60000]\n",
            "[Epoch: 8/100] Loss: 0.578558  [ 3232/60000]\n",
            "[Epoch: 8/100] Loss: 0.399732  [ 6432/60000]\n",
            "[Epoch: 8/100] Loss: 0.550343  [ 9632/60000]\n",
            "[Epoch: 8/100] Loss: 0.336011  [12832/60000]\n",
            "[Epoch: 8/100] Loss: 0.462945  [16032/60000]\n",
            "[Epoch: 8/100] Loss: 0.463544  [19232/60000]\n",
            "[Epoch: 8/100] Loss: 0.393660  [22432/60000]\n",
            "[Epoch: 8/100] Loss: 0.313060  [25632/60000]\n",
            "[Epoch: 8/100] Loss: 0.457333  [28832/60000]\n",
            "[Epoch: 8/100] Loss: 0.349922  [32032/60000]\n",
            "[Epoch: 8/100] Loss: 0.568017  [35232/60000]\n",
            "[Epoch: 8/100] Loss: 0.390579  [38432/60000]\n",
            "[Epoch: 8/100] Loss: 0.651550  [41632/60000]\n",
            "[Epoch: 8/100] Loss: 0.697266  [44832/60000]\n",
            "[Epoch: 8/100] Loss: 0.368045  [48032/60000]\n",
            "[Epoch: 8/100] Loss: 0.335185  [51232/60000]\n",
            "[Epoch: 8/100] Loss: 0.876111  [54432/60000]\n",
            "[Epoch: 8/100] Loss: 0.456228  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.443321 \n",
            "\n",
            "[Epoch: 9/100] Loss: 0.521614  [   32/60000]\n",
            "[Epoch: 9/100] Loss: 0.432157  [ 3232/60000]\n",
            "[Epoch: 9/100] Loss: 0.305825  [ 6432/60000]\n",
            "[Epoch: 9/100] Loss: 0.402070  [ 9632/60000]\n",
            "[Epoch: 9/100] Loss: 0.543038  [12832/60000]\n",
            "[Epoch: 9/100] Loss: 0.413697  [16032/60000]\n",
            "[Epoch: 9/100] Loss: 0.712689  [19232/60000]\n",
            "[Epoch: 9/100] Loss: 0.605395  [22432/60000]\n",
            "[Epoch: 9/100] Loss: 0.642968  [25632/60000]\n",
            "[Epoch: 9/100] Loss: 0.267058  [28832/60000]\n",
            "[Epoch: 9/100] Loss: 0.500858  [32032/60000]\n",
            "[Epoch: 9/100] Loss: 0.366890  [35232/60000]\n",
            "[Epoch: 9/100] Loss: 0.458867  [38432/60000]\n",
            "[Epoch: 9/100] Loss: 0.462008  [41632/60000]\n",
            "[Epoch: 9/100] Loss: 0.361378  [44832/60000]\n",
            "[Epoch: 9/100] Loss: 0.402371  [48032/60000]\n",
            "[Epoch: 9/100] Loss: 0.521045  [51232/60000]\n",
            "[Epoch: 9/100] Loss: 0.367803  [54432/60000]\n",
            "[Epoch: 9/100] Loss: 0.322685  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.412395 \n",
            "\n",
            "[Epoch: 10/100] Loss: 0.430858  [   32/60000]\n",
            "[Epoch: 10/100] Loss: 0.555636  [ 3232/60000]\n",
            "[Epoch: 10/100] Loss: 0.608950  [ 6432/60000]\n",
            "[Epoch: 10/100] Loss: 0.222156  [ 9632/60000]\n",
            "[Epoch: 10/100] Loss: 0.359780  [12832/60000]\n",
            "[Epoch: 10/100] Loss: 0.308882  [16032/60000]\n",
            "[Epoch: 10/100] Loss: 0.287143  [19232/60000]\n",
            "[Epoch: 10/100] Loss: 0.177586  [22432/60000]\n",
            "[Epoch: 10/100] Loss: 0.307767  [25632/60000]\n",
            "[Epoch: 10/100] Loss: 0.648022  [28832/60000]\n",
            "[Epoch: 10/100] Loss: 0.294449  [32032/60000]\n",
            "[Epoch: 10/100] Loss: 0.532499  [35232/60000]\n",
            "[Epoch: 10/100] Loss: 0.423660  [38432/60000]\n",
            "[Epoch: 10/100] Loss: 0.441290  [41632/60000]\n",
            "[Epoch: 10/100] Loss: 0.332260  [44832/60000]\n",
            "[Epoch: 10/100] Loss: 0.285601  [48032/60000]\n",
            "[Epoch: 10/100] Loss: 0.373125  [51232/60000]\n",
            "[Epoch: 10/100] Loss: 0.323312  [54432/60000]\n",
            "[Epoch: 10/100] Loss: 0.316375  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.4%, Avg loss: 0.389521 \n",
            "\n",
            "[Epoch: 11/100] Loss: 0.288000  [   32/60000]\n",
            "[Epoch: 11/100] Loss: 0.239308  [ 3232/60000]\n",
            "[Epoch: 11/100] Loss: 0.677653  [ 6432/60000]\n",
            "[Epoch: 11/100] Loss: 0.248487  [ 9632/60000]\n",
            "[Epoch: 11/100] Loss: 0.308846  [12832/60000]\n",
            "[Epoch: 11/100] Loss: 0.398498  [16032/60000]\n",
            "[Epoch: 11/100] Loss: 0.953474  [19232/60000]\n",
            "[Epoch: 11/100] Loss: 0.259016  [22432/60000]\n",
            "[Epoch: 11/100] Loss: 0.410758  [25632/60000]\n",
            "[Epoch: 11/100] Loss: 0.468881  [28832/60000]\n",
            "[Epoch: 11/100] Loss: 0.475479  [32032/60000]\n",
            "[Epoch: 11/100] Loss: 0.267353  [35232/60000]\n",
            "[Epoch: 11/100] Loss: 0.169616  [38432/60000]\n",
            "[Epoch: 11/100] Loss: 0.256615  [41632/60000]\n",
            "[Epoch: 11/100] Loss: 0.436154  [44832/60000]\n",
            "[Epoch: 11/100] Loss: 0.380155  [48032/60000]\n",
            "[Epoch: 11/100] Loss: 0.423117  [51232/60000]\n",
            "[Epoch: 11/100] Loss: 0.435304  [54432/60000]\n",
            "[Epoch: 11/100] Loss: 0.235960  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.373295 \n",
            "\n",
            "[Epoch: 12/100] Loss: 0.425522  [   32/60000]\n",
            "[Epoch: 12/100] Loss: 0.196288  [ 3232/60000]\n",
            "[Epoch: 12/100] Loss: 0.377850  [ 6432/60000]\n",
            "[Epoch: 12/100] Loss: 0.676775  [ 9632/60000]\n",
            "[Epoch: 12/100] Loss: 0.527791  [12832/60000]\n",
            "[Epoch: 12/100] Loss: 0.243405  [16032/60000]\n",
            "[Epoch: 12/100] Loss: 0.190399  [19232/60000]\n",
            "[Epoch: 12/100] Loss: 0.341544  [22432/60000]\n",
            "[Epoch: 12/100] Loss: 0.159296  [25632/60000]\n",
            "[Epoch: 12/100] Loss: 0.514288  [28832/60000]\n",
            "[Epoch: 12/100] Loss: 0.314550  [32032/60000]\n",
            "[Epoch: 12/100] Loss: 0.389452  [35232/60000]\n",
            "[Epoch: 12/100] Loss: 0.452376  [38432/60000]\n",
            "[Epoch: 12/100] Loss: 0.325172  [41632/60000]\n",
            "[Epoch: 12/100] Loss: 0.291937  [44832/60000]\n",
            "[Epoch: 12/100] Loss: 0.425538  [48032/60000]\n",
            "[Epoch: 12/100] Loss: 0.249565  [51232/60000]\n",
            "[Epoch: 12/100] Loss: 0.555023  [54432/60000]\n",
            "[Epoch: 12/100] Loss: 0.365781  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.9%, Avg loss: 0.358711 \n",
            "\n",
            "[Epoch: 13/100] Loss: 0.481710  [   32/60000]\n",
            "[Epoch: 13/100] Loss: 0.348682  [ 3232/60000]\n",
            "[Epoch: 13/100] Loss: 0.386830  [ 6432/60000]\n",
            "[Epoch: 13/100] Loss: 0.262232  [ 9632/60000]\n",
            "[Epoch: 13/100] Loss: 0.443771  [12832/60000]\n",
            "[Epoch: 13/100] Loss: 0.302787  [16032/60000]\n",
            "[Epoch: 13/100] Loss: 0.263111  [19232/60000]\n",
            "[Epoch: 13/100] Loss: 0.571289  [22432/60000]\n",
            "[Epoch: 13/100] Loss: 0.551838  [25632/60000]\n",
            "[Epoch: 13/100] Loss: 0.224513  [28832/60000]\n",
            "[Epoch: 13/100] Loss: 0.556655  [32032/60000]\n",
            "[Epoch: 13/100] Loss: 0.321916  [35232/60000]\n",
            "[Epoch: 13/100] Loss: 0.321240  [38432/60000]\n",
            "[Epoch: 13/100] Loss: 0.249076  [41632/60000]\n",
            "[Epoch: 13/100] Loss: 0.377218  [44832/60000]\n",
            "[Epoch: 13/100] Loss: 0.314010  [48032/60000]\n",
            "[Epoch: 13/100] Loss: 0.246338  [51232/60000]\n",
            "[Epoch: 13/100] Loss: 0.392950  [54432/60000]\n",
            "[Epoch: 13/100] Loss: 0.490034  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.346917 \n",
            "\n",
            "[Epoch: 14/100] Loss: 0.258762  [   32/60000]\n",
            "[Epoch: 14/100] Loss: 0.293601  [ 3232/60000]\n",
            "[Epoch: 14/100] Loss: 0.383069  [ 6432/60000]\n",
            "[Epoch: 14/100] Loss: 0.231938  [ 9632/60000]\n",
            "[Epoch: 14/100] Loss: 0.508835  [12832/60000]\n",
            "[Epoch: 14/100] Loss: 0.210496  [16032/60000]\n",
            "[Epoch: 14/100] Loss: 0.292136  [19232/60000]\n",
            "[Epoch: 14/100] Loss: 0.285398  [22432/60000]\n",
            "[Epoch: 14/100] Loss: 0.319601  [25632/60000]\n",
            "[Epoch: 14/100] Loss: 0.531167  [28832/60000]\n",
            "[Epoch: 14/100] Loss: 0.312574  [32032/60000]\n",
            "[Epoch: 14/100] Loss: 0.283346  [35232/60000]\n",
            "[Epoch: 14/100] Loss: 0.634992  [38432/60000]\n",
            "[Epoch: 14/100] Loss: 0.357460  [41632/60000]\n",
            "[Epoch: 14/100] Loss: 0.242969  [44832/60000]\n",
            "[Epoch: 14/100] Loss: 0.173107  [48032/60000]\n",
            "[Epoch: 14/100] Loss: 0.541858  [51232/60000]\n",
            "[Epoch: 14/100] Loss: 0.377251  [54432/60000]\n",
            "[Epoch: 14/100] Loss: 0.391243  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.337856 \n",
            "\n",
            "[Epoch: 15/100] Loss: 0.451104  [   32/60000]\n",
            "[Epoch: 15/100] Loss: 0.419395  [ 3232/60000]\n",
            "[Epoch: 15/100] Loss: 0.291099  [ 6432/60000]\n",
            "[Epoch: 15/100] Loss: 0.219778  [ 9632/60000]\n",
            "[Epoch: 15/100] Loss: 0.256074  [12832/60000]\n",
            "[Epoch: 15/100] Loss: 0.643318  [16032/60000]\n",
            "[Epoch: 15/100] Loss: 0.514621  [19232/60000]\n",
            "[Epoch: 15/100] Loss: 0.368516  [22432/60000]\n",
            "[Epoch: 15/100] Loss: 0.207708  [25632/60000]\n",
            "[Epoch: 15/100] Loss: 0.393045  [28832/60000]\n",
            "[Epoch: 15/100] Loss: 0.769288  [32032/60000]\n",
            "[Epoch: 15/100] Loss: 0.251917  [35232/60000]\n",
            "[Epoch: 15/100] Loss: 0.329580  [38432/60000]\n",
            "[Epoch: 15/100] Loss: 0.210689  [41632/60000]\n",
            "[Epoch: 15/100] Loss: 0.272495  [44832/60000]\n",
            "[Epoch: 15/100] Loss: 0.452939  [48032/60000]\n",
            "[Epoch: 15/100] Loss: 0.380949  [51232/60000]\n",
            "[Epoch: 15/100] Loss: 0.379123  [54432/60000]\n",
            "[Epoch: 15/100] Loss: 0.298484  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.329234 \n",
            "\n",
            "[Epoch: 16/100] Loss: 0.629201  [   32/60000]\n",
            "[Epoch: 16/100] Loss: 0.186840  [ 3232/60000]\n",
            "[Epoch: 16/100] Loss: 0.406288  [ 6432/60000]\n",
            "[Epoch: 16/100] Loss: 0.187482  [ 9632/60000]\n",
            "[Epoch: 16/100] Loss: 0.308098  [12832/60000]\n",
            "[Epoch: 16/100] Loss: 0.435807  [16032/60000]\n",
            "[Epoch: 16/100] Loss: 0.460804  [19232/60000]\n",
            "[Epoch: 16/100] Loss: 0.447796  [22432/60000]\n",
            "[Epoch: 16/100] Loss: 0.410447  [25632/60000]\n",
            "[Epoch: 16/100] Loss: 0.416312  [28832/60000]\n",
            "[Epoch: 16/100] Loss: 0.211865  [32032/60000]\n",
            "[Epoch: 16/100] Loss: 0.682745  [35232/60000]\n",
            "[Epoch: 16/100] Loss: 0.409529  [38432/60000]\n",
            "[Epoch: 16/100] Loss: 0.226538  [41632/60000]\n",
            "[Epoch: 16/100] Loss: 0.239932  [44832/60000]\n",
            "[Epoch: 16/100] Loss: 0.335536  [48032/60000]\n",
            "[Epoch: 16/100] Loss: 0.368668  [51232/60000]\n",
            "[Epoch: 16/100] Loss: 0.208930  [54432/60000]\n",
            "[Epoch: 16/100] Loss: 0.473176  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.322934 \n",
            "\n",
            "[Epoch: 17/100] Loss: 0.298638  [   32/60000]\n",
            "[Epoch: 17/100] Loss: 0.155118  [ 3232/60000]\n",
            "[Epoch: 17/100] Loss: 0.253945  [ 6432/60000]\n",
            "[Epoch: 17/100] Loss: 0.271876  [ 9632/60000]\n",
            "[Epoch: 17/100] Loss: 0.547227  [12832/60000]\n",
            "[Epoch: 17/100] Loss: 0.155017  [16032/60000]\n",
            "[Epoch: 17/100] Loss: 0.296318  [19232/60000]\n",
            "[Epoch: 17/100] Loss: 0.517505  [22432/60000]\n",
            "[Epoch: 17/100] Loss: 0.218731  [25632/60000]\n",
            "[Epoch: 17/100] Loss: 0.479045  [28832/60000]\n",
            "[Epoch: 17/100] Loss: 0.853390  [32032/60000]\n",
            "[Epoch: 17/100] Loss: 0.439065  [35232/60000]\n",
            "[Epoch: 17/100] Loss: 0.208896  [38432/60000]\n",
            "[Epoch: 17/100] Loss: 0.056403  [41632/60000]\n",
            "[Epoch: 17/100] Loss: 0.237149  [44832/60000]\n",
            "[Epoch: 17/100] Loss: 0.376031  [48032/60000]\n",
            "[Epoch: 17/100] Loss: 0.136668  [51232/60000]\n",
            "[Epoch: 17/100] Loss: 0.476034  [54432/60000]\n",
            "[Epoch: 17/100] Loss: 0.184246  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.316080 \n",
            "\n",
            "[Epoch: 18/100] Loss: 0.283873  [   32/60000]\n",
            "[Epoch: 18/100] Loss: 0.275796  [ 3232/60000]\n",
            "[Epoch: 18/100] Loss: 0.398228  [ 6432/60000]\n",
            "[Epoch: 18/100] Loss: 0.480791  [ 9632/60000]\n",
            "[Epoch: 18/100] Loss: 0.260839  [12832/60000]\n",
            "[Epoch: 18/100] Loss: 0.289005  [16032/60000]\n",
            "[Epoch: 18/100] Loss: 0.656998  [19232/60000]\n",
            "[Epoch: 18/100] Loss: 0.439963  [22432/60000]\n",
            "[Epoch: 18/100] Loss: 0.241052  [25632/60000]\n",
            "[Epoch: 18/100] Loss: 0.443383  [28832/60000]\n",
            "[Epoch: 18/100] Loss: 0.592699  [32032/60000]\n",
            "[Epoch: 18/100] Loss: 0.452901  [35232/60000]\n",
            "[Epoch: 18/100] Loss: 0.172384  [38432/60000]\n",
            "[Epoch: 18/100] Loss: 0.168550  [41632/60000]\n",
            "[Epoch: 18/100] Loss: 0.225043  [44832/60000]\n",
            "[Epoch: 18/100] Loss: 0.352924  [48032/60000]\n",
            "[Epoch: 18/100] Loss: 0.251014  [51232/60000]\n",
            "[Epoch: 18/100] Loss: 0.335552  [54432/60000]\n",
            "[Epoch: 18/100] Loss: 0.124661  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.310079 \n",
            "\n",
            "[Epoch: 19/100] Loss: 0.466846  [   32/60000]\n",
            "[Epoch: 19/100] Loss: 0.263477  [ 3232/60000]\n",
            "[Epoch: 19/100] Loss: 0.294431  [ 6432/60000]\n",
            "[Epoch: 19/100] Loss: 0.300840  [ 9632/60000]\n",
            "[Epoch: 19/100] Loss: 0.173587  [12832/60000]\n",
            "[Epoch: 19/100] Loss: 0.146919  [16032/60000]\n",
            "[Epoch: 19/100] Loss: 0.139829  [19232/60000]\n",
            "[Epoch: 19/100] Loss: 0.185691  [22432/60000]\n",
            "[Epoch: 19/100] Loss: 0.213834  [25632/60000]\n",
            "[Epoch: 19/100] Loss: 0.198160  [28832/60000]\n",
            "[Epoch: 19/100] Loss: 0.207741  [32032/60000]\n",
            "[Epoch: 19/100] Loss: 0.146156  [35232/60000]\n",
            "[Epoch: 19/100] Loss: 0.552526  [38432/60000]\n",
            "[Epoch: 19/100] Loss: 0.605877  [41632/60000]\n",
            "[Epoch: 19/100] Loss: 0.225760  [44832/60000]\n",
            "[Epoch: 19/100] Loss: 0.367133  [48032/60000]\n",
            "[Epoch: 19/100] Loss: 0.211587  [51232/60000]\n",
            "[Epoch: 19/100] Loss: 0.193624  [54432/60000]\n",
            "[Epoch: 19/100] Loss: 0.348260  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.303969 \n",
            "\n",
            "[Epoch: 20/100] Loss: 0.443688  [   32/60000]\n",
            "[Epoch: 20/100] Loss: 0.270620  [ 3232/60000]\n",
            "[Epoch: 20/100] Loss: 0.443464  [ 6432/60000]\n",
            "[Epoch: 20/100] Loss: 0.359472  [ 9632/60000]\n",
            "[Epoch: 20/100] Loss: 0.481745  [12832/60000]\n",
            "[Epoch: 20/100] Loss: 0.343351  [16032/60000]\n",
            "[Epoch: 20/100] Loss: 0.352362  [19232/60000]\n",
            "[Epoch: 20/100] Loss: 0.310151  [22432/60000]\n",
            "[Epoch: 20/100] Loss: 0.427414  [25632/60000]\n",
            "[Epoch: 20/100] Loss: 0.567116  [28832/60000]\n",
            "[Epoch: 20/100] Loss: 0.241230  [32032/60000]\n",
            "[Epoch: 20/100] Loss: 0.349220  [35232/60000]\n",
            "[Epoch: 20/100] Loss: 0.202624  [38432/60000]\n",
            "[Epoch: 20/100] Loss: 0.110293  [41632/60000]\n",
            "[Epoch: 20/100] Loss: 0.369894  [44832/60000]\n",
            "[Epoch: 20/100] Loss: 0.371586  [48032/60000]\n",
            "[Epoch: 20/100] Loss: 0.191294  [51232/60000]\n",
            "[Epoch: 20/100] Loss: 0.521011  [54432/60000]\n",
            "[Epoch: 20/100] Loss: 0.263528  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.299763 \n",
            "\n",
            "[Epoch: 21/100] Loss: 0.251757  [   32/60000]\n",
            "[Epoch: 21/100] Loss: 0.422948  [ 3232/60000]\n",
            "[Epoch: 21/100] Loss: 0.219683  [ 6432/60000]\n",
            "[Epoch: 21/100] Loss: 0.268591  [ 9632/60000]\n",
            "[Epoch: 21/100] Loss: 0.300824  [12832/60000]\n",
            "[Epoch: 21/100] Loss: 0.153116  [16032/60000]\n",
            "[Epoch: 21/100] Loss: 0.126877  [19232/60000]\n",
            "[Epoch: 21/100] Loss: 0.135925  [22432/60000]\n",
            "[Epoch: 21/100] Loss: 0.147359  [25632/60000]\n",
            "[Epoch: 21/100] Loss: 0.216178  [28832/60000]\n",
            "[Epoch: 21/100] Loss: 0.386246  [32032/60000]\n",
            "[Epoch: 21/100] Loss: 0.270624  [35232/60000]\n",
            "[Epoch: 21/100] Loss: 0.093865  [38432/60000]\n",
            "[Epoch: 21/100] Loss: 0.383571  [41632/60000]\n",
            "[Epoch: 21/100] Loss: 0.313636  [44832/60000]\n",
            "[Epoch: 21/100] Loss: 0.182966  [48032/60000]\n",
            "[Epoch: 21/100] Loss: 0.187331  [51232/60000]\n",
            "[Epoch: 21/100] Loss: 0.325402  [54432/60000]\n",
            "[Epoch: 21/100] Loss: 0.185623  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.293892 \n",
            "\n",
            "[Epoch: 22/100] Loss: 0.175660  [   32/60000]\n",
            "[Epoch: 22/100] Loss: 0.246404  [ 3232/60000]\n",
            "[Epoch: 22/100] Loss: 0.347764  [ 6432/60000]\n",
            "[Epoch: 22/100] Loss: 0.232939  [ 9632/60000]\n",
            "[Epoch: 22/100] Loss: 0.270392  [12832/60000]\n",
            "[Epoch: 22/100] Loss: 0.217457  [16032/60000]\n",
            "[Epoch: 22/100] Loss: 0.435319  [19232/60000]\n",
            "[Epoch: 22/100] Loss: 0.112091  [22432/60000]\n",
            "[Epoch: 22/100] Loss: 0.348661  [25632/60000]\n",
            "[Epoch: 22/100] Loss: 0.439367  [28832/60000]\n",
            "[Epoch: 22/100] Loss: 0.624061  [32032/60000]\n",
            "[Epoch: 22/100] Loss: 0.133689  [35232/60000]\n",
            "[Epoch: 22/100] Loss: 0.533737  [38432/60000]\n",
            "[Epoch: 22/100] Loss: 0.169092  [41632/60000]\n",
            "[Epoch: 22/100] Loss: 0.550236  [44832/60000]\n",
            "[Epoch: 22/100] Loss: 0.379211  [48032/60000]\n",
            "[Epoch: 22/100] Loss: 0.294559  [51232/60000]\n",
            "[Epoch: 22/100] Loss: 0.206235  [54432/60000]\n",
            "[Epoch: 22/100] Loss: 0.239094  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.289289 \n",
            "\n",
            "[Epoch: 23/100] Loss: 0.284772  [   32/60000]\n",
            "[Epoch: 23/100] Loss: 0.116161  [ 3232/60000]\n",
            "[Epoch: 23/100] Loss: 0.091740  [ 6432/60000]\n",
            "[Epoch: 23/100] Loss: 0.233620  [ 9632/60000]\n",
            "[Epoch: 23/100] Loss: 0.245929  [12832/60000]\n",
            "[Epoch: 23/100] Loss: 0.373838  [16032/60000]\n",
            "[Epoch: 23/100] Loss: 0.203787  [19232/60000]\n",
            "[Epoch: 23/100] Loss: 0.064672  [22432/60000]\n",
            "[Epoch: 23/100] Loss: 0.391397  [25632/60000]\n",
            "[Epoch: 23/100] Loss: 0.191735  [28832/60000]\n",
            "[Epoch: 23/100] Loss: 0.112049  [32032/60000]\n",
            "[Epoch: 23/100] Loss: 0.448025  [35232/60000]\n",
            "[Epoch: 23/100] Loss: 0.103288  [38432/60000]\n",
            "[Epoch: 23/100] Loss: 0.105229  [41632/60000]\n",
            "[Epoch: 23/100] Loss: 0.420813  [44832/60000]\n",
            "[Epoch: 23/100] Loss: 0.152513  [48032/60000]\n",
            "[Epoch: 23/100] Loss: 0.286086  [51232/60000]\n",
            "[Epoch: 23/100] Loss: 0.388681  [54432/60000]\n",
            "[Epoch: 23/100] Loss: 0.172380  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.285058 \n",
            "\n",
            "[Epoch: 24/100] Loss: 0.307452  [   32/60000]\n",
            "[Epoch: 24/100] Loss: 0.145842  [ 3232/60000]\n",
            "[Epoch: 24/100] Loss: 0.209815  [ 6432/60000]\n",
            "[Epoch: 24/100] Loss: 0.876181  [ 9632/60000]\n",
            "[Epoch: 24/100] Loss: 0.268186  [12832/60000]\n",
            "[Epoch: 24/100] Loss: 0.188672  [16032/60000]\n",
            "[Epoch: 24/100] Loss: 0.310179  [19232/60000]\n",
            "[Epoch: 24/100] Loss: 0.414516  [22432/60000]\n",
            "[Epoch: 24/100] Loss: 0.517936  [25632/60000]\n",
            "[Epoch: 24/100] Loss: 0.133506  [28832/60000]\n",
            "[Epoch: 24/100] Loss: 0.431821  [32032/60000]\n",
            "[Epoch: 24/100] Loss: 0.213749  [35232/60000]\n",
            "[Epoch: 24/100] Loss: 0.477474  [38432/60000]\n",
            "[Epoch: 24/100] Loss: 0.231570  [41632/60000]\n",
            "[Epoch: 24/100] Loss: 0.316544  [44832/60000]\n",
            "[Epoch: 24/100] Loss: 0.317455  [48032/60000]\n",
            "[Epoch: 24/100] Loss: 0.153399  [51232/60000]\n",
            "[Epoch: 24/100] Loss: 0.148273  [54432/60000]\n",
            "[Epoch: 24/100] Loss: 0.551715  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.9%, Avg loss: 0.280984 \n",
            "\n",
            "[Epoch: 25/100] Loss: 0.135778  [   32/60000]\n",
            "[Epoch: 25/100] Loss: 0.408598  [ 3232/60000]\n",
            "[Epoch: 25/100] Loss: 0.210031  [ 6432/60000]\n",
            "[Epoch: 25/100] Loss: 0.620809  [ 9632/60000]\n",
            "[Epoch: 25/100] Loss: 0.254673  [12832/60000]\n",
            "[Epoch: 25/100] Loss: 0.473606  [16032/60000]\n",
            "[Epoch: 25/100] Loss: 0.273076  [19232/60000]\n",
            "[Epoch: 25/100] Loss: 0.375058  [22432/60000]\n",
            "[Epoch: 25/100] Loss: 0.171236  [25632/60000]\n",
            "[Epoch: 25/100] Loss: 0.196723  [28832/60000]\n",
            "[Epoch: 25/100] Loss: 0.148427  [32032/60000]\n",
            "[Epoch: 25/100] Loss: 0.448867  [35232/60000]\n",
            "[Epoch: 25/100] Loss: 0.147071  [38432/60000]\n",
            "[Epoch: 25/100] Loss: 0.244571  [41632/60000]\n",
            "[Epoch: 25/100] Loss: 0.337774  [44832/60000]\n",
            "[Epoch: 25/100] Loss: 0.479467  [48032/60000]\n",
            "[Epoch: 25/100] Loss: 0.224686  [51232/60000]\n",
            "[Epoch: 25/100] Loss: 0.535403  [54432/60000]\n",
            "[Epoch: 25/100] Loss: 0.224983  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.277051 \n",
            "\n",
            "[Epoch: 26/100] Loss: 0.196676  [   32/60000]\n",
            "[Epoch: 26/100] Loss: 0.316895  [ 3232/60000]\n",
            "[Epoch: 26/100] Loss: 0.227628  [ 6432/60000]\n",
            "[Epoch: 26/100] Loss: 0.139277  [ 9632/60000]\n",
            "[Epoch: 26/100] Loss: 0.312824  [12832/60000]\n",
            "[Epoch: 26/100] Loss: 0.378821  [16032/60000]\n",
            "[Epoch: 26/100] Loss: 0.367879  [19232/60000]\n",
            "[Epoch: 26/100] Loss: 0.097743  [22432/60000]\n",
            "[Epoch: 26/100] Loss: 0.139284  [25632/60000]\n",
            "[Epoch: 26/100] Loss: 0.275298  [28832/60000]\n",
            "[Epoch: 26/100] Loss: 0.164985  [32032/60000]\n",
            "[Epoch: 26/100] Loss: 0.379362  [35232/60000]\n",
            "[Epoch: 26/100] Loss: 0.232817  [38432/60000]\n",
            "[Epoch: 26/100] Loss: 0.307284  [41632/60000]\n",
            "[Epoch: 26/100] Loss: 0.132133  [44832/60000]\n",
            "[Epoch: 26/100] Loss: 0.133514  [48032/60000]\n",
            "[Epoch: 26/100] Loss: 0.501664  [51232/60000]\n",
            "[Epoch: 26/100] Loss: 0.084946  [54432/60000]\n",
            "[Epoch: 26/100] Loss: 0.199294  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.1%, Avg loss: 0.273444 \n",
            "\n",
            "[Epoch: 27/100] Loss: 0.159599  [   32/60000]\n",
            "[Epoch: 27/100] Loss: 0.441640  [ 3232/60000]\n",
            "[Epoch: 27/100] Loss: 0.237661  [ 6432/60000]\n",
            "[Epoch: 27/100] Loss: 0.221418  [ 9632/60000]\n",
            "[Epoch: 27/100] Loss: 0.329572  [12832/60000]\n",
            "[Epoch: 27/100] Loss: 0.168366  [16032/60000]\n",
            "[Epoch: 27/100] Loss: 0.244252  [19232/60000]\n",
            "[Epoch: 27/100] Loss: 0.701893  [22432/60000]\n",
            "[Epoch: 27/100] Loss: 0.226247  [25632/60000]\n",
            "[Epoch: 27/100] Loss: 0.345846  [28832/60000]\n",
            "[Epoch: 27/100] Loss: 0.388198  [32032/60000]\n",
            "[Epoch: 27/100] Loss: 0.337235  [35232/60000]\n",
            "[Epoch: 27/100] Loss: 0.126522  [38432/60000]\n",
            "[Epoch: 27/100] Loss: 0.219672  [41632/60000]\n",
            "[Epoch: 27/100] Loss: 0.188981  [44832/60000]\n",
            "[Epoch: 27/100] Loss: 0.213211  [48032/60000]\n",
            "[Epoch: 27/100] Loss: 0.309667  [51232/60000]\n",
            "[Epoch: 27/100] Loss: 0.288576  [54432/60000]\n",
            "[Epoch: 27/100] Loss: 0.330427  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.270001 \n",
            "\n",
            "[Epoch: 28/100] Loss: 0.233749  [   32/60000]\n",
            "[Epoch: 28/100] Loss: 0.214357  [ 3232/60000]\n",
            "[Epoch: 28/100] Loss: 0.216868  [ 6432/60000]\n",
            "[Epoch: 28/100] Loss: 0.393105  [ 9632/60000]\n",
            "[Epoch: 28/100] Loss: 0.083322  [12832/60000]\n",
            "[Epoch: 28/100] Loss: 0.178907  [16032/60000]\n",
            "[Epoch: 28/100] Loss: 0.295419  [19232/60000]\n",
            "[Epoch: 28/100] Loss: 0.109220  [22432/60000]\n",
            "[Epoch: 28/100] Loss: 0.439100  [25632/60000]\n",
            "[Epoch: 28/100] Loss: 0.430570  [28832/60000]\n",
            "[Epoch: 28/100] Loss: 0.155765  [32032/60000]\n",
            "[Epoch: 28/100] Loss: 0.307483  [35232/60000]\n",
            "[Epoch: 28/100] Loss: 0.084108  [38432/60000]\n",
            "[Epoch: 28/100] Loss: 0.174336  [41632/60000]\n",
            "[Epoch: 28/100] Loss: 0.099813  [44832/60000]\n",
            "[Epoch: 28/100] Loss: 0.165291  [48032/60000]\n",
            "[Epoch: 28/100] Loss: 0.151847  [51232/60000]\n",
            "[Epoch: 28/100] Loss: 0.402011  [54432/60000]\n",
            "[Epoch: 28/100] Loss: 0.283366  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.266280 \n",
            "\n",
            "[Epoch: 29/100] Loss: 0.228846  [   32/60000]\n",
            "[Epoch: 29/100] Loss: 0.217990  [ 3232/60000]\n",
            "[Epoch: 29/100] Loss: 0.342293  [ 6432/60000]\n",
            "[Epoch: 29/100] Loss: 0.214608  [ 9632/60000]\n",
            "[Epoch: 29/100] Loss: 0.223372  [12832/60000]\n",
            "[Epoch: 29/100] Loss: 0.106036  [16032/60000]\n",
            "[Epoch: 29/100] Loss: 0.262419  [19232/60000]\n",
            "[Epoch: 29/100] Loss: 0.399158  [22432/60000]\n",
            "[Epoch: 29/100] Loss: 0.391347  [25632/60000]\n",
            "[Epoch: 29/100] Loss: 0.430889  [28832/60000]\n",
            "[Epoch: 29/100] Loss: 0.464021  [32032/60000]\n",
            "[Epoch: 29/100] Loss: 0.275776  [35232/60000]\n",
            "[Epoch: 29/100] Loss: 0.190004  [38432/60000]\n",
            "[Epoch: 29/100] Loss: 0.249242  [41632/60000]\n",
            "[Epoch: 29/100] Loss: 0.379986  [44832/60000]\n",
            "[Epoch: 29/100] Loss: 0.271830  [48032/60000]\n",
            "[Epoch: 29/100] Loss: 0.311302  [51232/60000]\n",
            "[Epoch: 29/100] Loss: 0.486076  [54432/60000]\n",
            "[Epoch: 29/100] Loss: 0.316723  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.263783 \n",
            "\n",
            "[Epoch: 30/100] Loss: 0.234586  [   32/60000]\n",
            "[Epoch: 30/100] Loss: 0.207548  [ 3232/60000]\n",
            "[Epoch: 30/100] Loss: 0.112559  [ 6432/60000]\n",
            "[Epoch: 30/100] Loss: 0.316479  [ 9632/60000]\n",
            "[Epoch: 30/100] Loss: 0.282140  [12832/60000]\n",
            "[Epoch: 30/100] Loss: 0.318953  [16032/60000]\n",
            "[Epoch: 30/100] Loss: 0.224789  [19232/60000]\n",
            "[Epoch: 30/100] Loss: 0.136910  [22432/60000]\n",
            "[Epoch: 30/100] Loss: 0.083991  [25632/60000]\n",
            "[Epoch: 30/100] Loss: 0.419232  [28832/60000]\n",
            "[Epoch: 30/100] Loss: 0.160818  [32032/60000]\n",
            "[Epoch: 30/100] Loss: 0.120862  [35232/60000]\n",
            "[Epoch: 30/100] Loss: 0.294911  [38432/60000]\n",
            "[Epoch: 30/100] Loss: 0.074301  [41632/60000]\n",
            "[Epoch: 30/100] Loss: 0.391685  [44832/60000]\n",
            "[Epoch: 30/100] Loss: 0.216302  [48032/60000]\n",
            "[Epoch: 30/100] Loss: 0.306920  [51232/60000]\n",
            "[Epoch: 30/100] Loss: 0.240063  [54432/60000]\n",
            "[Epoch: 30/100] Loss: 0.270352  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.259523 \n",
            "\n",
            "[Epoch: 31/100] Loss: 0.328217  [   32/60000]\n",
            "[Epoch: 31/100] Loss: 0.602306  [ 3232/60000]\n",
            "[Epoch: 31/100] Loss: 0.320098  [ 6432/60000]\n",
            "[Epoch: 31/100] Loss: 0.638696  [ 9632/60000]\n",
            "[Epoch: 31/100] Loss: 0.181554  [12832/60000]\n",
            "[Epoch: 31/100] Loss: 0.314357  [16032/60000]\n",
            "[Epoch: 31/100] Loss: 0.102158  [19232/60000]\n",
            "[Epoch: 31/100] Loss: 0.438191  [22432/60000]\n",
            "[Epoch: 31/100] Loss: 0.253439  [25632/60000]\n",
            "[Epoch: 31/100] Loss: 0.159749  [28832/60000]\n",
            "[Epoch: 31/100] Loss: 0.243886  [32032/60000]\n",
            "[Epoch: 31/100] Loss: 0.121900  [35232/60000]\n",
            "[Epoch: 31/100] Loss: 0.428215  [38432/60000]\n",
            "[Epoch: 31/100] Loss: 0.182699  [41632/60000]\n",
            "[Epoch: 31/100] Loss: 0.181512  [44832/60000]\n",
            "[Epoch: 31/100] Loss: 0.140192  [48032/60000]\n",
            "[Epoch: 31/100] Loss: 0.513996  [51232/60000]\n",
            "[Epoch: 31/100] Loss: 0.166250  [54432/60000]\n",
            "[Epoch: 31/100] Loss: 0.169677  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.256783 \n",
            "\n",
            "[Epoch: 32/100] Loss: 0.344141  [   32/60000]\n",
            "[Epoch: 32/100] Loss: 0.200240  [ 3232/60000]\n",
            "[Epoch: 32/100] Loss: 0.451392  [ 6432/60000]\n",
            "[Epoch: 32/100] Loss: 0.565836  [ 9632/60000]\n",
            "[Epoch: 32/100] Loss: 0.250262  [12832/60000]\n",
            "[Epoch: 32/100] Loss: 0.472798  [16032/60000]\n",
            "[Epoch: 32/100] Loss: 0.313323  [19232/60000]\n",
            "[Epoch: 32/100] Loss: 0.062587  [22432/60000]\n",
            "[Epoch: 32/100] Loss: 0.111160  [25632/60000]\n",
            "[Epoch: 32/100] Loss: 0.152364  [28832/60000]\n",
            "[Epoch: 32/100] Loss: 0.166866  [32032/60000]\n",
            "[Epoch: 32/100] Loss: 0.187344  [35232/60000]\n",
            "[Epoch: 32/100] Loss: 0.181286  [38432/60000]\n",
            "[Epoch: 32/100] Loss: 0.130741  [41632/60000]\n",
            "[Epoch: 32/100] Loss: 0.186584  [44832/60000]\n",
            "[Epoch: 32/100] Loss: 0.166206  [48032/60000]\n",
            "[Epoch: 32/100] Loss: 0.166103  [51232/60000]\n",
            "[Epoch: 32/100] Loss: 0.092673  [54432/60000]\n",
            "[Epoch: 32/100] Loss: 0.498009  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.253324 \n",
            "\n",
            "[Epoch: 33/100] Loss: 0.202572  [   32/60000]\n",
            "[Epoch: 33/100] Loss: 0.425884  [ 3232/60000]\n",
            "[Epoch: 33/100] Loss: 0.075863  [ 6432/60000]\n",
            "[Epoch: 33/100] Loss: 0.226222  [ 9632/60000]\n",
            "[Epoch: 33/100] Loss: 0.275807  [12832/60000]\n",
            "[Epoch: 33/100] Loss: 0.145026  [16032/60000]\n",
            "[Epoch: 33/100] Loss: 0.529237  [19232/60000]\n",
            "[Epoch: 33/100] Loss: 0.387768  [22432/60000]\n",
            "[Epoch: 33/100] Loss: 0.211085  [25632/60000]\n",
            "[Epoch: 33/100] Loss: 0.438573  [28832/60000]\n",
            "[Epoch: 33/100] Loss: 0.217744  [32032/60000]\n",
            "[Epoch: 33/100] Loss: 0.210640  [35232/60000]\n",
            "[Epoch: 33/100] Loss: 0.499136  [38432/60000]\n",
            "[Epoch: 33/100] Loss: 0.479705  [41632/60000]\n",
            "[Epoch: 33/100] Loss: 0.122205  [44832/60000]\n",
            "[Epoch: 33/100] Loss: 0.535187  [48032/60000]\n",
            "[Epoch: 33/100] Loss: 0.317073  [51232/60000]\n",
            "[Epoch: 33/100] Loss: 0.361844  [54432/60000]\n",
            "[Epoch: 33/100] Loss: 0.648219  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.250391 \n",
            "\n",
            "[Epoch: 34/100] Loss: 0.127360  [   32/60000]\n",
            "[Epoch: 34/100] Loss: 0.184920  [ 3232/60000]\n",
            "[Epoch: 34/100] Loss: 0.293452  [ 6432/60000]\n",
            "[Epoch: 34/100] Loss: 0.295944  [ 9632/60000]\n",
            "[Epoch: 34/100] Loss: 0.104594  [12832/60000]\n",
            "[Epoch: 34/100] Loss: 0.542452  [16032/60000]\n",
            "[Epoch: 34/100] Loss: 0.408040  [19232/60000]\n",
            "[Epoch: 34/100] Loss: 0.277106  [22432/60000]\n",
            "[Epoch: 34/100] Loss: 0.173787  [25632/60000]\n",
            "[Epoch: 34/100] Loss: 0.250167  [28832/60000]\n",
            "[Epoch: 34/100] Loss: 0.178753  [32032/60000]\n",
            "[Epoch: 34/100] Loss: 0.114334  [35232/60000]\n",
            "[Epoch: 34/100] Loss: 0.168449  [38432/60000]\n",
            "[Epoch: 34/100] Loss: 0.090715  [41632/60000]\n",
            "[Epoch: 34/100] Loss: 0.141372  [44832/60000]\n",
            "[Epoch: 34/100] Loss: 0.141979  [48032/60000]\n",
            "[Epoch: 34/100] Loss: 0.749303  [51232/60000]\n",
            "[Epoch: 34/100] Loss: 0.399779  [54432/60000]\n",
            "[Epoch: 34/100] Loss: 0.093313  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.247579 \n",
            "\n",
            "[Epoch: 35/100] Loss: 0.203488  [   32/60000]\n",
            "[Epoch: 35/100] Loss: 0.304196  [ 3232/60000]\n",
            "[Epoch: 35/100] Loss: 0.235204  [ 6432/60000]\n",
            "[Epoch: 35/100] Loss: 0.128693  [ 9632/60000]\n",
            "[Epoch: 35/100] Loss: 0.466904  [12832/60000]\n",
            "[Epoch: 35/100] Loss: 0.389632  [16032/60000]\n",
            "[Epoch: 35/100] Loss: 0.203214  [19232/60000]\n",
            "[Epoch: 35/100] Loss: 0.171568  [22432/60000]\n",
            "[Epoch: 35/100] Loss: 0.217939  [25632/60000]\n",
            "[Epoch: 35/100] Loss: 0.427089  [28832/60000]\n",
            "[Epoch: 35/100] Loss: 0.502017  [32032/60000]\n",
            "[Epoch: 35/100] Loss: 0.061846  [35232/60000]\n",
            "[Epoch: 35/100] Loss: 0.038328  [38432/60000]\n",
            "[Epoch: 35/100] Loss: 0.560707  [41632/60000]\n",
            "[Epoch: 35/100] Loss: 0.133301  [44832/60000]\n",
            "[Epoch: 35/100] Loss: 0.363302  [48032/60000]\n",
            "[Epoch: 35/100] Loss: 0.289738  [51232/60000]\n",
            "[Epoch: 35/100] Loss: 0.476120  [54432/60000]\n",
            "[Epoch: 35/100] Loss: 0.251882  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.244706 \n",
            "\n",
            "[Epoch: 36/100] Loss: 0.226472  [   32/60000]\n",
            "[Epoch: 36/100] Loss: 0.314911  [ 3232/60000]\n",
            "[Epoch: 36/100] Loss: 0.096248  [ 6432/60000]\n",
            "[Epoch: 36/100] Loss: 0.200060  [ 9632/60000]\n",
            "[Epoch: 36/100] Loss: 0.448550  [12832/60000]\n",
            "[Epoch: 36/100] Loss: 0.120752  [16032/60000]\n",
            "[Epoch: 36/100] Loss: 0.396823  [19232/60000]\n",
            "[Epoch: 36/100] Loss: 0.224367  [22432/60000]\n",
            "[Epoch: 36/100] Loss: 0.742761  [25632/60000]\n",
            "[Epoch: 36/100] Loss: 0.094244  [28832/60000]\n",
            "[Epoch: 36/100] Loss: 0.059326  [32032/60000]\n",
            "[Epoch: 36/100] Loss: 0.645518  [35232/60000]\n",
            "[Epoch: 36/100] Loss: 0.206904  [38432/60000]\n",
            "[Epoch: 36/100] Loss: 0.247667  [41632/60000]\n",
            "[Epoch: 36/100] Loss: 0.251582  [44832/60000]\n",
            "[Epoch: 36/100] Loss: 0.114046  [48032/60000]\n",
            "[Epoch: 36/100] Loss: 0.351769  [51232/60000]\n",
            "[Epoch: 36/100] Loss: 0.224769  [54432/60000]\n",
            "[Epoch: 36/100] Loss: 0.257593  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.242519 \n",
            "\n",
            "[Epoch: 37/100] Loss: 0.267041  [   32/60000]\n",
            "[Epoch: 37/100] Loss: 0.292472  [ 3232/60000]\n",
            "[Epoch: 37/100] Loss: 0.208369  [ 6432/60000]\n",
            "[Epoch: 37/100] Loss: 0.264567  [ 9632/60000]\n",
            "[Epoch: 37/100] Loss: 0.204707  [12832/60000]\n",
            "[Epoch: 37/100] Loss: 0.287535  [16032/60000]\n",
            "[Epoch: 37/100] Loss: 0.205068  [19232/60000]\n",
            "[Epoch: 37/100] Loss: 0.230746  [22432/60000]\n",
            "[Epoch: 37/100] Loss: 0.193961  [25632/60000]\n",
            "[Epoch: 37/100] Loss: 0.362904  [28832/60000]\n",
            "[Epoch: 37/100] Loss: 0.172786  [32032/60000]\n",
            "[Epoch: 37/100] Loss: 0.197205  [35232/60000]\n",
            "[Epoch: 37/100] Loss: 0.156359  [38432/60000]\n",
            "[Epoch: 37/100] Loss: 0.317767  [41632/60000]\n",
            "[Epoch: 37/100] Loss: 0.173827  [44832/60000]\n",
            "[Epoch: 37/100] Loss: 0.603174  [48032/60000]\n",
            "[Epoch: 37/100] Loss: 0.206085  [51232/60000]\n",
            "[Epoch: 37/100] Loss: 0.162952  [54432/60000]\n",
            "[Epoch: 37/100] Loss: 0.083779  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.3%, Avg loss: 0.238215 \n",
            "\n",
            "[Epoch: 38/100] Loss: 0.098582  [   32/60000]\n",
            "[Epoch: 38/100] Loss: 0.205810  [ 3232/60000]\n",
            "[Epoch: 38/100] Loss: 0.147461  [ 6432/60000]\n",
            "[Epoch: 38/100] Loss: 0.195147  [ 9632/60000]\n",
            "[Epoch: 38/100] Loss: 0.559476  [12832/60000]\n",
            "[Epoch: 38/100] Loss: 0.208346  [16032/60000]\n",
            "[Epoch: 38/100] Loss: 0.194671  [19232/60000]\n",
            "[Epoch: 38/100] Loss: 0.169083  [22432/60000]\n",
            "[Epoch: 38/100] Loss: 0.342359  [25632/60000]\n",
            "[Epoch: 38/100] Loss: 0.237345  [28832/60000]\n",
            "[Epoch: 38/100] Loss: 0.291348  [32032/60000]\n",
            "[Epoch: 38/100] Loss: 0.210861  [35232/60000]\n",
            "[Epoch: 38/100] Loss: 0.300823  [38432/60000]\n",
            "[Epoch: 38/100] Loss: 0.243686  [41632/60000]\n",
            "[Epoch: 38/100] Loss: 0.069215  [44832/60000]\n",
            "[Epoch: 38/100] Loss: 0.231701  [48032/60000]\n",
            "[Epoch: 38/100] Loss: 0.426171  [51232/60000]\n",
            "[Epoch: 38/100] Loss: 0.099262  [54432/60000]\n",
            "[Epoch: 38/100] Loss: 0.139187  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.3%, Avg loss: 0.236432 \n",
            "\n",
            "[Epoch: 39/100] Loss: 0.244427  [   32/60000]\n",
            "[Epoch: 39/100] Loss: 0.107749  [ 3232/60000]\n",
            "[Epoch: 39/100] Loss: 0.232712  [ 6432/60000]\n",
            "[Epoch: 39/100] Loss: 0.279747  [ 9632/60000]\n",
            "[Epoch: 39/100] Loss: 0.355207  [12832/60000]\n",
            "[Epoch: 39/100] Loss: 0.071288  [16032/60000]\n",
            "[Epoch: 39/100] Loss: 0.238025  [19232/60000]\n",
            "[Epoch: 39/100] Loss: 0.285304  [22432/60000]\n",
            "[Epoch: 39/100] Loss: 0.489878  [25632/60000]\n",
            "[Epoch: 39/100] Loss: 0.210512  [28832/60000]\n",
            "[Epoch: 39/100] Loss: 0.167193  [32032/60000]\n",
            "[Epoch: 39/100] Loss: 0.328886  [35232/60000]\n",
            "[Epoch: 39/100] Loss: 0.144397  [38432/60000]\n",
            "[Epoch: 39/100] Loss: 0.191742  [41632/60000]\n",
            "[Epoch: 39/100] Loss: 0.454580  [44832/60000]\n",
            "[Epoch: 39/100] Loss: 0.179228  [48032/60000]\n",
            "[Epoch: 39/100] Loss: 0.297622  [51232/60000]\n",
            "[Epoch: 39/100] Loss: 0.238870  [54432/60000]\n",
            "[Epoch: 39/100] Loss: 0.334778  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.233119 \n",
            "\n",
            "[Epoch: 40/100] Loss: 0.319205  [   32/60000]\n",
            "[Epoch: 40/100] Loss: 0.461900  [ 3232/60000]\n",
            "[Epoch: 40/100] Loss: 0.258815  [ 6432/60000]\n",
            "[Epoch: 40/100] Loss: 0.204678  [ 9632/60000]\n",
            "[Epoch: 40/100] Loss: 0.363289  [12832/60000]\n",
            "[Epoch: 40/100] Loss: 0.112816  [16032/60000]\n",
            "[Epoch: 40/100] Loss: 0.413816  [19232/60000]\n",
            "[Epoch: 40/100] Loss: 0.283005  [22432/60000]\n",
            "[Epoch: 40/100] Loss: 0.211961  [25632/60000]\n",
            "[Epoch: 40/100] Loss: 0.262301  [28832/60000]\n",
            "[Epoch: 40/100] Loss: 0.266558  [32032/60000]\n",
            "[Epoch: 40/100] Loss: 0.127591  [35232/60000]\n",
            "[Epoch: 40/100] Loss: 0.321364  [38432/60000]\n",
            "[Epoch: 40/100] Loss: 0.115428  [41632/60000]\n",
            "[Epoch: 40/100] Loss: 0.153967  [44832/60000]\n",
            "[Epoch: 40/100] Loss: 0.202203  [48032/60000]\n",
            "[Epoch: 40/100] Loss: 0.403228  [51232/60000]\n",
            "[Epoch: 40/100] Loss: 0.501030  [54432/60000]\n",
            "[Epoch: 40/100] Loss: 0.243864  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.230675 \n",
            "\n",
            "[Epoch: 41/100] Loss: 0.108341  [   32/60000]\n",
            "[Epoch: 41/100] Loss: 0.330434  [ 3232/60000]\n",
            "[Epoch: 41/100] Loss: 0.371524  [ 6432/60000]\n",
            "[Epoch: 41/100] Loss: 0.387414  [ 9632/60000]\n",
            "[Epoch: 41/100] Loss: 0.274266  [12832/60000]\n",
            "[Epoch: 41/100] Loss: 0.176961  [16032/60000]\n",
            "[Epoch: 41/100] Loss: 0.308829  [19232/60000]\n",
            "[Epoch: 41/100] Loss: 0.057926  [22432/60000]\n",
            "[Epoch: 41/100] Loss: 0.319589  [25632/60000]\n",
            "[Epoch: 41/100] Loss: 0.323679  [28832/60000]\n",
            "[Epoch: 41/100] Loss: 0.284010  [32032/60000]\n",
            "[Epoch: 41/100] Loss: 0.289957  [35232/60000]\n",
            "[Epoch: 41/100] Loss: 0.396982  [38432/60000]\n",
            "[Epoch: 41/100] Loss: 0.337674  [41632/60000]\n",
            "[Epoch: 41/100] Loss: 0.092985  [44832/60000]\n",
            "[Epoch: 41/100] Loss: 0.080322  [48032/60000]\n",
            "[Epoch: 41/100] Loss: 0.155946  [51232/60000]\n",
            "[Epoch: 41/100] Loss: 0.127240  [54432/60000]\n",
            "[Epoch: 41/100] Loss: 0.407624  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.227545 \n",
            "\n",
            "[Epoch: 42/100] Loss: 0.499617  [   32/60000]\n",
            "[Epoch: 42/100] Loss: 0.123271  [ 3232/60000]\n",
            "[Epoch: 42/100] Loss: 0.308154  [ 6432/60000]\n",
            "[Epoch: 42/100] Loss: 0.066674  [ 9632/60000]\n",
            "[Epoch: 42/100] Loss: 0.390083  [12832/60000]\n",
            "[Epoch: 42/100] Loss: 0.141815  [16032/60000]\n",
            "[Epoch: 42/100] Loss: 0.099223  [19232/60000]\n",
            "[Epoch: 42/100] Loss: 0.289450  [22432/60000]\n",
            "[Epoch: 42/100] Loss: 0.309884  [25632/60000]\n",
            "[Epoch: 42/100] Loss: 0.407714  [28832/60000]\n",
            "[Epoch: 42/100] Loss: 0.395385  [32032/60000]\n",
            "[Epoch: 42/100] Loss: 0.205911  [35232/60000]\n",
            "[Epoch: 42/100] Loss: 0.204835  [38432/60000]\n",
            "[Epoch: 42/100] Loss: 0.381448  [41632/60000]\n",
            "[Epoch: 42/100] Loss: 0.065440  [44832/60000]\n",
            "[Epoch: 42/100] Loss: 0.114803  [48032/60000]\n",
            "[Epoch: 42/100] Loss: 0.299351  [51232/60000]\n",
            "[Epoch: 42/100] Loss: 0.202908  [54432/60000]\n",
            "[Epoch: 42/100] Loss: 0.237960  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.224991 \n",
            "\n",
            "[Epoch: 43/100] Loss: 0.117570  [   32/60000]\n",
            "[Epoch: 43/100] Loss: 0.270548  [ 3232/60000]\n",
            "[Epoch: 43/100] Loss: 0.282480  [ 6432/60000]\n",
            "[Epoch: 43/100] Loss: 0.142140  [ 9632/60000]\n",
            "[Epoch: 43/100] Loss: 0.263911  [12832/60000]\n",
            "[Epoch: 43/100] Loss: 0.174910  [16032/60000]\n",
            "[Epoch: 43/100] Loss: 0.177488  [19232/60000]\n",
            "[Epoch: 43/100] Loss: 0.571017  [22432/60000]\n",
            "[Epoch: 43/100] Loss: 0.492531  [25632/60000]\n",
            "[Epoch: 43/100] Loss: 0.148105  [28832/60000]\n",
            "[Epoch: 43/100] Loss: 0.203872  [32032/60000]\n",
            "[Epoch: 43/100] Loss: 0.575840  [35232/60000]\n",
            "[Epoch: 43/100] Loss: 0.334292  [38432/60000]\n",
            "[Epoch: 43/100] Loss: 0.154965  [41632/60000]\n",
            "[Epoch: 43/100] Loss: 0.310807  [44832/60000]\n",
            "[Epoch: 43/100] Loss: 0.195435  [48032/60000]\n",
            "[Epoch: 43/100] Loss: 0.108152  [51232/60000]\n",
            "[Epoch: 43/100] Loss: 0.104811  [54432/60000]\n",
            "[Epoch: 43/100] Loss: 0.259940  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.222624 \n",
            "\n",
            "[Epoch: 44/100] Loss: 0.163624  [   32/60000]\n",
            "[Epoch: 44/100] Loss: 0.237237  [ 3232/60000]\n",
            "[Epoch: 44/100] Loss: 0.069172  [ 6432/60000]\n",
            "[Epoch: 44/100] Loss: 0.247069  [ 9632/60000]\n",
            "[Epoch: 44/100] Loss: 0.162308  [12832/60000]\n",
            "[Epoch: 44/100] Loss: 0.129658  [16032/60000]\n",
            "[Epoch: 44/100] Loss: 0.271836  [19232/60000]\n",
            "[Epoch: 44/100] Loss: 0.160130  [22432/60000]\n",
            "[Epoch: 44/100] Loss: 0.069684  [25632/60000]\n",
            "[Epoch: 44/100] Loss: 0.059727  [28832/60000]\n",
            "[Epoch: 44/100] Loss: 0.194722  [32032/60000]\n",
            "[Epoch: 44/100] Loss: 0.376569  [35232/60000]\n",
            "[Epoch: 44/100] Loss: 0.183589  [38432/60000]\n",
            "[Epoch: 44/100] Loss: 0.297708  [41632/60000]\n",
            "[Epoch: 44/100] Loss: 0.194861  [44832/60000]\n",
            "[Epoch: 44/100] Loss: 0.410705  [48032/60000]\n",
            "[Epoch: 44/100] Loss: 0.211674  [51232/60000]\n",
            "[Epoch: 44/100] Loss: 0.145412  [54432/60000]\n",
            "[Epoch: 44/100] Loss: 0.324183  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.219898 \n",
            "\n",
            "[Epoch: 45/100] Loss: 0.236705  [   32/60000]\n",
            "[Epoch: 45/100] Loss: 0.042873  [ 3232/60000]\n",
            "[Epoch: 45/100] Loss: 0.249398  [ 6432/60000]\n",
            "[Epoch: 45/100] Loss: 0.366590  [ 9632/60000]\n",
            "[Epoch: 45/100] Loss: 0.323181  [12832/60000]\n",
            "[Epoch: 45/100] Loss: 0.158268  [16032/60000]\n",
            "[Epoch: 45/100] Loss: 0.367057  [19232/60000]\n",
            "[Epoch: 45/100] Loss: 0.227333  [22432/60000]\n",
            "[Epoch: 45/100] Loss: 0.042872  [25632/60000]\n",
            "[Epoch: 45/100] Loss: 0.071272  [28832/60000]\n",
            "[Epoch: 45/100] Loss: 0.394795  [32032/60000]\n",
            "[Epoch: 45/100] Loss: 0.228915  [35232/60000]\n",
            "[Epoch: 45/100] Loss: 0.169798  [38432/60000]\n",
            "[Epoch: 45/100] Loss: 0.141996  [41632/60000]\n",
            "[Epoch: 45/100] Loss: 0.129392  [44832/60000]\n",
            "[Epoch: 45/100] Loss: 0.195704  [48032/60000]\n",
            "[Epoch: 45/100] Loss: 0.246950  [51232/60000]\n",
            "[Epoch: 45/100] Loss: 0.135808  [54432/60000]\n",
            "[Epoch: 45/100] Loss: 0.359172  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.217545 \n",
            "\n",
            "[Epoch: 46/100] Loss: 0.119017  [   32/60000]\n",
            "[Epoch: 46/100] Loss: 0.077165  [ 3232/60000]\n",
            "[Epoch: 46/100] Loss: 0.054782  [ 6432/60000]\n",
            "[Epoch: 46/100] Loss: 0.118525  [ 9632/60000]\n",
            "[Epoch: 46/100] Loss: 0.441408  [12832/60000]\n",
            "[Epoch: 46/100] Loss: 0.260989  [16032/60000]\n",
            "[Epoch: 46/100] Loss: 0.368728  [19232/60000]\n",
            "[Epoch: 46/100] Loss: 0.183026  [22432/60000]\n",
            "[Epoch: 46/100] Loss: 0.130096  [25632/60000]\n",
            "[Epoch: 46/100] Loss: 0.137790  [28832/60000]\n",
            "[Epoch: 46/100] Loss: 0.183225  [32032/60000]\n",
            "[Epoch: 46/100] Loss: 0.329361  [35232/60000]\n",
            "[Epoch: 46/100] Loss: 0.300416  [38432/60000]\n",
            "[Epoch: 46/100] Loss: 0.382110  [41632/60000]\n",
            "[Epoch: 46/100] Loss: 0.294087  [44832/60000]\n",
            "[Epoch: 46/100] Loss: 0.040980  [48032/60000]\n",
            "[Epoch: 46/100] Loss: 0.240548  [51232/60000]\n",
            "[Epoch: 46/100] Loss: 0.223679  [54432/60000]\n",
            "[Epoch: 46/100] Loss: 0.464994  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.215520 \n",
            "\n",
            "[Epoch: 47/100] Loss: 0.284582  [   32/60000]\n",
            "[Epoch: 47/100] Loss: 0.374812  [ 3232/60000]\n",
            "[Epoch: 47/100] Loss: 0.116624  [ 6432/60000]\n",
            "[Epoch: 47/100] Loss: 0.219945  [ 9632/60000]\n",
            "[Epoch: 47/100] Loss: 0.202359  [12832/60000]\n",
            "[Epoch: 47/100] Loss: 0.478462  [16032/60000]\n",
            "[Epoch: 47/100] Loss: 0.179994  [19232/60000]\n",
            "[Epoch: 47/100] Loss: 0.284842  [22432/60000]\n",
            "[Epoch: 47/100] Loss: 0.174090  [25632/60000]\n",
            "[Epoch: 47/100] Loss: 0.094306  [28832/60000]\n",
            "[Epoch: 47/100] Loss: 0.223076  [32032/60000]\n",
            "[Epoch: 47/100] Loss: 0.278374  [35232/60000]\n",
            "[Epoch: 47/100] Loss: 0.174556  [38432/60000]\n",
            "[Epoch: 47/100] Loss: 0.185401  [41632/60000]\n",
            "[Epoch: 47/100] Loss: 0.285138  [44832/60000]\n",
            "[Epoch: 47/100] Loss: 0.213959  [48032/60000]\n",
            "[Epoch: 47/100] Loss: 0.203562  [51232/60000]\n",
            "[Epoch: 47/100] Loss: 0.269950  [54432/60000]\n",
            "[Epoch: 47/100] Loss: 0.110569  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.212720 \n",
            "\n",
            "[Epoch: 48/100] Loss: 0.247387  [   32/60000]\n",
            "[Epoch: 48/100] Loss: 0.207953  [ 3232/60000]\n",
            "[Epoch: 48/100] Loss: 0.192924  [ 6432/60000]\n",
            "[Epoch: 48/100] Loss: 0.287171  [ 9632/60000]\n",
            "[Epoch: 48/100] Loss: 0.369848  [12832/60000]\n",
            "[Epoch: 48/100] Loss: 0.250106  [16032/60000]\n",
            "[Epoch: 48/100] Loss: 0.193510  [19232/60000]\n",
            "[Epoch: 48/100] Loss: 0.123076  [22432/60000]\n",
            "[Epoch: 48/100] Loss: 0.147508  [25632/60000]\n",
            "[Epoch: 48/100] Loss: 0.193514  [28832/60000]\n",
            "[Epoch: 48/100] Loss: 0.102700  [32032/60000]\n",
            "[Epoch: 48/100] Loss: 0.075258  [35232/60000]\n",
            "[Epoch: 48/100] Loss: 0.830290  [38432/60000]\n",
            "[Epoch: 48/100] Loss: 0.333363  [41632/60000]\n",
            "[Epoch: 48/100] Loss: 0.242238  [44832/60000]\n",
            "[Epoch: 48/100] Loss: 0.079701  [48032/60000]\n",
            "[Epoch: 48/100] Loss: 0.170654  [51232/60000]\n",
            "[Epoch: 48/100] Loss: 0.305637  [54432/60000]\n",
            "[Epoch: 48/100] Loss: 0.176042  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.210083 \n",
            "\n",
            "[Epoch: 49/100] Loss: 0.237111  [   32/60000]\n",
            "[Epoch: 49/100] Loss: 0.128897  [ 3232/60000]\n",
            "[Epoch: 49/100] Loss: 0.204352  [ 6432/60000]\n",
            "[Epoch: 49/100] Loss: 0.124677  [ 9632/60000]\n",
            "[Epoch: 49/100] Loss: 0.170980  [12832/60000]\n",
            "[Epoch: 49/100] Loss: 0.183633  [16032/60000]\n",
            "[Epoch: 49/100] Loss: 0.043163  [19232/60000]\n",
            "[Epoch: 49/100] Loss: 0.075187  [22432/60000]\n",
            "[Epoch: 49/100] Loss: 0.166426  [25632/60000]\n",
            "[Epoch: 49/100] Loss: 0.316252  [28832/60000]\n",
            "[Epoch: 49/100] Loss: 0.245987  [32032/60000]\n",
            "[Epoch: 49/100] Loss: 0.311951  [35232/60000]\n",
            "[Epoch: 49/100] Loss: 0.143295  [38432/60000]\n",
            "[Epoch: 49/100] Loss: 0.111224  [41632/60000]\n",
            "[Epoch: 49/100] Loss: 0.134689  [44832/60000]\n",
            "[Epoch: 49/100] Loss: 0.204387  [48032/60000]\n",
            "[Epoch: 49/100] Loss: 0.112978  [51232/60000]\n",
            "[Epoch: 49/100] Loss: 0.135163  [54432/60000]\n",
            "[Epoch: 49/100] Loss: 0.281056  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.207814 \n",
            "\n",
            "[Epoch: 50/100] Loss: 0.072753  [   32/60000]\n",
            "[Epoch: 50/100] Loss: 0.233006  [ 3232/60000]\n",
            "[Epoch: 50/100] Loss: 0.192371  [ 6432/60000]\n",
            "[Epoch: 50/100] Loss: 0.294881  [ 9632/60000]\n",
            "[Epoch: 50/100] Loss: 0.097080  [12832/60000]\n",
            "[Epoch: 50/100] Loss: 0.172280  [16032/60000]\n",
            "[Epoch: 50/100] Loss: 0.124773  [19232/60000]\n",
            "[Epoch: 50/100] Loss: 0.135430  [22432/60000]\n",
            "[Epoch: 50/100] Loss: 0.260131  [25632/60000]\n",
            "[Epoch: 50/100] Loss: 0.152272  [28832/60000]\n",
            "[Epoch: 50/100] Loss: 0.172982  [32032/60000]\n",
            "[Epoch: 50/100] Loss: 0.309077  [35232/60000]\n",
            "[Epoch: 50/100] Loss: 0.061985  [38432/60000]\n",
            "[Epoch: 50/100] Loss: 0.249012  [41632/60000]\n",
            "[Epoch: 50/100] Loss: 0.064302  [44832/60000]\n",
            "[Epoch: 50/100] Loss: 0.178377  [48032/60000]\n",
            "[Epoch: 50/100] Loss: 0.294765  [51232/60000]\n",
            "[Epoch: 50/100] Loss: 0.261855  [54432/60000]\n",
            "[Epoch: 50/100] Loss: 0.327854  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.205930 \n",
            "\n",
            "[Epoch: 51/100] Loss: 0.040705  [   32/60000]\n",
            "[Epoch: 51/100] Loss: 0.315467  [ 3232/60000]\n",
            "[Epoch: 51/100] Loss: 0.207136  [ 6432/60000]\n",
            "[Epoch: 51/100] Loss: 0.091798  [ 9632/60000]\n",
            "[Epoch: 51/100] Loss: 0.089049  [12832/60000]\n",
            "[Epoch: 51/100] Loss: 0.271518  [16032/60000]\n",
            "[Epoch: 51/100] Loss: 0.169709  [19232/60000]\n",
            "[Epoch: 51/100] Loss: 0.089564  [22432/60000]\n",
            "[Epoch: 51/100] Loss: 0.079377  [25632/60000]\n",
            "[Epoch: 51/100] Loss: 0.190090  [28832/60000]\n",
            "[Epoch: 51/100] Loss: 0.203589  [32032/60000]\n",
            "[Epoch: 51/100] Loss: 0.139925  [35232/60000]\n",
            "[Epoch: 51/100] Loss: 0.097672  [38432/60000]\n",
            "[Epoch: 51/100] Loss: 0.436620  [41632/60000]\n",
            "[Epoch: 51/100] Loss: 0.279043  [44832/60000]\n",
            "[Epoch: 51/100] Loss: 0.149889  [48032/60000]\n",
            "[Epoch: 51/100] Loss: 0.296935  [51232/60000]\n",
            "[Epoch: 51/100] Loss: 0.215092  [54432/60000]\n",
            "[Epoch: 51/100] Loss: 0.326297  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.202724 \n",
            "\n",
            "[Epoch: 52/100] Loss: 0.194402  [   32/60000]\n",
            "[Epoch: 52/100] Loss: 0.141855  [ 3232/60000]\n",
            "[Epoch: 52/100] Loss: 0.293182  [ 6432/60000]\n",
            "[Epoch: 52/100] Loss: 0.114502  [ 9632/60000]\n",
            "[Epoch: 52/100] Loss: 0.219310  [12832/60000]\n",
            "[Epoch: 52/100] Loss: 0.207298  [16032/60000]\n",
            "[Epoch: 52/100] Loss: 0.125867  [19232/60000]\n",
            "[Epoch: 52/100] Loss: 0.136430  [22432/60000]\n",
            "[Epoch: 52/100] Loss: 0.121071  [25632/60000]\n",
            "[Epoch: 52/100] Loss: 0.044129  [28832/60000]\n",
            "[Epoch: 52/100] Loss: 0.156500  [32032/60000]\n",
            "[Epoch: 52/100] Loss: 0.123527  [35232/60000]\n",
            "[Epoch: 52/100] Loss: 0.385552  [38432/60000]\n",
            "[Epoch: 52/100] Loss: 0.135217  [41632/60000]\n",
            "[Epoch: 52/100] Loss: 0.075707  [44832/60000]\n",
            "[Epoch: 52/100] Loss: 0.124745  [48032/60000]\n",
            "[Epoch: 52/100] Loss: 0.342839  [51232/60000]\n",
            "[Epoch: 52/100] Loss: 0.277588  [54432/60000]\n",
            "[Epoch: 52/100] Loss: 0.118699  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.201293 \n",
            "\n",
            "[Epoch: 53/100] Loss: 0.393507  [   32/60000]\n",
            "[Epoch: 53/100] Loss: 0.209919  [ 3232/60000]\n",
            "[Epoch: 53/100] Loss: 0.130797  [ 6432/60000]\n",
            "[Epoch: 53/100] Loss: 0.201459  [ 9632/60000]\n",
            "[Epoch: 53/100] Loss: 0.175097  [12832/60000]\n",
            "[Epoch: 53/100] Loss: 0.114605  [16032/60000]\n",
            "[Epoch: 53/100] Loss: 0.256425  [19232/60000]\n",
            "[Epoch: 53/100] Loss: 0.151277  [22432/60000]\n",
            "[Epoch: 53/100] Loss: 0.311890  [25632/60000]\n",
            "[Epoch: 53/100] Loss: 0.171870  [28832/60000]\n",
            "[Epoch: 53/100] Loss: 0.072806  [32032/60000]\n",
            "[Epoch: 53/100] Loss: 0.239021  [35232/60000]\n",
            "[Epoch: 53/100] Loss: 0.500169  [38432/60000]\n",
            "[Epoch: 53/100] Loss: 0.149971  [41632/60000]\n",
            "[Epoch: 53/100] Loss: 0.281234  [44832/60000]\n",
            "[Epoch: 53/100] Loss: 0.123012  [48032/60000]\n",
            "[Epoch: 53/100] Loss: 0.152551  [51232/60000]\n",
            "[Epoch: 53/100] Loss: 0.121463  [54432/60000]\n",
            "[Epoch: 53/100] Loss: 0.274121  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.199696 \n",
            "\n",
            "[Epoch: 54/100] Loss: 0.249046  [   32/60000]\n",
            "[Epoch: 54/100] Loss: 0.141476  [ 3232/60000]\n",
            "[Epoch: 54/100] Loss: 0.262198  [ 6432/60000]\n",
            "[Epoch: 54/100] Loss: 0.271235  [ 9632/60000]\n",
            "[Epoch: 54/100] Loss: 0.144008  [12832/60000]\n",
            "[Epoch: 54/100] Loss: 0.090612  [16032/60000]\n",
            "[Epoch: 54/100] Loss: 0.160698  [19232/60000]\n",
            "[Epoch: 54/100] Loss: 0.213858  [22432/60000]\n",
            "[Epoch: 54/100] Loss: 0.172164  [25632/60000]\n",
            "[Epoch: 54/100] Loss: 0.153140  [28832/60000]\n",
            "[Epoch: 54/100] Loss: 0.094774  [32032/60000]\n",
            "[Epoch: 54/100] Loss: 0.379230  [35232/60000]\n",
            "[Epoch: 54/100] Loss: 0.108241  [38432/60000]\n",
            "[Epoch: 54/100] Loss: 0.420739  [41632/60000]\n",
            "[Epoch: 54/100] Loss: 0.068844  [44832/60000]\n",
            "[Epoch: 54/100] Loss: 0.095521  [48032/60000]\n",
            "[Epoch: 54/100] Loss: 0.117388  [51232/60000]\n",
            "[Epoch: 54/100] Loss: 0.323421  [54432/60000]\n",
            "[Epoch: 54/100] Loss: 0.255224  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.196669 \n",
            "\n",
            "[Epoch: 55/100] Loss: 0.099030  [   32/60000]\n",
            "[Epoch: 55/100] Loss: 0.050975  [ 3232/60000]\n",
            "[Epoch: 55/100] Loss: 0.279091  [ 6432/60000]\n",
            "[Epoch: 55/100] Loss: 0.140554  [ 9632/60000]\n",
            "[Epoch: 55/100] Loss: 0.230277  [12832/60000]\n",
            "[Epoch: 55/100] Loss: 0.170324  [16032/60000]\n",
            "[Epoch: 55/100] Loss: 0.066711  [19232/60000]\n",
            "[Epoch: 55/100] Loss: 0.313403  [22432/60000]\n",
            "[Epoch: 55/100] Loss: 0.215982  [25632/60000]\n",
            "[Epoch: 55/100] Loss: 0.254554  [28832/60000]\n",
            "[Epoch: 55/100] Loss: 0.046692  [32032/60000]\n",
            "[Epoch: 55/100] Loss: 0.107684  [35232/60000]\n",
            "[Epoch: 55/100] Loss: 0.108400  [38432/60000]\n",
            "[Epoch: 55/100] Loss: 0.518526  [41632/60000]\n",
            "[Epoch: 55/100] Loss: 0.186272  [44832/60000]\n",
            "[Epoch: 55/100] Loss: 0.093512  [48032/60000]\n",
            "[Epoch: 55/100] Loss: 0.149213  [51232/60000]\n",
            "[Epoch: 55/100] Loss: 0.303524  [54432/60000]\n",
            "[Epoch: 55/100] Loss: 0.169375  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.195101 \n",
            "\n",
            "[Epoch: 56/100] Loss: 0.207404  [   32/60000]\n",
            "[Epoch: 56/100] Loss: 0.290119  [ 3232/60000]\n",
            "[Epoch: 56/100] Loss: 0.071589  [ 6432/60000]\n",
            "[Epoch: 56/100] Loss: 0.284630  [ 9632/60000]\n",
            "[Epoch: 56/100] Loss: 0.259070  [12832/60000]\n",
            "[Epoch: 56/100] Loss: 0.264811  [16032/60000]\n",
            "[Epoch: 56/100] Loss: 0.156454  [19232/60000]\n",
            "[Epoch: 56/100] Loss: 0.093936  [22432/60000]\n",
            "[Epoch: 56/100] Loss: 0.079664  [25632/60000]\n",
            "[Epoch: 56/100] Loss: 0.223502  [28832/60000]\n",
            "[Epoch: 56/100] Loss: 0.157421  [32032/60000]\n",
            "[Epoch: 56/100] Loss: 0.089856  [35232/60000]\n",
            "[Epoch: 56/100] Loss: 0.155663  [38432/60000]\n",
            "[Epoch: 56/100] Loss: 0.252933  [41632/60000]\n",
            "[Epoch: 56/100] Loss: 0.238916  [44832/60000]\n",
            "[Epoch: 56/100] Loss: 0.281647  [48032/60000]\n",
            "[Epoch: 56/100] Loss: 0.161007  [51232/60000]\n",
            "[Epoch: 56/100] Loss: 0.087395  [54432/60000]\n",
            "[Epoch: 56/100] Loss: 0.167605  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.192921 \n",
            "\n",
            "[Epoch: 57/100] Loss: 0.179091  [   32/60000]\n",
            "[Epoch: 57/100] Loss: 0.167654  [ 3232/60000]\n",
            "[Epoch: 57/100] Loss: 0.158458  [ 6432/60000]\n",
            "[Epoch: 57/100] Loss: 0.364870  [ 9632/60000]\n",
            "[Epoch: 57/100] Loss: 0.480023  [12832/60000]\n",
            "[Epoch: 57/100] Loss: 0.276378  [16032/60000]\n",
            "[Epoch: 57/100] Loss: 0.268524  [19232/60000]\n",
            "[Epoch: 57/100] Loss: 0.058329  [22432/60000]\n",
            "[Epoch: 57/100] Loss: 0.115684  [25632/60000]\n",
            "[Epoch: 57/100] Loss: 0.087681  [28832/60000]\n",
            "[Epoch: 57/100] Loss: 0.109532  [32032/60000]\n",
            "[Epoch: 57/100] Loss: 0.367626  [35232/60000]\n",
            "[Epoch: 57/100] Loss: 0.169504  [38432/60000]\n",
            "[Epoch: 57/100] Loss: 0.273690  [41632/60000]\n",
            "[Epoch: 57/100] Loss: 0.122187  [44832/60000]\n",
            "[Epoch: 57/100] Loss: 0.104549  [48032/60000]\n",
            "[Epoch: 57/100] Loss: 0.172488  [51232/60000]\n",
            "[Epoch: 57/100] Loss: 0.101557  [54432/60000]\n",
            "[Epoch: 57/100] Loss: 0.338936  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.190250 \n",
            "\n",
            "[Epoch: 58/100] Loss: 0.215290  [   32/60000]\n",
            "[Epoch: 58/100] Loss: 0.284432  [ 3232/60000]\n",
            "[Epoch: 58/100] Loss: 0.135225  [ 6432/60000]\n",
            "[Epoch: 58/100] Loss: 0.203309  [ 9632/60000]\n",
            "[Epoch: 58/100] Loss: 0.153266  [12832/60000]\n",
            "[Epoch: 58/100] Loss: 0.132391  [16032/60000]\n",
            "[Epoch: 58/100] Loss: 0.239038  [19232/60000]\n",
            "[Epoch: 58/100] Loss: 0.303613  [22432/60000]\n",
            "[Epoch: 58/100] Loss: 0.385363  [25632/60000]\n",
            "[Epoch: 58/100] Loss: 0.163510  [28832/60000]\n",
            "[Epoch: 58/100] Loss: 0.269944  [32032/60000]\n",
            "[Epoch: 58/100] Loss: 0.160854  [35232/60000]\n",
            "[Epoch: 58/100] Loss: 0.396134  [38432/60000]\n",
            "[Epoch: 58/100] Loss: 0.686576  [41632/60000]\n",
            "[Epoch: 58/100] Loss: 0.122490  [44832/60000]\n",
            "[Epoch: 58/100] Loss: 0.134196  [48032/60000]\n",
            "[Epoch: 58/100] Loss: 0.202678  [51232/60000]\n",
            "[Epoch: 58/100] Loss: 0.026300  [54432/60000]\n",
            "[Epoch: 58/100] Loss: 0.199007  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.188293 \n",
            "\n",
            "[Epoch: 59/100] Loss: 0.166729  [   32/60000]\n",
            "[Epoch: 59/100] Loss: 0.253572  [ 3232/60000]\n",
            "[Epoch: 59/100] Loss: 0.156383  [ 6432/60000]\n",
            "[Epoch: 59/100] Loss: 0.111652  [ 9632/60000]\n",
            "[Epoch: 59/100] Loss: 0.289782  [12832/60000]\n",
            "[Epoch: 59/100] Loss: 0.123684  [16032/60000]\n",
            "[Epoch: 59/100] Loss: 0.182323  [19232/60000]\n",
            "[Epoch: 59/100] Loss: 0.080708  [22432/60000]\n",
            "[Epoch: 59/100] Loss: 0.089983  [25632/60000]\n",
            "[Epoch: 59/100] Loss: 0.238270  [28832/60000]\n",
            "[Epoch: 59/100] Loss: 0.041245  [32032/60000]\n",
            "[Epoch: 59/100] Loss: 0.267407  [35232/60000]\n",
            "[Epoch: 59/100] Loss: 0.147835  [38432/60000]\n",
            "[Epoch: 59/100] Loss: 0.279896  [41632/60000]\n",
            "[Epoch: 59/100] Loss: 0.146216  [44832/60000]\n",
            "[Epoch: 59/100] Loss: 0.057598  [48032/60000]\n",
            "[Epoch: 59/100] Loss: 0.192052  [51232/60000]\n",
            "[Epoch: 59/100] Loss: 0.346318  [54432/60000]\n",
            "[Epoch: 59/100] Loss: 0.290385  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186048 \n",
            "\n",
            "[Epoch: 60/100] Loss: 0.231891  [   32/60000]\n",
            "[Epoch: 60/100] Loss: 0.060635  [ 3232/60000]\n",
            "[Epoch: 60/100] Loss: 0.060471  [ 6432/60000]\n",
            "[Epoch: 60/100] Loss: 0.152446  [ 9632/60000]\n",
            "[Epoch: 60/100] Loss: 0.091818  [12832/60000]\n",
            "[Epoch: 60/100] Loss: 0.103987  [16032/60000]\n",
            "[Epoch: 60/100] Loss: 0.143292  [19232/60000]\n",
            "[Epoch: 60/100] Loss: 0.053988  [22432/60000]\n",
            "[Epoch: 60/100] Loss: 0.289070  [25632/60000]\n",
            "[Epoch: 60/100] Loss: 0.078050  [28832/60000]\n",
            "[Epoch: 60/100] Loss: 0.144049  [32032/60000]\n",
            "[Epoch: 60/100] Loss: 0.341325  [35232/60000]\n",
            "[Epoch: 60/100] Loss: 0.253056  [38432/60000]\n",
            "[Epoch: 60/100] Loss: 0.135233  [41632/60000]\n",
            "[Epoch: 60/100] Loss: 0.186579  [44832/60000]\n",
            "[Epoch: 60/100] Loss: 0.082439  [48032/60000]\n",
            "[Epoch: 60/100] Loss: 0.125419  [51232/60000]\n",
            "[Epoch: 60/100] Loss: 0.315047  [54432/60000]\n",
            "[Epoch: 60/100] Loss: 0.324303  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.184630 \n",
            "\n",
            "[Epoch: 61/100] Loss: 0.210149  [   32/60000]\n",
            "[Epoch: 61/100] Loss: 0.141219  [ 3232/60000]\n",
            "[Epoch: 61/100] Loss: 0.261128  [ 6432/60000]\n",
            "[Epoch: 61/100] Loss: 0.233710  [ 9632/60000]\n",
            "[Epoch: 61/100] Loss: 0.149838  [12832/60000]\n",
            "[Epoch: 61/100] Loss: 0.088209  [16032/60000]\n",
            "[Epoch: 61/100] Loss: 0.395549  [19232/60000]\n",
            "[Epoch: 61/100] Loss: 0.270102  [22432/60000]\n",
            "[Epoch: 61/100] Loss: 0.124724  [25632/60000]\n",
            "[Epoch: 61/100] Loss: 0.065610  [28832/60000]\n",
            "[Epoch: 61/100] Loss: 0.314840  [32032/60000]\n",
            "[Epoch: 61/100] Loss: 0.103728  [35232/60000]\n",
            "[Epoch: 61/100] Loss: 0.228867  [38432/60000]\n",
            "[Epoch: 61/100] Loss: 0.101308  [41632/60000]\n",
            "[Epoch: 61/100] Loss: 0.141408  [44832/60000]\n",
            "[Epoch: 61/100] Loss: 0.278703  [48032/60000]\n",
            "[Epoch: 61/100] Loss: 0.268888  [51232/60000]\n",
            "[Epoch: 61/100] Loss: 0.298127  [54432/60000]\n",
            "[Epoch: 61/100] Loss: 0.155682  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.182720 \n",
            "\n",
            "[Epoch: 62/100] Loss: 0.157260  [   32/60000]\n",
            "[Epoch: 62/100] Loss: 0.215197  [ 3232/60000]\n",
            "[Epoch: 62/100] Loss: 0.152375  [ 6432/60000]\n",
            "[Epoch: 62/100] Loss: 0.299508  [ 9632/60000]\n",
            "[Epoch: 62/100] Loss: 0.107304  [12832/60000]\n",
            "[Epoch: 62/100] Loss: 0.187023  [16032/60000]\n",
            "[Epoch: 62/100] Loss: 0.432117  [19232/60000]\n",
            "[Epoch: 62/100] Loss: 0.093030  [22432/60000]\n",
            "[Epoch: 62/100] Loss: 0.044534  [25632/60000]\n",
            "[Epoch: 62/100] Loss: 0.093720  [28832/60000]\n",
            "[Epoch: 62/100] Loss: 0.332927  [32032/60000]\n",
            "[Epoch: 62/100] Loss: 0.243678  [35232/60000]\n",
            "[Epoch: 62/100] Loss: 0.149608  [38432/60000]\n",
            "[Epoch: 62/100] Loss: 0.135357  [41632/60000]\n",
            "[Epoch: 62/100] Loss: 0.099166  [44832/60000]\n",
            "[Epoch: 62/100] Loss: 0.189769  [48032/60000]\n",
            "[Epoch: 62/100] Loss: 0.077718  [51232/60000]\n",
            "[Epoch: 62/100] Loss: 0.218111  [54432/60000]\n",
            "[Epoch: 62/100] Loss: 0.074757  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.180660 \n",
            "\n",
            "[Epoch: 63/100] Loss: 0.085428  [   32/60000]\n",
            "[Epoch: 63/100] Loss: 0.130052  [ 3232/60000]\n",
            "[Epoch: 63/100] Loss: 0.165551  [ 6432/60000]\n",
            "[Epoch: 63/100] Loss: 0.235618  [ 9632/60000]\n",
            "[Epoch: 63/100] Loss: 0.152365  [12832/60000]\n",
            "[Epoch: 63/100] Loss: 0.044255  [16032/60000]\n",
            "[Epoch: 63/100] Loss: 0.126126  [19232/60000]\n",
            "[Epoch: 63/100] Loss: 0.121258  [22432/60000]\n",
            "[Epoch: 63/100] Loss: 0.342968  [25632/60000]\n",
            "[Epoch: 63/100] Loss: 0.170999  [28832/60000]\n",
            "[Epoch: 63/100] Loss: 0.106129  [32032/60000]\n",
            "[Epoch: 63/100] Loss: 0.166253  [35232/60000]\n",
            "[Epoch: 63/100] Loss: 0.209983  [38432/60000]\n",
            "[Epoch: 63/100] Loss: 0.056219  [41632/60000]\n",
            "[Epoch: 63/100] Loss: 0.209914  [44832/60000]\n",
            "[Epoch: 63/100] Loss: 0.253020  [48032/60000]\n",
            "[Epoch: 63/100] Loss: 0.045749  [51232/60000]\n",
            "[Epoch: 63/100] Loss: 0.069780  [54432/60000]\n",
            "[Epoch: 63/100] Loss: 0.241792  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.179117 \n",
            "\n",
            "[Epoch: 64/100] Loss: 0.083000  [   32/60000]\n",
            "[Epoch: 64/100] Loss: 0.177200  [ 3232/60000]\n",
            "[Epoch: 64/100] Loss: 0.144641  [ 6432/60000]\n",
            "[Epoch: 64/100] Loss: 0.155492  [ 9632/60000]\n",
            "[Epoch: 64/100] Loss: 0.141686  [12832/60000]\n",
            "[Epoch: 64/100] Loss: 0.279630  [16032/60000]\n",
            "[Epoch: 64/100] Loss: 0.294099  [19232/60000]\n",
            "[Epoch: 64/100] Loss: 0.203064  [22432/60000]\n",
            "[Epoch: 64/100] Loss: 0.150620  [25632/60000]\n",
            "[Epoch: 64/100] Loss: 0.062260  [28832/60000]\n",
            "[Epoch: 64/100] Loss: 0.176975  [32032/60000]\n",
            "[Epoch: 64/100] Loss: 0.357334  [35232/60000]\n",
            "[Epoch: 64/100] Loss: 0.214226  [38432/60000]\n",
            "[Epoch: 64/100] Loss: 0.193288  [41632/60000]\n",
            "[Epoch: 64/100] Loss: 0.240067  [44832/60000]\n",
            "[Epoch: 64/100] Loss: 0.165395  [48032/60000]\n",
            "[Epoch: 64/100] Loss: 0.254942  [51232/60000]\n",
            "[Epoch: 64/100] Loss: 0.072762  [54432/60000]\n",
            "[Epoch: 64/100] Loss: 0.218809  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.176979 \n",
            "\n",
            "[Epoch: 65/100] Loss: 0.132933  [   32/60000]\n",
            "[Epoch: 65/100] Loss: 0.222021  [ 3232/60000]\n",
            "[Epoch: 65/100] Loss: 0.130335  [ 6432/60000]\n",
            "[Epoch: 65/100] Loss: 0.155564  [ 9632/60000]\n",
            "[Epoch: 65/100] Loss: 0.048797  [12832/60000]\n",
            "[Epoch: 65/100] Loss: 0.073792  [16032/60000]\n",
            "[Epoch: 65/100] Loss: 0.280704  [19232/60000]\n",
            "[Epoch: 65/100] Loss: 0.305443  [22432/60000]\n",
            "[Epoch: 65/100] Loss: 0.134889  [25632/60000]\n",
            "[Epoch: 65/100] Loss: 0.113196  [28832/60000]\n",
            "[Epoch: 65/100] Loss: 0.267426  [32032/60000]\n",
            "[Epoch: 65/100] Loss: 0.058386  [35232/60000]\n",
            "[Epoch: 65/100] Loss: 0.071957  [38432/60000]\n",
            "[Epoch: 65/100] Loss: 0.110761  [41632/60000]\n",
            "[Epoch: 65/100] Loss: 0.060131  [44832/60000]\n",
            "[Epoch: 65/100] Loss: 0.041769  [48032/60000]\n",
            "[Epoch: 65/100] Loss: 0.155974  [51232/60000]\n",
            "[Epoch: 65/100] Loss: 0.284477  [54432/60000]\n",
            "[Epoch: 65/100] Loss: 0.156625  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175350 \n",
            "\n",
            "[Epoch: 66/100] Loss: 0.336129  [   32/60000]\n",
            "[Epoch: 66/100] Loss: 0.119512  [ 3232/60000]\n",
            "[Epoch: 66/100] Loss: 0.048799  [ 6432/60000]\n",
            "[Epoch: 66/100] Loss: 0.127351  [ 9632/60000]\n",
            "[Epoch: 66/100] Loss: 0.203165  [12832/60000]\n",
            "[Epoch: 66/100] Loss: 0.089544  [16032/60000]\n",
            "[Epoch: 66/100] Loss: 0.200295  [19232/60000]\n",
            "[Epoch: 66/100] Loss: 0.101454  [22432/60000]\n",
            "[Epoch: 66/100] Loss: 0.074241  [25632/60000]\n",
            "[Epoch: 66/100] Loss: 0.050618  [28832/60000]\n",
            "[Epoch: 66/100] Loss: 0.485656  [32032/60000]\n",
            "[Epoch: 66/100] Loss: 0.145584  [35232/60000]\n",
            "[Epoch: 66/100] Loss: 0.342289  [38432/60000]\n",
            "[Epoch: 66/100] Loss: 0.331092  [41632/60000]\n",
            "[Epoch: 66/100] Loss: 0.158193  [44832/60000]\n",
            "[Epoch: 66/100] Loss: 0.140510  [48032/60000]\n",
            "[Epoch: 66/100] Loss: 0.055540  [51232/60000]\n",
            "[Epoch: 66/100] Loss: 0.083533  [54432/60000]\n",
            "[Epoch: 66/100] Loss: 0.057033  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.173065 \n",
            "\n",
            "[Epoch: 67/100] Loss: 0.354542  [   32/60000]\n",
            "[Epoch: 67/100] Loss: 0.213336  [ 3232/60000]\n",
            "[Epoch: 67/100] Loss: 0.139414  [ 6432/60000]\n",
            "[Epoch: 67/100] Loss: 0.325183  [ 9632/60000]\n",
            "[Epoch: 67/100] Loss: 0.156289  [12832/60000]\n",
            "[Epoch: 67/100] Loss: 0.058988  [16032/60000]\n",
            "[Epoch: 67/100] Loss: 0.138082  [19232/60000]\n",
            "[Epoch: 67/100] Loss: 0.055123  [22432/60000]\n",
            "[Epoch: 67/100] Loss: 0.169384  [25632/60000]\n",
            "[Epoch: 67/100] Loss: 0.141569  [28832/60000]\n",
            "[Epoch: 67/100] Loss: 0.045785  [32032/60000]\n",
            "[Epoch: 67/100] Loss: 0.202312  [35232/60000]\n",
            "[Epoch: 67/100] Loss: 0.071605  [38432/60000]\n",
            "[Epoch: 67/100] Loss: 0.094631  [41632/60000]\n",
            "[Epoch: 67/100] Loss: 0.086189  [44832/60000]\n",
            "[Epoch: 67/100] Loss: 0.036023  [48032/60000]\n",
            "[Epoch: 67/100] Loss: 0.616006  [51232/60000]\n",
            "[Epoch: 67/100] Loss: 0.104031  [54432/60000]\n",
            "[Epoch: 67/100] Loss: 0.060785  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.172928 \n",
            "\n",
            "[Epoch: 68/100] Loss: 0.096021  [   32/60000]\n",
            "[Epoch: 68/100] Loss: 0.098773  [ 3232/60000]\n",
            "[Epoch: 68/100] Loss: 0.070174  [ 6432/60000]\n",
            "[Epoch: 68/100] Loss: 0.252120  [ 9632/60000]\n",
            "[Epoch: 68/100] Loss: 0.122952  [12832/60000]\n",
            "[Epoch: 68/100] Loss: 0.133306  [16032/60000]\n",
            "[Epoch: 68/100] Loss: 0.431215  [19232/60000]\n",
            "[Epoch: 68/100] Loss: 0.057461  [22432/60000]\n",
            "[Epoch: 68/100] Loss: 0.106938  [25632/60000]\n",
            "[Epoch: 68/100] Loss: 0.140851  [28832/60000]\n",
            "[Epoch: 68/100] Loss: 0.033793  [32032/60000]\n",
            "[Epoch: 68/100] Loss: 0.151126  [35232/60000]\n",
            "[Epoch: 68/100] Loss: 0.248717  [38432/60000]\n",
            "[Epoch: 68/100] Loss: 0.159401  [41632/60000]\n",
            "[Epoch: 68/100] Loss: 0.227799  [44832/60000]\n",
            "[Epoch: 68/100] Loss: 0.372769  [48032/60000]\n",
            "[Epoch: 68/100] Loss: 0.139191  [51232/60000]\n",
            "[Epoch: 68/100] Loss: 0.067226  [54432/60000]\n",
            "[Epoch: 68/100] Loss: 0.145437  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.170334 \n",
            "\n",
            "[Epoch: 69/100] Loss: 0.143062  [   32/60000]\n",
            "[Epoch: 69/100] Loss: 0.184944  [ 3232/60000]\n",
            "[Epoch: 69/100] Loss: 0.082305  [ 6432/60000]\n",
            "[Epoch: 69/100] Loss: 0.304595  [ 9632/60000]\n",
            "[Epoch: 69/100] Loss: 0.125093  [12832/60000]\n",
            "[Epoch: 69/100] Loss: 0.199274  [16032/60000]\n",
            "[Epoch: 69/100] Loss: 0.084947  [19232/60000]\n",
            "[Epoch: 69/100] Loss: 0.083722  [22432/60000]\n",
            "[Epoch: 69/100] Loss: 0.192332  [25632/60000]\n",
            "[Epoch: 69/100] Loss: 0.119502  [28832/60000]\n",
            "[Epoch: 69/100] Loss: 0.210593  [32032/60000]\n",
            "[Epoch: 69/100] Loss: 0.412579  [35232/60000]\n",
            "[Epoch: 69/100] Loss: 0.088406  [38432/60000]\n",
            "[Epoch: 69/100] Loss: 0.165306  [41632/60000]\n",
            "[Epoch: 69/100] Loss: 0.198592  [44832/60000]\n",
            "[Epoch: 69/100] Loss: 0.144279  [48032/60000]\n",
            "[Epoch: 69/100] Loss: 0.122590  [51232/60000]\n",
            "[Epoch: 69/100] Loss: 0.176941  [54432/60000]\n",
            "[Epoch: 69/100] Loss: 0.148015  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.169571 \n",
            "\n",
            "[Epoch: 70/100] Loss: 0.060750  [   32/60000]\n",
            "[Epoch: 70/100] Loss: 0.206641  [ 3232/60000]\n",
            "[Epoch: 70/100] Loss: 0.028218  [ 6432/60000]\n",
            "[Epoch: 70/100] Loss: 0.129935  [ 9632/60000]\n",
            "[Epoch: 70/100] Loss: 0.145688  [12832/60000]\n",
            "[Epoch: 70/100] Loss: 0.156968  [16032/60000]\n",
            "[Epoch: 70/100] Loss: 0.202410  [19232/60000]\n",
            "[Epoch: 70/100] Loss: 0.333666  [22432/60000]\n",
            "[Epoch: 70/100] Loss: 0.085694  [25632/60000]\n",
            "[Epoch: 70/100] Loss: 0.069239  [28832/60000]\n",
            "[Epoch: 70/100] Loss: 0.133299  [32032/60000]\n",
            "[Epoch: 70/100] Loss: 0.136943  [35232/60000]\n",
            "[Epoch: 70/100] Loss: 0.145237  [38432/60000]\n",
            "[Epoch: 70/100] Loss: 0.193378  [41632/60000]\n",
            "[Epoch: 70/100] Loss: 0.429508  [44832/60000]\n",
            "[Epoch: 70/100] Loss: 0.150968  [48032/60000]\n",
            "[Epoch: 70/100] Loss: 0.289719  [51232/60000]\n",
            "[Epoch: 70/100] Loss: 0.102684  [54432/60000]\n",
            "[Epoch: 70/100] Loss: 0.406415  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.166878 \n",
            "\n",
            "[Epoch: 71/100] Loss: 0.091816  [   32/60000]\n",
            "[Epoch: 71/100] Loss: 0.119385  [ 3232/60000]\n",
            "[Epoch: 71/100] Loss: 0.122669  [ 6432/60000]\n",
            "[Epoch: 71/100] Loss: 0.096582  [ 9632/60000]\n",
            "[Epoch: 71/100] Loss: 0.199961  [12832/60000]\n",
            "[Epoch: 71/100] Loss: 0.159642  [16032/60000]\n",
            "[Epoch: 71/100] Loss: 0.038456  [19232/60000]\n",
            "[Epoch: 71/100] Loss: 0.079273  [22432/60000]\n",
            "[Epoch: 71/100] Loss: 0.063789  [25632/60000]\n",
            "[Epoch: 71/100] Loss: 0.310636  [28832/60000]\n",
            "[Epoch: 71/100] Loss: 0.249494  [32032/60000]\n",
            "[Epoch: 71/100] Loss: 0.223623  [35232/60000]\n",
            "[Epoch: 71/100] Loss: 0.069662  [38432/60000]\n",
            "[Epoch: 71/100] Loss: 0.283557  [41632/60000]\n",
            "[Epoch: 71/100] Loss: 0.212664  [44832/60000]\n",
            "[Epoch: 71/100] Loss: 0.200129  [48032/60000]\n",
            "[Epoch: 71/100] Loss: 0.131532  [51232/60000]\n",
            "[Epoch: 71/100] Loss: 0.051089  [54432/60000]\n",
            "[Epoch: 71/100] Loss: 0.195181  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.165362 \n",
            "\n",
            "[Epoch: 72/100] Loss: 0.181980  [   32/60000]\n",
            "[Epoch: 72/100] Loss: 0.182387  [ 3232/60000]\n",
            "[Epoch: 72/100] Loss: 0.269748  [ 6432/60000]\n",
            "[Epoch: 72/100] Loss: 0.160477  [ 9632/60000]\n",
            "[Epoch: 72/100] Loss: 0.267616  [12832/60000]\n",
            "[Epoch: 72/100] Loss: 0.052094  [16032/60000]\n",
            "[Epoch: 72/100] Loss: 0.074683  [19232/60000]\n",
            "[Epoch: 72/100] Loss: 0.189273  [22432/60000]\n",
            "[Epoch: 72/100] Loss: 0.237955  [25632/60000]\n",
            "[Epoch: 72/100] Loss: 0.119993  [28832/60000]\n",
            "[Epoch: 72/100] Loss: 0.075041  [32032/60000]\n",
            "[Epoch: 72/100] Loss: 0.140328  [35232/60000]\n",
            "[Epoch: 72/100] Loss: 0.144582  [38432/60000]\n",
            "[Epoch: 72/100] Loss: 0.035796  [41632/60000]\n",
            "[Epoch: 72/100] Loss: 0.133045  [44832/60000]\n",
            "[Epoch: 72/100] Loss: 0.225498  [48032/60000]\n",
            "[Epoch: 72/100] Loss: 0.132071  [51232/60000]\n",
            "[Epoch: 72/100] Loss: 0.156803  [54432/60000]\n",
            "[Epoch: 72/100] Loss: 0.340134  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.164348 \n",
            "\n",
            "[Epoch: 73/100] Loss: 0.076583  [   32/60000]\n",
            "[Epoch: 73/100] Loss: 0.151737  [ 3232/60000]\n",
            "[Epoch: 73/100] Loss: 0.148989  [ 6432/60000]\n",
            "[Epoch: 73/100] Loss: 0.051664  [ 9632/60000]\n",
            "[Epoch: 73/100] Loss: 0.078297  [12832/60000]\n",
            "[Epoch: 73/100] Loss: 0.048023  [16032/60000]\n",
            "[Epoch: 73/100] Loss: 0.311802  [19232/60000]\n",
            "[Epoch: 73/100] Loss: 0.131255  [22432/60000]\n",
            "[Epoch: 73/100] Loss: 0.034548  [25632/60000]\n",
            "[Epoch: 73/100] Loss: 0.347734  [28832/60000]\n",
            "[Epoch: 73/100] Loss: 0.075192  [32032/60000]\n",
            "[Epoch: 73/100] Loss: 0.079654  [35232/60000]\n",
            "[Epoch: 73/100] Loss: 0.171477  [38432/60000]\n",
            "[Epoch: 73/100] Loss: 0.216672  [41632/60000]\n",
            "[Epoch: 73/100] Loss: 0.101957  [44832/60000]\n",
            "[Epoch: 73/100] Loss: 0.312237  [48032/60000]\n",
            "[Epoch: 73/100] Loss: 0.263840  [51232/60000]\n",
            "[Epoch: 73/100] Loss: 0.256700  [54432/60000]\n",
            "[Epoch: 73/100] Loss: 0.085140  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.163606 \n",
            "\n",
            "[Epoch: 74/100] Loss: 0.071536  [   32/60000]\n",
            "[Epoch: 74/100] Loss: 0.143490  [ 3232/60000]\n",
            "[Epoch: 74/100] Loss: 0.040733  [ 6432/60000]\n",
            "[Epoch: 74/100] Loss: 0.047725  [ 9632/60000]\n",
            "[Epoch: 74/100] Loss: 0.063592  [12832/60000]\n",
            "[Epoch: 74/100] Loss: 0.241505  [16032/60000]\n",
            "[Epoch: 74/100] Loss: 0.051553  [19232/60000]\n",
            "[Epoch: 74/100] Loss: 0.144410  [22432/60000]\n",
            "[Epoch: 74/100] Loss: 0.045501  [25632/60000]\n",
            "[Epoch: 74/100] Loss: 0.172489  [28832/60000]\n",
            "[Epoch: 74/100] Loss: 0.082725  [32032/60000]\n",
            "[Epoch: 74/100] Loss: 0.236464  [35232/60000]\n",
            "[Epoch: 74/100] Loss: 0.103075  [38432/60000]\n",
            "[Epoch: 74/100] Loss: 0.101739  [41632/60000]\n",
            "[Epoch: 74/100] Loss: 0.043937  [44832/60000]\n",
            "[Epoch: 74/100] Loss: 0.101341  [48032/60000]\n",
            "[Epoch: 74/100] Loss: 0.258245  [51232/60000]\n",
            "[Epoch: 74/100] Loss: 0.197136  [54432/60000]\n",
            "[Epoch: 74/100] Loss: 0.177588  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.161518 \n",
            "\n",
            "[Epoch: 75/100] Loss: 0.118974  [   32/60000]\n",
            "[Epoch: 75/100] Loss: 0.176761  [ 3232/60000]\n",
            "[Epoch: 75/100] Loss: 0.098699  [ 6432/60000]\n",
            "[Epoch: 75/100] Loss: 0.047714  [ 9632/60000]\n",
            "[Epoch: 75/100] Loss: 0.392827  [12832/60000]\n",
            "[Epoch: 75/100] Loss: 0.046520  [16032/60000]\n",
            "[Epoch: 75/100] Loss: 0.714700  [19232/60000]\n",
            "[Epoch: 75/100] Loss: 0.096415  [22432/60000]\n",
            "[Epoch: 75/100] Loss: 0.170525  [25632/60000]\n",
            "[Epoch: 75/100] Loss: 0.053818  [28832/60000]\n",
            "[Epoch: 75/100] Loss: 0.095049  [32032/60000]\n",
            "[Epoch: 75/100] Loss: 0.103902  [35232/60000]\n",
            "[Epoch: 75/100] Loss: 0.085290  [38432/60000]\n",
            "[Epoch: 75/100] Loss: 0.185325  [41632/60000]\n",
            "[Epoch: 75/100] Loss: 0.105072  [44832/60000]\n",
            "[Epoch: 75/100] Loss: 0.476964  [48032/60000]\n",
            "[Epoch: 75/100] Loss: 0.337673  [51232/60000]\n",
            "[Epoch: 75/100] Loss: 0.069518  [54432/60000]\n",
            "[Epoch: 75/100] Loss: 0.068744  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159737 \n",
            "\n",
            "[Epoch: 76/100] Loss: 0.064359  [   32/60000]\n",
            "[Epoch: 76/100] Loss: 0.201180  [ 3232/60000]\n",
            "[Epoch: 76/100] Loss: 0.323892  [ 6432/60000]\n",
            "[Epoch: 76/100] Loss: 0.278935  [ 9632/60000]\n",
            "[Epoch: 76/100] Loss: 0.203939  [12832/60000]\n",
            "[Epoch: 76/100] Loss: 0.154427  [16032/60000]\n",
            "[Epoch: 76/100] Loss: 0.178041  [19232/60000]\n",
            "[Epoch: 76/100] Loss: 0.090760  [22432/60000]\n",
            "[Epoch: 76/100] Loss: 0.206876  [25632/60000]\n",
            "[Epoch: 76/100] Loss: 0.234082  [28832/60000]\n",
            "[Epoch: 76/100] Loss: 0.201031  [32032/60000]\n",
            "[Epoch: 76/100] Loss: 0.087256  [35232/60000]\n",
            "[Epoch: 76/100] Loss: 0.050836  [38432/60000]\n",
            "[Epoch: 76/100] Loss: 0.132984  [41632/60000]\n",
            "[Epoch: 76/100] Loss: 0.185536  [44832/60000]\n",
            "[Epoch: 76/100] Loss: 0.059578  [48032/60000]\n",
            "[Epoch: 76/100] Loss: 0.093011  [51232/60000]\n",
            "[Epoch: 76/100] Loss: 0.095004  [54432/60000]\n",
            "[Epoch: 76/100] Loss: 0.124268  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.3%, Avg loss: 0.158142 \n",
            "\n",
            "[Epoch: 77/100] Loss: 0.133599  [   32/60000]\n",
            "[Epoch: 77/100] Loss: 0.233360  [ 3232/60000]\n",
            "[Epoch: 77/100] Loss: 0.046229  [ 6432/60000]\n",
            "[Epoch: 77/100] Loss: 0.127194  [ 9632/60000]\n",
            "[Epoch: 77/100] Loss: 0.102694  [12832/60000]\n",
            "[Epoch: 77/100] Loss: 0.229908  [16032/60000]\n",
            "[Epoch: 77/100] Loss: 0.153912  [19232/60000]\n",
            "[Epoch: 77/100] Loss: 0.327145  [22432/60000]\n",
            "[Epoch: 77/100] Loss: 0.048513  [25632/60000]\n",
            "[Epoch: 77/100] Loss: 0.278629  [28832/60000]\n",
            "[Epoch: 77/100] Loss: 0.325478  [32032/60000]\n",
            "[Epoch: 77/100] Loss: 0.189481  [35232/60000]\n",
            "[Epoch: 77/100] Loss: 0.083944  [38432/60000]\n",
            "[Epoch: 77/100] Loss: 0.060617  [41632/60000]\n",
            "[Epoch: 77/100] Loss: 0.057477  [44832/60000]\n",
            "[Epoch: 77/100] Loss: 0.051264  [48032/60000]\n",
            "[Epoch: 77/100] Loss: 0.117767  [51232/60000]\n",
            "[Epoch: 77/100] Loss: 0.339211  [54432/60000]\n",
            "[Epoch: 77/100] Loss: 0.186099  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.3%, Avg loss: 0.157117 \n",
            "\n",
            "[Epoch: 78/100] Loss: 0.066235  [   32/60000]\n",
            "[Epoch: 78/100] Loss: 0.048255  [ 3232/60000]\n",
            "[Epoch: 78/100] Loss: 0.186554  [ 6432/60000]\n",
            "[Epoch: 78/100] Loss: 0.204422  [ 9632/60000]\n",
            "[Epoch: 78/100] Loss: 0.052140  [12832/60000]\n",
            "[Epoch: 78/100] Loss: 0.062469  [16032/60000]\n",
            "[Epoch: 78/100] Loss: 0.188645  [19232/60000]\n",
            "[Epoch: 78/100] Loss: 0.025539  [22432/60000]\n",
            "[Epoch: 78/100] Loss: 0.053214  [25632/60000]\n",
            "[Epoch: 78/100] Loss: 0.153850  [28832/60000]\n",
            "[Epoch: 78/100] Loss: 0.050752  [32032/60000]\n",
            "[Epoch: 78/100] Loss: 0.044168  [35232/60000]\n",
            "[Epoch: 78/100] Loss: 0.086191  [38432/60000]\n",
            "[Epoch: 78/100] Loss: 0.327307  [41632/60000]\n",
            "[Epoch: 78/100] Loss: 0.036261  [44832/60000]\n",
            "[Epoch: 78/100] Loss: 0.120717  [48032/60000]\n",
            "[Epoch: 78/100] Loss: 0.245367  [51232/60000]\n",
            "[Epoch: 78/100] Loss: 0.053084  [54432/60000]\n",
            "[Epoch: 78/100] Loss: 0.245121  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.155721 \n",
            "\n",
            "[Epoch: 79/100] Loss: 0.072711  [   32/60000]\n",
            "[Epoch: 79/100] Loss: 0.342574  [ 3232/60000]\n",
            "[Epoch: 79/100] Loss: 0.291370  [ 6432/60000]\n",
            "[Epoch: 79/100] Loss: 0.100382  [ 9632/60000]\n",
            "[Epoch: 79/100] Loss: 0.398209  [12832/60000]\n",
            "[Epoch: 79/100] Loss: 0.075276  [16032/60000]\n",
            "[Epoch: 79/100] Loss: 0.192722  [19232/60000]\n",
            "[Epoch: 79/100] Loss: 0.033267  [22432/60000]\n",
            "[Epoch: 79/100] Loss: 0.191678  [25632/60000]\n",
            "[Epoch: 79/100] Loss: 0.224897  [28832/60000]\n",
            "[Epoch: 79/100] Loss: 0.248330  [32032/60000]\n",
            "[Epoch: 79/100] Loss: 0.167873  [35232/60000]\n",
            "[Epoch: 79/100] Loss: 0.073866  [38432/60000]\n",
            "[Epoch: 79/100] Loss: 0.134507  [41632/60000]\n",
            "[Epoch: 79/100] Loss: 0.066432  [44832/60000]\n",
            "[Epoch: 79/100] Loss: 0.120180  [48032/60000]\n",
            "[Epoch: 79/100] Loss: 0.088505  [51232/60000]\n",
            "[Epoch: 79/100] Loss: 0.286670  [54432/60000]\n",
            "[Epoch: 79/100] Loss: 0.088180  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.154375 \n",
            "\n",
            "[Epoch: 80/100] Loss: 0.093160  [   32/60000]\n",
            "[Epoch: 80/100] Loss: 0.447589  [ 3232/60000]\n",
            "[Epoch: 80/100] Loss: 0.105549  [ 6432/60000]\n",
            "[Epoch: 80/100] Loss: 0.080271  [ 9632/60000]\n",
            "[Epoch: 80/100] Loss: 0.191543  [12832/60000]\n",
            "[Epoch: 80/100] Loss: 0.278746  [16032/60000]\n",
            "[Epoch: 80/100] Loss: 0.087273  [19232/60000]\n",
            "[Epoch: 80/100] Loss: 0.069757  [22432/60000]\n",
            "[Epoch: 80/100] Loss: 0.156318  [25632/60000]\n",
            "[Epoch: 80/100] Loss: 0.073272  [28832/60000]\n",
            "[Epoch: 80/100] Loss: 0.048201  [32032/60000]\n",
            "[Epoch: 80/100] Loss: 0.025825  [35232/60000]\n",
            "[Epoch: 80/100] Loss: 0.191306  [38432/60000]\n",
            "[Epoch: 80/100] Loss: 0.072203  [41632/60000]\n",
            "[Epoch: 80/100] Loss: 0.406294  [44832/60000]\n",
            "[Epoch: 80/100] Loss: 0.066412  [48032/60000]\n",
            "[Epoch: 80/100] Loss: 0.064937  [51232/60000]\n",
            "[Epoch: 80/100] Loss: 0.042263  [54432/60000]\n",
            "[Epoch: 80/100] Loss: 0.120861  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.152874 \n",
            "\n",
            "[Epoch: 81/100] Loss: 0.268932  [   32/60000]\n",
            "[Epoch: 81/100] Loss: 0.058441  [ 3232/60000]\n",
            "[Epoch: 81/100] Loss: 0.084802  [ 6432/60000]\n",
            "[Epoch: 81/100] Loss: 0.104417  [ 9632/60000]\n",
            "[Epoch: 81/100] Loss: 0.046299  [12832/60000]\n",
            "[Epoch: 81/100] Loss: 0.134430  [16032/60000]\n",
            "[Epoch: 81/100] Loss: 0.065404  [19232/60000]\n",
            "[Epoch: 81/100] Loss: 0.087002  [22432/60000]\n",
            "[Epoch: 81/100] Loss: 0.174408  [25632/60000]\n",
            "[Epoch: 81/100] Loss: 0.067606  [28832/60000]\n",
            "[Epoch: 81/100] Loss: 0.105125  [32032/60000]\n",
            "[Epoch: 81/100] Loss: 0.217136  [35232/60000]\n",
            "[Epoch: 81/100] Loss: 0.141003  [38432/60000]\n",
            "[Epoch: 81/100] Loss: 0.171272  [41632/60000]\n",
            "[Epoch: 81/100] Loss: 0.052341  [44832/60000]\n",
            "[Epoch: 81/100] Loss: 0.050544  [48032/60000]\n",
            "[Epoch: 81/100] Loss: 0.137667  [51232/60000]\n",
            "[Epoch: 81/100] Loss: 0.034818  [54432/60000]\n",
            "[Epoch: 81/100] Loss: 0.246732  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.151020 \n",
            "\n",
            "[Epoch: 82/100] Loss: 0.060950  [   32/60000]\n",
            "[Epoch: 82/100] Loss: 0.214801  [ 3232/60000]\n",
            "[Epoch: 82/100] Loss: 0.197930  [ 6432/60000]\n",
            "[Epoch: 82/100] Loss: 0.100741  [ 9632/60000]\n",
            "[Epoch: 82/100] Loss: 0.191119  [12832/60000]\n",
            "[Epoch: 82/100] Loss: 0.170914  [16032/60000]\n",
            "[Epoch: 82/100] Loss: 0.037812  [19232/60000]\n",
            "[Epoch: 82/100] Loss: 0.160437  [22432/60000]\n",
            "[Epoch: 82/100] Loss: 0.100897  [25632/60000]\n",
            "[Epoch: 82/100] Loss: 0.025875  [28832/60000]\n",
            "[Epoch: 82/100] Loss: 0.098603  [32032/60000]\n",
            "[Epoch: 82/100] Loss: 0.383050  [35232/60000]\n",
            "[Epoch: 82/100] Loss: 0.287534  [38432/60000]\n",
            "[Epoch: 82/100] Loss: 0.062053  [41632/60000]\n",
            "[Epoch: 82/100] Loss: 0.190026  [44832/60000]\n",
            "[Epoch: 82/100] Loss: 0.313767  [48032/60000]\n",
            "[Epoch: 82/100] Loss: 0.038173  [51232/60000]\n",
            "[Epoch: 82/100] Loss: 0.053935  [54432/60000]\n",
            "[Epoch: 82/100] Loss: 0.092896  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.149989 \n",
            "\n",
            "[Epoch: 83/100] Loss: 0.240700  [   32/60000]\n",
            "[Epoch: 83/100] Loss: 0.092799  [ 3232/60000]\n",
            "[Epoch: 83/100] Loss: 0.141866  [ 6432/60000]\n",
            "[Epoch: 83/100] Loss: 0.188028  [ 9632/60000]\n",
            "[Epoch: 83/100] Loss: 0.052146  [12832/60000]\n",
            "[Epoch: 83/100] Loss: 0.108299  [16032/60000]\n",
            "[Epoch: 83/100] Loss: 0.086277  [19232/60000]\n",
            "[Epoch: 83/100] Loss: 0.027033  [22432/60000]\n",
            "[Epoch: 83/100] Loss: 0.271322  [25632/60000]\n",
            "[Epoch: 83/100] Loss: 0.277873  [28832/60000]\n",
            "[Epoch: 83/100] Loss: 0.159232  [32032/60000]\n",
            "[Epoch: 83/100] Loss: 0.062842  [35232/60000]\n",
            "[Epoch: 83/100] Loss: 0.065691  [38432/60000]\n",
            "[Epoch: 83/100] Loss: 0.069711  [41632/60000]\n",
            "[Epoch: 83/100] Loss: 0.097670  [44832/60000]\n",
            "[Epoch: 83/100] Loss: 0.218262  [48032/60000]\n",
            "[Epoch: 83/100] Loss: 0.143382  [51232/60000]\n",
            "[Epoch: 83/100] Loss: 0.171012  [54432/60000]\n",
            "[Epoch: 83/100] Loss: 0.204904  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.149028 \n",
            "\n",
            "[Epoch: 84/100] Loss: 0.151416  [   32/60000]\n",
            "[Epoch: 84/100] Loss: 0.391028  [ 3232/60000]\n",
            "[Epoch: 84/100] Loss: 0.255937  [ 6432/60000]\n",
            "[Epoch: 84/100] Loss: 0.043579  [ 9632/60000]\n",
            "[Epoch: 84/100] Loss: 0.254720  [12832/60000]\n",
            "[Epoch: 84/100] Loss: 0.109300  [16032/60000]\n",
            "[Epoch: 84/100] Loss: 0.094198  [19232/60000]\n",
            "[Epoch: 84/100] Loss: 0.141769  [22432/60000]\n",
            "[Epoch: 84/100] Loss: 0.067735  [25632/60000]\n",
            "[Epoch: 84/100] Loss: 0.165722  [28832/60000]\n",
            "[Epoch: 84/100] Loss: 0.081358  [32032/60000]\n",
            "[Epoch: 84/100] Loss: 0.050221  [35232/60000]\n",
            "[Epoch: 84/100] Loss: 0.104873  [38432/60000]\n",
            "[Epoch: 84/100] Loss: 0.059333  [41632/60000]\n",
            "[Epoch: 84/100] Loss: 0.066780  [44832/60000]\n",
            "[Epoch: 84/100] Loss: 0.035355  [48032/60000]\n",
            "[Epoch: 84/100] Loss: 0.267623  [51232/60000]\n",
            "[Epoch: 84/100] Loss: 0.079200  [54432/60000]\n",
            "[Epoch: 84/100] Loss: 0.084082  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.147339 \n",
            "\n",
            "[Epoch: 85/100] Loss: 0.018428  [   32/60000]\n",
            "[Epoch: 85/100] Loss: 0.161367  [ 3232/60000]\n",
            "[Epoch: 85/100] Loss: 0.201497  [ 6432/60000]\n",
            "[Epoch: 85/100] Loss: 0.196233  [ 9632/60000]\n",
            "[Epoch: 85/100] Loss: 0.272377  [12832/60000]\n",
            "[Epoch: 85/100] Loss: 0.118568  [16032/60000]\n",
            "[Epoch: 85/100] Loss: 0.135753  [19232/60000]\n",
            "[Epoch: 85/100] Loss: 0.085491  [22432/60000]\n",
            "[Epoch: 85/100] Loss: 0.044092  [25632/60000]\n",
            "[Epoch: 85/100] Loss: 0.349098  [28832/60000]\n",
            "[Epoch: 85/100] Loss: 0.106375  [32032/60000]\n",
            "[Epoch: 85/100] Loss: 0.154563  [35232/60000]\n",
            "[Epoch: 85/100] Loss: 0.053880  [38432/60000]\n",
            "[Epoch: 85/100] Loss: 0.139808  [41632/60000]\n",
            "[Epoch: 85/100] Loss: 0.059637  [44832/60000]\n",
            "[Epoch: 85/100] Loss: 0.260744  [48032/60000]\n",
            "[Epoch: 85/100] Loss: 0.025420  [51232/60000]\n",
            "[Epoch: 85/100] Loss: 0.066229  [54432/60000]\n",
            "[Epoch: 85/100] Loss: 0.249692  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.146458 \n",
            "\n",
            "[Epoch: 86/100] Loss: 0.117827  [   32/60000]\n",
            "[Epoch: 86/100] Loss: 0.112420  [ 3232/60000]\n",
            "[Epoch: 86/100] Loss: 0.067499  [ 6432/60000]\n",
            "[Epoch: 86/100] Loss: 0.097632  [ 9632/60000]\n",
            "[Epoch: 86/100] Loss: 0.475543  [12832/60000]\n",
            "[Epoch: 86/100] Loss: 0.110069  [16032/60000]\n",
            "[Epoch: 86/100] Loss: 0.173901  [19232/60000]\n",
            "[Epoch: 86/100] Loss: 0.024247  [22432/60000]\n",
            "[Epoch: 86/100] Loss: 0.063212  [25632/60000]\n",
            "[Epoch: 86/100] Loss: 0.171374  [28832/60000]\n",
            "[Epoch: 86/100] Loss: 0.126680  [32032/60000]\n",
            "[Epoch: 86/100] Loss: 0.114230  [35232/60000]\n",
            "[Epoch: 86/100] Loss: 0.155591  [38432/60000]\n",
            "[Epoch: 86/100] Loss: 0.067472  [41632/60000]\n",
            "[Epoch: 86/100] Loss: 0.033649  [44832/60000]\n",
            "[Epoch: 86/100] Loss: 0.267208  [48032/60000]\n",
            "[Epoch: 86/100] Loss: 0.242544  [51232/60000]\n",
            "[Epoch: 86/100] Loss: 0.068331  [54432/60000]\n",
            "[Epoch: 86/100] Loss: 0.106014  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.145286 \n",
            "\n",
            "[Epoch: 87/100] Loss: 0.104013  [   32/60000]\n",
            "[Epoch: 87/100] Loss: 0.150206  [ 3232/60000]\n",
            "[Epoch: 87/100] Loss: 0.228651  [ 6432/60000]\n",
            "[Epoch: 87/100] Loss: 0.222401  [ 9632/60000]\n",
            "[Epoch: 87/100] Loss: 0.240318  [12832/60000]\n",
            "[Epoch: 87/100] Loss: 0.140267  [16032/60000]\n",
            "[Epoch: 87/100] Loss: 0.153967  [19232/60000]\n",
            "[Epoch: 87/100] Loss: 0.057950  [22432/60000]\n",
            "[Epoch: 87/100] Loss: 0.098669  [25632/60000]\n",
            "[Epoch: 87/100] Loss: 0.250732  [28832/60000]\n",
            "[Epoch: 87/100] Loss: 0.086304  [32032/60000]\n",
            "[Epoch: 87/100] Loss: 0.116139  [35232/60000]\n",
            "[Epoch: 87/100] Loss: 0.148868  [38432/60000]\n",
            "[Epoch: 87/100] Loss: 0.021601  [41632/60000]\n",
            "[Epoch: 87/100] Loss: 0.196926  [44832/60000]\n",
            "[Epoch: 87/100] Loss: 0.101206  [48032/60000]\n",
            "[Epoch: 87/100] Loss: 0.047065  [51232/60000]\n",
            "[Epoch: 87/100] Loss: 0.166977  [54432/60000]\n",
            "[Epoch: 87/100] Loss: 0.198540  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.144098 \n",
            "\n",
            "[Epoch: 88/100] Loss: 0.148036  [   32/60000]\n",
            "[Epoch: 88/100] Loss: 0.186397  [ 3232/60000]\n",
            "[Epoch: 88/100] Loss: 0.116182  [ 6432/60000]\n",
            "[Epoch: 88/100] Loss: 0.135871  [ 9632/60000]\n",
            "[Epoch: 88/100] Loss: 0.308066  [12832/60000]\n",
            "[Epoch: 88/100] Loss: 0.310202  [16032/60000]\n",
            "[Epoch: 88/100] Loss: 0.082392  [19232/60000]\n",
            "[Epoch: 88/100] Loss: 0.119366  [22432/60000]\n",
            "[Epoch: 88/100] Loss: 0.136841  [25632/60000]\n",
            "[Epoch: 88/100] Loss: 0.187252  [28832/60000]\n",
            "[Epoch: 88/100] Loss: 0.217847  [32032/60000]\n",
            "[Epoch: 88/100] Loss: 0.107417  [35232/60000]\n",
            "[Epoch: 88/100] Loss: 0.075313  [38432/60000]\n",
            "[Epoch: 88/100] Loss: 0.107382  [41632/60000]\n",
            "[Epoch: 88/100] Loss: 0.133013  [44832/60000]\n",
            "[Epoch: 88/100] Loss: 0.067860  [48032/60000]\n",
            "[Epoch: 88/100] Loss: 0.233146  [51232/60000]\n",
            "[Epoch: 88/100] Loss: 0.144870  [54432/60000]\n",
            "[Epoch: 88/100] Loss: 0.739063  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.142782 \n",
            "\n",
            "[Epoch: 89/100] Loss: 0.218573  [   32/60000]\n",
            "[Epoch: 89/100] Loss: 0.042761  [ 3232/60000]\n",
            "[Epoch: 89/100] Loss: 0.033604  [ 6432/60000]\n",
            "[Epoch: 89/100] Loss: 0.196125  [ 9632/60000]\n",
            "[Epoch: 89/100] Loss: 0.051344  [12832/60000]\n",
            "[Epoch: 89/100] Loss: 0.062249  [16032/60000]\n",
            "[Epoch: 89/100] Loss: 0.100174  [19232/60000]\n",
            "[Epoch: 89/100] Loss: 0.051270  [22432/60000]\n",
            "[Epoch: 89/100] Loss: 0.176721  [25632/60000]\n",
            "[Epoch: 89/100] Loss: 0.076138  [28832/60000]\n",
            "[Epoch: 89/100] Loss: 0.046748  [32032/60000]\n",
            "[Epoch: 89/100] Loss: 0.097610  [35232/60000]\n",
            "[Epoch: 89/100] Loss: 0.103180  [38432/60000]\n",
            "[Epoch: 89/100] Loss: 0.076849  [41632/60000]\n",
            "[Epoch: 89/100] Loss: 0.101776  [44832/60000]\n",
            "[Epoch: 89/100] Loss: 0.151763  [48032/60000]\n",
            "[Epoch: 89/100] Loss: 0.138335  [51232/60000]\n",
            "[Epoch: 89/100] Loss: 0.162268  [54432/60000]\n",
            "[Epoch: 89/100] Loss: 0.250408  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.141188 \n",
            "\n",
            "[Epoch: 90/100] Loss: 0.105199  [   32/60000]\n",
            "[Epoch: 90/100] Loss: 0.078225  [ 3232/60000]\n",
            "[Epoch: 90/100] Loss: 0.200982  [ 6432/60000]\n",
            "[Epoch: 90/100] Loss: 0.104691  [ 9632/60000]\n",
            "[Epoch: 90/100] Loss: 0.112135  [12832/60000]\n",
            "[Epoch: 90/100] Loss: 0.329567  [16032/60000]\n",
            "[Epoch: 90/100] Loss: 0.231882  [19232/60000]\n",
            "[Epoch: 90/100] Loss: 0.092230  [22432/60000]\n",
            "[Epoch: 90/100] Loss: 0.035286  [25632/60000]\n",
            "[Epoch: 90/100] Loss: 0.141067  [28832/60000]\n",
            "[Epoch: 90/100] Loss: 0.047010  [32032/60000]\n",
            "[Epoch: 90/100] Loss: 0.041866  [35232/60000]\n",
            "[Epoch: 90/100] Loss: 0.069418  [38432/60000]\n",
            "[Epoch: 90/100] Loss: 0.118880  [41632/60000]\n",
            "[Epoch: 90/100] Loss: 0.209447  [44832/60000]\n",
            "[Epoch: 90/100] Loss: 0.075367  [48032/60000]\n",
            "[Epoch: 90/100] Loss: 0.178895  [51232/60000]\n",
            "[Epoch: 90/100] Loss: 0.380466  [54432/60000]\n",
            "[Epoch: 90/100] Loss: 0.133866  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.140539 \n",
            "\n",
            "[Epoch: 91/100] Loss: 0.244300  [   32/60000]\n",
            "[Epoch: 91/100] Loss: 0.075738  [ 3232/60000]\n",
            "[Epoch: 91/100] Loss: 0.043272  [ 6432/60000]\n",
            "[Epoch: 91/100] Loss: 0.101908  [ 9632/60000]\n",
            "[Epoch: 91/100] Loss: 0.049648  [12832/60000]\n",
            "[Epoch: 91/100] Loss: 0.255124  [16032/60000]\n",
            "[Epoch: 91/100] Loss: 0.057856  [19232/60000]\n",
            "[Epoch: 91/100] Loss: 0.105857  [22432/60000]\n",
            "[Epoch: 91/100] Loss: 0.420903  [25632/60000]\n",
            "[Epoch: 91/100] Loss: 0.128834  [28832/60000]\n",
            "[Epoch: 91/100] Loss: 0.352076  [32032/60000]\n",
            "[Epoch: 91/100] Loss: 0.293536  [35232/60000]\n",
            "[Epoch: 91/100] Loss: 0.033215  [38432/60000]\n",
            "[Epoch: 91/100] Loss: 0.110238  [41632/60000]\n",
            "[Epoch: 91/100] Loss: 0.090049  [44832/60000]\n",
            "[Epoch: 91/100] Loss: 0.144015  [48032/60000]\n",
            "[Epoch: 91/100] Loss: 0.064855  [51232/60000]\n",
            "[Epoch: 91/100] Loss: 0.079941  [54432/60000]\n",
            "[Epoch: 91/100] Loss: 0.106675  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.139400 \n",
            "\n",
            "[Epoch: 92/100] Loss: 0.136175  [   32/60000]\n",
            "[Epoch: 92/100] Loss: 0.114869  [ 3232/60000]\n",
            "[Epoch: 92/100] Loss: 0.258900  [ 6432/60000]\n",
            "[Epoch: 92/100] Loss: 0.079506  [ 9632/60000]\n",
            "[Epoch: 92/100] Loss: 0.080953  [12832/60000]\n",
            "[Epoch: 92/100] Loss: 0.563366  [16032/60000]\n",
            "[Epoch: 92/100] Loss: 0.092508  [19232/60000]\n",
            "[Epoch: 92/100] Loss: 0.099207  [22432/60000]\n",
            "[Epoch: 92/100] Loss: 0.058459  [25632/60000]\n",
            "[Epoch: 92/100] Loss: 0.108847  [28832/60000]\n",
            "[Epoch: 92/100] Loss: 0.063350  [32032/60000]\n",
            "[Epoch: 92/100] Loss: 0.179278  [35232/60000]\n",
            "[Epoch: 92/100] Loss: 0.071184  [38432/60000]\n",
            "[Epoch: 92/100] Loss: 0.486095  [41632/60000]\n",
            "[Epoch: 92/100] Loss: 0.238052  [44832/60000]\n",
            "[Epoch: 92/100] Loss: 0.181835  [48032/60000]\n",
            "[Epoch: 92/100] Loss: 0.058627  [51232/60000]\n",
            "[Epoch: 92/100] Loss: 0.289021  [54432/60000]\n",
            "[Epoch: 92/100] Loss: 0.221818  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.138633 \n",
            "\n",
            "[Epoch: 93/100] Loss: 0.243225  [   32/60000]\n",
            "[Epoch: 93/100] Loss: 0.165502  [ 3232/60000]\n",
            "[Epoch: 93/100] Loss: 0.045406  [ 6432/60000]\n",
            "[Epoch: 93/100] Loss: 0.518101  [ 9632/60000]\n",
            "[Epoch: 93/100] Loss: 0.110613  [12832/60000]\n",
            "[Epoch: 93/100] Loss: 0.084168  [16032/60000]\n",
            "[Epoch: 93/100] Loss: 0.049563  [19232/60000]\n",
            "[Epoch: 93/100] Loss: 0.104507  [22432/60000]\n",
            "[Epoch: 93/100] Loss: 0.156769  [25632/60000]\n",
            "[Epoch: 93/100] Loss: 0.153535  [28832/60000]\n",
            "[Epoch: 93/100] Loss: 0.006211  [32032/60000]\n",
            "[Epoch: 93/100] Loss: 0.062529  [35232/60000]\n",
            "[Epoch: 93/100] Loss: 0.061555  [38432/60000]\n",
            "[Epoch: 93/100] Loss: 0.079827  [41632/60000]\n",
            "[Epoch: 93/100] Loss: 0.249010  [44832/60000]\n",
            "[Epoch: 93/100] Loss: 0.043962  [48032/60000]\n",
            "[Epoch: 93/100] Loss: 0.084734  [51232/60000]\n",
            "[Epoch: 93/100] Loss: 0.093141  [54432/60000]\n",
            "[Epoch: 93/100] Loss: 0.104923  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.137375 \n",
            "\n",
            "[Epoch: 94/100] Loss: 0.118885  [   32/60000]\n",
            "[Epoch: 94/100] Loss: 0.095608  [ 3232/60000]\n",
            "[Epoch: 94/100] Loss: 0.048219  [ 6432/60000]\n",
            "[Epoch: 94/100] Loss: 0.174874  [ 9632/60000]\n",
            "[Epoch: 94/100] Loss: 0.176872  [12832/60000]\n",
            "[Epoch: 94/100] Loss: 0.206330  [16032/60000]\n",
            "[Epoch: 94/100] Loss: 0.034644  [19232/60000]\n",
            "[Epoch: 94/100] Loss: 0.065508  [22432/60000]\n",
            "[Epoch: 94/100] Loss: 0.037113  [25632/60000]\n",
            "[Epoch: 94/100] Loss: 0.070972  [28832/60000]\n",
            "[Epoch: 94/100] Loss: 0.073521  [32032/60000]\n",
            "[Epoch: 94/100] Loss: 0.019687  [35232/60000]\n",
            "[Epoch: 94/100] Loss: 0.046877  [38432/60000]\n",
            "[Epoch: 94/100] Loss: 0.269584  [41632/60000]\n",
            "[Epoch: 94/100] Loss: 0.056936  [44832/60000]\n",
            "[Epoch: 94/100] Loss: 0.143763  [48032/60000]\n",
            "[Epoch: 94/100] Loss: 0.047398  [51232/60000]\n",
            "[Epoch: 94/100] Loss: 0.026743  [54432/60000]\n",
            "[Epoch: 94/100] Loss: 0.184405  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.136367 \n",
            "\n",
            "[Epoch: 95/100] Loss: 0.092710  [   32/60000]\n",
            "[Epoch: 95/100] Loss: 0.228742  [ 3232/60000]\n",
            "[Epoch: 95/100] Loss: 0.186930  [ 6432/60000]\n",
            "[Epoch: 95/100] Loss: 0.052820  [ 9632/60000]\n",
            "[Epoch: 95/100] Loss: 0.071260  [12832/60000]\n",
            "[Epoch: 95/100] Loss: 0.094152  [16032/60000]\n",
            "[Epoch: 95/100] Loss: 0.081711  [19232/60000]\n",
            "[Epoch: 95/100] Loss: 0.084907  [22432/60000]\n",
            "[Epoch: 95/100] Loss: 0.130774  [25632/60000]\n",
            "[Epoch: 95/100] Loss: 0.185986  [28832/60000]\n",
            "[Epoch: 95/100] Loss: 0.138405  [32032/60000]\n",
            "[Epoch: 95/100] Loss: 0.103039  [35232/60000]\n",
            "[Epoch: 95/100] Loss: 0.028487  [38432/60000]\n",
            "[Epoch: 95/100] Loss: 0.092536  [41632/60000]\n",
            "[Epoch: 95/100] Loss: 0.148298  [44832/60000]\n",
            "[Epoch: 95/100] Loss: 0.283840  [48032/60000]\n",
            "[Epoch: 95/100] Loss: 0.201067  [51232/60000]\n",
            "[Epoch: 95/100] Loss: 0.069068  [54432/60000]\n",
            "[Epoch: 95/100] Loss: 0.031024  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.135213 \n",
            "\n",
            "[Epoch: 96/100] Loss: 0.033115  [   32/60000]\n",
            "[Epoch: 96/100] Loss: 0.182147  [ 3232/60000]\n",
            "[Epoch: 96/100] Loss: 0.097395  [ 6432/60000]\n",
            "[Epoch: 96/100] Loss: 0.174550  [ 9632/60000]\n",
            "[Epoch: 96/100] Loss: 0.017312  [12832/60000]\n",
            "[Epoch: 96/100] Loss: 0.054021  [16032/60000]\n",
            "[Epoch: 96/100] Loss: 0.048516  [19232/60000]\n",
            "[Epoch: 96/100] Loss: 0.023904  [22432/60000]\n",
            "[Epoch: 96/100] Loss: 0.268744  [25632/60000]\n",
            "[Epoch: 96/100] Loss: 0.051338  [28832/60000]\n",
            "[Epoch: 96/100] Loss: 0.081173  [32032/60000]\n",
            "[Epoch: 96/100] Loss: 0.227833  [35232/60000]\n",
            "[Epoch: 96/100] Loss: 0.564830  [38432/60000]\n",
            "[Epoch: 96/100] Loss: 0.107653  [41632/60000]\n",
            "[Epoch: 96/100] Loss: 0.103494  [44832/60000]\n",
            "[Epoch: 96/100] Loss: 0.167144  [48032/60000]\n",
            "[Epoch: 96/100] Loss: 0.118814  [51232/60000]\n",
            "[Epoch: 96/100] Loss: 0.039836  [54432/60000]\n",
            "[Epoch: 96/100] Loss: 0.132100  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133693 \n",
            "\n",
            "[Epoch: 97/100] Loss: 0.118772  [   32/60000]\n",
            "[Epoch: 97/100] Loss: 0.380172  [ 3232/60000]\n",
            "[Epoch: 97/100] Loss: 0.208643  [ 6432/60000]\n",
            "[Epoch: 97/100] Loss: 0.072167  [ 9632/60000]\n",
            "[Epoch: 97/100] Loss: 0.123151  [12832/60000]\n",
            "[Epoch: 97/100] Loss: 0.023822  [16032/60000]\n",
            "[Epoch: 97/100] Loss: 0.057709  [19232/60000]\n",
            "[Epoch: 97/100] Loss: 0.168528  [22432/60000]\n",
            "[Epoch: 97/100] Loss: 0.052263  [25632/60000]\n",
            "[Epoch: 97/100] Loss: 0.125105  [28832/60000]\n",
            "[Epoch: 97/100] Loss: 0.154842  [32032/60000]\n",
            "[Epoch: 97/100] Loss: 0.089653  [35232/60000]\n",
            "[Epoch: 97/100] Loss: 0.096129  [38432/60000]\n",
            "[Epoch: 97/100] Loss: 0.063938  [41632/60000]\n",
            "[Epoch: 97/100] Loss: 0.099519  [44832/60000]\n",
            "[Epoch: 97/100] Loss: 0.015565  [48032/60000]\n",
            "[Epoch: 97/100] Loss: 0.034355  [51232/60000]\n",
            "[Epoch: 97/100] Loss: 0.021989  [54432/60000]\n",
            "[Epoch: 97/100] Loss: 0.071546  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133017 \n",
            "\n",
            "[Epoch: 98/100] Loss: 0.154740  [   32/60000]\n",
            "[Epoch: 98/100] Loss: 0.189833  [ 3232/60000]\n",
            "[Epoch: 98/100] Loss: 0.089934  [ 6432/60000]\n",
            "[Epoch: 98/100] Loss: 0.161882  [ 9632/60000]\n",
            "[Epoch: 98/100] Loss: 0.144027  [12832/60000]\n",
            "[Epoch: 98/100] Loss: 0.041510  [16032/60000]\n",
            "[Epoch: 98/100] Loss: 0.064002  [19232/60000]\n",
            "[Epoch: 98/100] Loss: 0.291084  [22432/60000]\n",
            "[Epoch: 98/100] Loss: 0.072402  [25632/60000]\n",
            "[Epoch: 98/100] Loss: 0.022640  [28832/60000]\n",
            "[Epoch: 98/100] Loss: 0.042958  [32032/60000]\n",
            "[Epoch: 98/100] Loss: 0.057251  [35232/60000]\n",
            "[Epoch: 98/100] Loss: 0.186197  [38432/60000]\n",
            "[Epoch: 98/100] Loss: 0.030006  [41632/60000]\n",
            "[Epoch: 98/100] Loss: 0.250632  [44832/60000]\n",
            "[Epoch: 98/100] Loss: 0.303845  [48032/60000]\n",
            "[Epoch: 98/100] Loss: 0.191536  [51232/60000]\n",
            "[Epoch: 98/100] Loss: 0.192433  [54432/60000]\n",
            "[Epoch: 98/100] Loss: 0.049404  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.132042 \n",
            "\n",
            "[Epoch: 99/100] Loss: 0.048214  [   32/60000]\n",
            "[Epoch: 99/100] Loss: 0.061918  [ 3232/60000]\n",
            "[Epoch: 99/100] Loss: 0.018241  [ 6432/60000]\n",
            "[Epoch: 99/100] Loss: 0.147091  [ 9632/60000]\n",
            "[Epoch: 99/100] Loss: 0.075070  [12832/60000]\n",
            "[Epoch: 99/100] Loss: 0.093053  [16032/60000]\n",
            "[Epoch: 99/100] Loss: 0.072059  [19232/60000]\n",
            "[Epoch: 99/100] Loss: 0.112745  [22432/60000]\n",
            "[Epoch: 99/100] Loss: 0.214903  [25632/60000]\n",
            "[Epoch: 99/100] Loss: 0.144850  [28832/60000]\n",
            "[Epoch: 99/100] Loss: 0.091066  [32032/60000]\n",
            "[Epoch: 99/100] Loss: 0.144785  [35232/60000]\n",
            "[Epoch: 99/100] Loss: 0.190069  [38432/60000]\n",
            "[Epoch: 99/100] Loss: 0.188459  [41632/60000]\n",
            "[Epoch: 99/100] Loss: 0.082430  [44832/60000]\n",
            "[Epoch: 99/100] Loss: 0.069090  [48032/60000]\n",
            "[Epoch: 99/100] Loss: 0.050966  [51232/60000]\n",
            "[Epoch: 99/100] Loss: 0.146367  [54432/60000]\n",
            "[Epoch: 99/100] Loss: 0.111363  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.131890 \n",
            "\n",
            "[Epoch: 100/100] Loss: 0.130264  [   32/60000]\n",
            "[Epoch: 100/100] Loss: 0.139892  [ 3232/60000]\n",
            "[Epoch: 100/100] Loss: 0.048691  [ 6432/60000]\n",
            "[Epoch: 100/100] Loss: 0.062379  [ 9632/60000]\n",
            "[Epoch: 100/100] Loss: 0.082836  [12832/60000]\n",
            "[Epoch: 100/100] Loss: 0.009615  [16032/60000]\n",
            "[Epoch: 100/100] Loss: 0.049455  [19232/60000]\n",
            "[Epoch: 100/100] Loss: 0.300494  [22432/60000]\n",
            "[Epoch: 100/100] Loss: 0.268365  [25632/60000]\n",
            "[Epoch: 100/100] Loss: 0.076866  [28832/60000]\n",
            "[Epoch: 100/100] Loss: 0.272052  [32032/60000]\n",
            "[Epoch: 100/100] Loss: 0.069135  [35232/60000]\n",
            "[Epoch: 100/100] Loss: 0.215107  [38432/60000]\n",
            "[Epoch: 100/100] Loss: 0.137071  [41632/60000]\n",
            "[Epoch: 100/100] Loss: 0.073251  [44832/60000]\n",
            "[Epoch: 100/100] Loss: 0.027922  [48032/60000]\n",
            "[Epoch: 100/100] Loss: 0.168701  [51232/60000]\n",
            "[Epoch: 100/100] Loss: 0.097958  [54432/60000]\n",
            "[Epoch: 100/100] Loss: 0.278878  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.130444 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Net().to(device)\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "tolerance = 5\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "model.to(device)\n",
        "best_train_loss = float(\"inf\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    # training loop\n",
        "    for batch, (X, y) in enumerate(train_data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * BATCH_SIZE + len(X)\n",
        "            print(f\"[Epoch: {epoch+1}/{NUM_EPOCHS}] Loss: {loss:>7f}  [{current:>5d}/{len(train_data_loader.dataset):>5d}]\")\n",
        "\n",
        "\n",
        "    # eval loop\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            logits = model(X)\n",
        "            loss = criterion(logits, y)\n",
        "            test_loss += loss.item()\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    test_loss /= len(test_data_loader)\n",
        "    correct /= len(test_data_loader.dataset)\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if test_loss < best_train_loss:\n",
        "        best_train_loss = test_loss\n",
        "    else:\n",
        "        tolerance -= 1\n",
        "        if tolerance == 0:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdFYzC50KZZE"
      },
      "source": [
        "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzG-pn3CKZZE"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")"
      ],
      "metadata": {
        "id": "01nchDeFpiAB",
        "outputId": "8de2d592-48cd-483d-e187-d894c601ebe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-vIxT1ItKZZE"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "L9nEQ4VtKZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af03889-768a-4a18-927c-5df7799e3a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.96617\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "771UGdQSKZZF"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "e75zqgxoKZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b54e87-75d8-4238-dfe5-eb1f8847a7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9622\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI10zPNXKZZG"
      },
      "source": [
        "Проверка, что пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "H-ziy_kqKZZG"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU8RegyvKZZG"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DorianGrayPicture/yandex_ml_trainings_season_3.git"
      ],
      "metadata": {
        "id": "SjadCA4hjYqd",
        "outputId": "4a668f48-8fb1-4400-e722-ce8af5074b4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yandex_ml_trainings_season_3'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 27 (delta 8), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (27/27), 542.37 KiB | 3.21 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/yandex_ml_trainings_season_3/hw01_classification/\")"
      ],
      "metadata": {
        "id": "sEllSMPy6z3J"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ayxM_rn6KZZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346e9553-46d8-4e23-8c66-cab6ab47a73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_mnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "assert os.path.exists('hw_mnist_data_dict.npy'), 'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "loaded_data_dict = np.load('hw_mnist_data_dict.npy', allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
        "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
        "}\n",
        "\n",
        "with open('submission_dict_mnist_task_1.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict_mnist_task_1.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B3xgIcSKZZG"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuN81tNjKZZH"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}