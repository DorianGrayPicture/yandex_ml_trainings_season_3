{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vp9qtF5aq7Ra"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8KBN8KRq7Ra"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIjeh_Ghq7Rb",
        "outputId": "58c2cf24-e1ed-4f50-fa79-414b5e1858b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 22:36:41--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-09 22:36:41--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-04-09 22:36:42 (80.3 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tdc6FrBhq7Rb"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4-dP0yWZq7Rc"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuHL_1-Ys0Np",
        "outputId": "f1aebf7d-26f4-40fd-8cbc-87103cf57876"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "aYcL28OsgSq8",
        "outputId": "dfbf42bc-2cac-4038-ad29-85b27e56c8d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.88MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 9')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "0ajOjpkOs6Fi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_fmnist_data.transforms = train_transforms"
      ],
      "metadata": {
        "id": "f8GGHADiuJTG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = resnet18(num_classes=10)\n",
        "model_task_1.conv1 = nn.Conv2d(\n",
        "    in_channels=1,\n",
        "    out_channels=64,\n",
        "    kernel_size=(7, 7),\n",
        "    stride=(2, 2),\n",
        "    padding=(3, 3),\n",
        "    bias=False\n",
        ")\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5a875a69-0d96-43a7-fee2-ff637ae88edc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 0.1\n",
        "WEIGHT_DECAY = 1e-5\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "tolerance = 5\n",
        "\n",
        "optimizer = torch.optim.SGD(model_task_1.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "best_train_loss = float(\"inf\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    model_task_1.train()\n",
        "\n",
        "    # training loop\n",
        "    for batch, (X, y) in enumerate(train_data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        logits = model_task_1(X)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * BATCH_SIZE + len(X)\n",
        "            print(f\"[Epoch: {epoch+1}/{NUM_EPOCHS}] Loss: {loss:>7f}  [{current:>5d}/{len(train_data_loader.dataset):>5d}]\")\n",
        "\n",
        "\n",
        "    # eval loop\n",
        "    model_task_1.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            logits = model_task_1(X)\n",
        "            loss = criterion(logits, y)\n",
        "            test_loss += loss.item()\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    test_loss /= len(test_data_loader)\n",
        "    correct /= len(test_data_loader.dataset)\n",
        "\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if test_loss < best_train_loss:\n",
        "        best_train_loss = test_loss\n",
        "        tolerance = 5\n",
        "    else:\n",
        "        tolerance -= 1\n",
        "        if tolerance == 0:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Qivt2OvbDG",
        "outputId": "980775c4-2af6-4786-edaa-a09ec3087112"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1/100] Loss: 2.453789  [   32/60000]\n",
            "[Epoch: 1/100] Loss: 2.194788  [12832/60000]\n",
            "[Epoch: 1/100] Loss: 0.734085  [25632/60000]\n",
            "[Epoch: 1/100] Loss: 0.797986  [38432/60000]\n",
            "[Epoch: 1/100] Loss: 0.765464  [51232/60000]\n",
            "[Epoch: 1/100] Loss: 0.811702  [64032/60000]\n",
            "[Epoch: 1/100] Loss: 0.607830  [76832/60000]\n",
            "[Epoch: 1/100] Loss: 0.563075  [89632/60000]\n",
            "[Epoch: 1/100] Loss: 0.805900  [102432/60000]\n",
            "[Epoch: 1/100] Loss: 0.451864  [115232/60000]\n",
            "[Epoch: 1/100] Loss: 0.496525  [128032/60000]\n",
            "[Epoch: 1/100] Loss: 0.380705  [140832/60000]\n",
            "[Epoch: 1/100] Loss: 0.642318  [153632/60000]\n",
            "[Epoch: 1/100] Loss: 0.407152  [166432/60000]\n",
            "[Epoch: 1/100] Loss: 0.299366  [179232/60000]\n",
            "[Epoch: 1/100] Loss: 0.249200  [192032/60000]\n",
            "[Epoch: 1/100] Loss: 0.600172  [204832/60000]\n",
            "[Epoch: 1/100] Loss: 0.261000  [217632/60000]\n",
            "[Epoch: 1/100] Loss: 0.635147  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.454384 \n",
            "\n",
            "[Epoch: 2/100] Loss: 0.359974  [   32/60000]\n",
            "[Epoch: 2/100] Loss: 0.298197  [12832/60000]\n",
            "[Epoch: 2/100] Loss: 0.191356  [25632/60000]\n",
            "[Epoch: 2/100] Loss: 0.334491  [38432/60000]\n",
            "[Epoch: 2/100] Loss: 0.505858  [51232/60000]\n",
            "[Epoch: 2/100] Loss: 0.363830  [64032/60000]\n",
            "[Epoch: 2/100] Loss: 0.380951  [76832/60000]\n",
            "[Epoch: 2/100] Loss: 0.219715  [89632/60000]\n",
            "[Epoch: 2/100] Loss: 0.769837  [102432/60000]\n",
            "[Epoch: 2/100] Loss: 0.757846  [115232/60000]\n",
            "[Epoch: 2/100] Loss: 0.410020  [128032/60000]\n",
            "[Epoch: 2/100] Loss: 0.295671  [140832/60000]\n",
            "[Epoch: 2/100] Loss: 0.456099  [153632/60000]\n",
            "[Epoch: 2/100] Loss: 0.475639  [166432/60000]\n",
            "[Epoch: 2/100] Loss: 0.325475  [179232/60000]\n",
            "[Epoch: 2/100] Loss: 0.549691  [192032/60000]\n",
            "[Epoch: 2/100] Loss: 0.410025  [204832/60000]\n",
            "[Epoch: 2/100] Loss: 0.397795  [217632/60000]\n",
            "[Epoch: 2/100] Loss: 0.489864  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.443806 \n",
            "\n",
            "[Epoch: 3/100] Loss: 0.783878  [   32/60000]\n",
            "[Epoch: 3/100] Loss: 0.840787  [12832/60000]\n",
            "[Epoch: 3/100] Loss: 0.205841  [25632/60000]\n",
            "[Epoch: 3/100] Loss: 0.409926  [38432/60000]\n",
            "[Epoch: 3/100] Loss: 0.500841  [51232/60000]\n",
            "[Epoch: 3/100] Loss: 0.514508  [64032/60000]\n",
            "[Epoch: 3/100] Loss: 0.495566  [76832/60000]\n",
            "[Epoch: 3/100] Loss: 0.317019  [89632/60000]\n",
            "[Epoch: 3/100] Loss: 0.760171  [102432/60000]\n",
            "[Epoch: 3/100] Loss: 0.200206  [115232/60000]\n",
            "[Epoch: 3/100] Loss: 0.484189  [128032/60000]\n",
            "[Epoch: 3/100] Loss: 0.219608  [140832/60000]\n",
            "[Epoch: 3/100] Loss: 0.438934  [153632/60000]\n",
            "[Epoch: 3/100] Loss: 0.317696  [166432/60000]\n",
            "[Epoch: 3/100] Loss: 0.277395  [179232/60000]\n",
            "[Epoch: 3/100] Loss: 0.223816  [192032/60000]\n",
            "[Epoch: 3/100] Loss: 0.253158  [204832/60000]\n",
            "[Epoch: 3/100] Loss: 0.370526  [217632/60000]\n",
            "[Epoch: 3/100] Loss: 0.351385  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.379693 \n",
            "\n",
            "[Epoch: 4/100] Loss: 0.526936  [   32/60000]\n",
            "[Epoch: 4/100] Loss: 0.588904  [12832/60000]\n",
            "[Epoch: 4/100] Loss: 0.416804  [25632/60000]\n",
            "[Epoch: 4/100] Loss: 0.623052  [38432/60000]\n",
            "[Epoch: 4/100] Loss: 0.299961  [51232/60000]\n",
            "[Epoch: 4/100] Loss: 0.298963  [64032/60000]\n",
            "[Epoch: 4/100] Loss: 0.294976  [76832/60000]\n",
            "[Epoch: 4/100] Loss: 0.259074  [89632/60000]\n",
            "[Epoch: 4/100] Loss: 0.368784  [102432/60000]\n",
            "[Epoch: 4/100] Loss: 0.606446  [115232/60000]\n",
            "[Epoch: 4/100] Loss: 0.537859  [128032/60000]\n",
            "[Epoch: 4/100] Loss: 0.151488  [140832/60000]\n",
            "[Epoch: 4/100] Loss: 0.490960  [153632/60000]\n",
            "[Epoch: 4/100] Loss: 0.701844  [166432/60000]\n",
            "[Epoch: 4/100] Loss: 0.328172  [179232/60000]\n",
            "[Epoch: 4/100] Loss: 0.496215  [192032/60000]\n",
            "[Epoch: 4/100] Loss: 0.452012  [204832/60000]\n",
            "[Epoch: 4/100] Loss: 0.309664  [217632/60000]\n",
            "[Epoch: 4/100] Loss: 0.220559  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.411582 \n",
            "\n",
            "[Epoch: 5/100] Loss: 0.237481  [   32/60000]\n",
            "[Epoch: 5/100] Loss: 0.249901  [12832/60000]\n",
            "[Epoch: 5/100] Loss: 0.482446  [25632/60000]\n",
            "[Epoch: 5/100] Loss: 0.271454  [38432/60000]\n",
            "[Epoch: 5/100] Loss: 0.351470  [51232/60000]\n",
            "[Epoch: 5/100] Loss: 0.434203  [64032/60000]\n",
            "[Epoch: 5/100] Loss: 0.356879  [76832/60000]\n",
            "[Epoch: 5/100] Loss: 0.585347  [89632/60000]\n",
            "[Epoch: 5/100] Loss: 0.245953  [102432/60000]\n",
            "[Epoch: 5/100] Loss: 0.459228  [115232/60000]\n",
            "[Epoch: 5/100] Loss: 0.304865  [128032/60000]\n",
            "[Epoch: 5/100] Loss: 0.331262  [140832/60000]\n",
            "[Epoch: 5/100] Loss: 0.167246  [153632/60000]\n",
            "[Epoch: 5/100] Loss: 0.312160  [166432/60000]\n",
            "[Epoch: 5/100] Loss: 0.235897  [179232/60000]\n",
            "[Epoch: 5/100] Loss: 0.307751  [192032/60000]\n",
            "[Epoch: 5/100] Loss: 0.224108  [204832/60000]\n",
            "[Epoch: 5/100] Loss: 0.392327  [217632/60000]\n",
            "[Epoch: 5/100] Loss: 0.241742  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.421939 \n",
            "\n",
            "[Epoch: 6/100] Loss: 0.262723  [   32/60000]\n",
            "[Epoch: 6/100] Loss: 0.300985  [12832/60000]\n",
            "[Epoch: 6/100] Loss: 0.637530  [25632/60000]\n",
            "[Epoch: 6/100] Loss: 0.465038  [38432/60000]\n",
            "[Epoch: 6/100] Loss: 0.468900  [51232/60000]\n",
            "[Epoch: 6/100] Loss: 0.510680  [64032/60000]\n",
            "[Epoch: 6/100] Loss: 0.459881  [76832/60000]\n",
            "[Epoch: 6/100] Loss: 0.234538  [89632/60000]\n",
            "[Epoch: 6/100] Loss: 0.280818  [102432/60000]\n",
            "[Epoch: 6/100] Loss: 0.413937  [115232/60000]\n",
            "[Epoch: 6/100] Loss: 0.514882  [128032/60000]\n",
            "[Epoch: 6/100] Loss: 0.252966  [140832/60000]\n",
            "[Epoch: 6/100] Loss: 0.359882  [153632/60000]\n",
            "[Epoch: 6/100] Loss: 0.286064  [166432/60000]\n",
            "[Epoch: 6/100] Loss: 0.367915  [179232/60000]\n",
            "[Epoch: 6/100] Loss: 0.201453  [192032/60000]\n",
            "[Epoch: 6/100] Loss: 0.357301  [204832/60000]\n",
            "[Epoch: 6/100] Loss: 0.166260  [217632/60000]\n",
            "[Epoch: 6/100] Loss: 0.316586  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.335608 \n",
            "\n",
            "[Epoch: 7/100] Loss: 0.479195  [   32/60000]\n",
            "[Epoch: 7/100] Loss: 0.295813  [12832/60000]\n",
            "[Epoch: 7/100] Loss: 0.170528  [25632/60000]\n",
            "[Epoch: 7/100] Loss: 0.438411  [38432/60000]\n",
            "[Epoch: 7/100] Loss: 0.376149  [51232/60000]\n",
            "[Epoch: 7/100] Loss: 0.480532  [64032/60000]\n",
            "[Epoch: 7/100] Loss: 0.341868  [76832/60000]\n",
            "[Epoch: 7/100] Loss: 0.363353  [89632/60000]\n",
            "[Epoch: 7/100] Loss: 0.243214  [102432/60000]\n",
            "[Epoch: 7/100] Loss: 0.372261  [115232/60000]\n",
            "[Epoch: 7/100] Loss: 0.405930  [128032/60000]\n",
            "[Epoch: 7/100] Loss: 0.366729  [140832/60000]\n",
            "[Epoch: 7/100] Loss: 0.403196  [153632/60000]\n",
            "[Epoch: 7/100] Loss: 0.223754  [166432/60000]\n",
            "[Epoch: 7/100] Loss: 0.403853  [179232/60000]\n",
            "[Epoch: 7/100] Loss: 0.528667  [192032/60000]\n",
            "[Epoch: 7/100] Loss: 0.627129  [204832/60000]\n",
            "[Epoch: 7/100] Loss: 0.282430  [217632/60000]\n",
            "[Epoch: 7/100] Loss: 0.391549  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.357152 \n",
            "\n",
            "[Epoch: 8/100] Loss: 0.165013  [   32/60000]\n",
            "[Epoch: 8/100] Loss: 0.121738  [12832/60000]\n",
            "[Epoch: 8/100] Loss: 0.315975  [25632/60000]\n",
            "[Epoch: 8/100] Loss: 0.275905  [38432/60000]\n",
            "[Epoch: 8/100] Loss: 0.271113  [51232/60000]\n",
            "[Epoch: 8/100] Loss: 0.534382  [64032/60000]\n",
            "[Epoch: 8/100] Loss: 0.178732  [76832/60000]\n",
            "[Epoch: 8/100] Loss: 0.382620  [89632/60000]\n",
            "[Epoch: 8/100] Loss: 0.453828  [102432/60000]\n",
            "[Epoch: 8/100] Loss: 0.452743  [115232/60000]\n",
            "[Epoch: 8/100] Loss: 0.152255  [128032/60000]\n",
            "[Epoch: 8/100] Loss: 0.729732  [140832/60000]\n",
            "[Epoch: 8/100] Loss: 0.506651  [153632/60000]\n",
            "[Epoch: 8/100] Loss: 0.237200  [166432/60000]\n",
            "[Epoch: 8/100] Loss: 0.414963  [179232/60000]\n",
            "[Epoch: 8/100] Loss: 0.890607  [192032/60000]\n",
            "[Epoch: 8/100] Loss: 0.366308  [204832/60000]\n",
            "[Epoch: 8/100] Loss: 0.512013  [217632/60000]\n",
            "[Epoch: 8/100] Loss: 0.447383  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.416862 \n",
            "\n",
            "[Epoch: 9/100] Loss: 0.500075  [   32/60000]\n",
            "[Epoch: 9/100] Loss: 0.427807  [12832/60000]\n",
            "[Epoch: 9/100] Loss: 0.400024  [25632/60000]\n",
            "[Epoch: 9/100] Loss: 0.434171  [38432/60000]\n",
            "[Epoch: 9/100] Loss: 0.436035  [51232/60000]\n",
            "[Epoch: 9/100] Loss: 0.292016  [64032/60000]\n",
            "[Epoch: 9/100] Loss: 0.254582  [76832/60000]\n",
            "[Epoch: 9/100] Loss: 0.398502  [89632/60000]\n",
            "[Epoch: 9/100] Loss: 0.368652  [102432/60000]\n",
            "[Epoch: 9/100] Loss: 0.353543  [115232/60000]\n",
            "[Epoch: 9/100] Loss: 0.916207  [128032/60000]\n",
            "[Epoch: 9/100] Loss: 0.451682  [140832/60000]\n",
            "[Epoch: 9/100] Loss: 0.229563  [153632/60000]\n",
            "[Epoch: 9/100] Loss: 0.320865  [166432/60000]\n",
            "[Epoch: 9/100] Loss: 0.928516  [179232/60000]\n",
            "[Epoch: 9/100] Loss: 0.350843  [192032/60000]\n",
            "[Epoch: 9/100] Loss: 0.219520  [204832/60000]\n",
            "[Epoch: 9/100] Loss: 0.234348  [217632/60000]\n",
            "[Epoch: 9/100] Loss: 0.290560  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.445782 \n",
            "\n",
            "[Epoch: 10/100] Loss: 0.473427  [   32/60000]\n",
            "[Epoch: 10/100] Loss: 0.274616  [12832/60000]\n",
            "[Epoch: 10/100] Loss: 0.287820  [25632/60000]\n",
            "[Epoch: 10/100] Loss: 0.249447  [38432/60000]\n",
            "[Epoch: 10/100] Loss: 0.428820  [51232/60000]\n",
            "[Epoch: 10/100] Loss: 0.262207  [64032/60000]\n",
            "[Epoch: 10/100] Loss: 0.398965  [76832/60000]\n",
            "[Epoch: 10/100] Loss: 0.368925  [89632/60000]\n",
            "[Epoch: 10/100] Loss: 0.410748  [102432/60000]\n",
            "[Epoch: 10/100] Loss: 0.357303  [115232/60000]\n",
            "[Epoch: 10/100] Loss: 0.427179  [128032/60000]\n",
            "[Epoch: 10/100] Loss: 0.217599  [140832/60000]\n",
            "[Epoch: 10/100] Loss: 0.306573  [153632/60000]\n",
            "[Epoch: 10/100] Loss: 0.325562  [166432/60000]\n",
            "[Epoch: 10/100] Loss: 0.385191  [179232/60000]\n",
            "[Epoch: 10/100] Loss: 0.261492  [192032/60000]\n",
            "[Epoch: 10/100] Loss: 0.379036  [204832/60000]\n",
            "[Epoch: 10/100] Loss: 0.374095  [217632/60000]\n",
            "[Epoch: 10/100] Loss: 0.314425  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.338394 \n",
            "\n",
            "[Epoch: 11/100] Loss: 0.272843  [   32/60000]\n",
            "[Epoch: 11/100] Loss: 0.333807  [12832/60000]\n",
            "[Epoch: 11/100] Loss: 0.440315  [25632/60000]\n",
            "[Epoch: 11/100] Loss: 0.311327  [38432/60000]\n",
            "[Epoch: 11/100] Loss: 0.233613  [51232/60000]\n",
            "[Epoch: 11/100] Loss: 0.205941  [64032/60000]\n",
            "[Epoch: 11/100] Loss: 0.306868  [76832/60000]\n",
            "[Epoch: 11/100] Loss: 0.167582  [89632/60000]\n",
            "[Epoch: 11/100] Loss: 0.064597  [102432/60000]\n",
            "[Epoch: 11/100] Loss: 0.289534  [115232/60000]\n",
            "[Epoch: 11/100] Loss: 0.095339  [128032/60000]\n",
            "[Epoch: 11/100] Loss: 0.484431  [140832/60000]\n",
            "[Epoch: 11/100] Loss: 0.101832  [153632/60000]\n",
            "[Epoch: 11/100] Loss: 0.200864  [166432/60000]\n",
            "[Epoch: 11/100] Loss: 0.287395  [179232/60000]\n",
            "[Epoch: 11/100] Loss: 0.381456  [192032/60000]\n",
            "[Epoch: 11/100] Loss: 0.167571  [204832/60000]\n",
            "[Epoch: 11/100] Loss: 0.110525  [217632/60000]\n",
            "[Epoch: 11/100] Loss: 0.230250  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.262443 \n",
            "\n",
            "[Epoch: 12/100] Loss: 0.206608  [   32/60000]\n",
            "[Epoch: 12/100] Loss: 0.169501  [12832/60000]\n",
            "[Epoch: 12/100] Loss: 0.329337  [25632/60000]\n",
            "[Epoch: 12/100] Loss: 0.236008  [38432/60000]\n",
            "[Epoch: 12/100] Loss: 0.196811  [51232/60000]\n",
            "[Epoch: 12/100] Loss: 0.256651  [64032/60000]\n",
            "[Epoch: 12/100] Loss: 0.216378  [76832/60000]\n",
            "[Epoch: 12/100] Loss: 0.325459  [89632/60000]\n",
            "[Epoch: 12/100] Loss: 0.148244  [102432/60000]\n",
            "[Epoch: 12/100] Loss: 0.335068  [115232/60000]\n",
            "[Epoch: 12/100] Loss: 0.106160  [128032/60000]\n",
            "[Epoch: 12/100] Loss: 0.185786  [140832/60000]\n",
            "[Epoch: 12/100] Loss: 0.289711  [153632/60000]\n",
            "[Epoch: 12/100] Loss: 0.404216  [166432/60000]\n",
            "[Epoch: 12/100] Loss: 0.077789  [179232/60000]\n",
            "[Epoch: 12/100] Loss: 0.101026  [192032/60000]\n",
            "[Epoch: 12/100] Loss: 0.149008  [204832/60000]\n",
            "[Epoch: 12/100] Loss: 0.217335  [217632/60000]\n",
            "[Epoch: 12/100] Loss: 0.297846  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.235801 \n",
            "\n",
            "[Epoch: 13/100] Loss: 0.072728  [   32/60000]\n",
            "[Epoch: 13/100] Loss: 0.208437  [12832/60000]\n",
            "[Epoch: 13/100] Loss: 0.214025  [25632/60000]\n",
            "[Epoch: 13/100] Loss: 0.261422  [38432/60000]\n",
            "[Epoch: 13/100] Loss: 0.081955  [51232/60000]\n",
            "[Epoch: 13/100] Loss: 0.322474  [64032/60000]\n",
            "[Epoch: 13/100] Loss: 0.172980  [76832/60000]\n",
            "[Epoch: 13/100] Loss: 0.356868  [89632/60000]\n",
            "[Epoch: 13/100] Loss: 0.353595  [102432/60000]\n",
            "[Epoch: 13/100] Loss: 0.149018  [115232/60000]\n",
            "[Epoch: 13/100] Loss: 0.149030  [128032/60000]\n",
            "[Epoch: 13/100] Loss: 0.107674  [140832/60000]\n",
            "[Epoch: 13/100] Loss: 0.322264  [153632/60000]\n",
            "[Epoch: 13/100] Loss: 0.267262  [166432/60000]\n",
            "[Epoch: 13/100] Loss: 0.476479  [179232/60000]\n",
            "[Epoch: 13/100] Loss: 0.254407  [192032/60000]\n",
            "[Epoch: 13/100] Loss: 0.148028  [204832/60000]\n",
            "[Epoch: 13/100] Loss: 0.130212  [217632/60000]\n",
            "[Epoch: 13/100] Loss: 0.430079  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.251886 \n",
            "\n",
            "[Epoch: 14/100] Loss: 0.124824  [   32/60000]\n",
            "[Epoch: 14/100] Loss: 0.347451  [12832/60000]\n",
            "[Epoch: 14/100] Loss: 0.264513  [25632/60000]\n",
            "[Epoch: 14/100] Loss: 0.299176  [38432/60000]\n",
            "[Epoch: 14/100] Loss: 0.306585  [51232/60000]\n",
            "[Epoch: 14/100] Loss: 0.222673  [64032/60000]\n",
            "[Epoch: 14/100] Loss: 0.114662  [76832/60000]\n",
            "[Epoch: 14/100] Loss: 0.043553  [89632/60000]\n",
            "[Epoch: 14/100] Loss: 0.073686  [102432/60000]\n",
            "[Epoch: 14/100] Loss: 0.130190  [115232/60000]\n",
            "[Epoch: 14/100] Loss: 0.102463  [128032/60000]\n",
            "[Epoch: 14/100] Loss: 0.181193  [140832/60000]\n",
            "[Epoch: 14/100] Loss: 0.175022  [153632/60000]\n",
            "[Epoch: 14/100] Loss: 0.068382  [166432/60000]\n",
            "[Epoch: 14/100] Loss: 0.449755  [179232/60000]\n",
            "[Epoch: 14/100] Loss: 0.152492  [192032/60000]\n",
            "[Epoch: 14/100] Loss: 0.277217  [204832/60000]\n",
            "[Epoch: 14/100] Loss: 0.246997  [217632/60000]\n",
            "[Epoch: 14/100] Loss: 0.101437  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.239911 \n",
            "\n",
            "[Epoch: 15/100] Loss: 0.103718  [   32/60000]\n",
            "[Epoch: 15/100] Loss: 0.069930  [12832/60000]\n",
            "[Epoch: 15/100] Loss: 0.119617  [25632/60000]\n",
            "[Epoch: 15/100] Loss: 0.177538  [38432/60000]\n",
            "[Epoch: 15/100] Loss: 0.114787  [51232/60000]\n",
            "[Epoch: 15/100] Loss: 0.229341  [64032/60000]\n",
            "[Epoch: 15/100] Loss: 0.190435  [76832/60000]\n",
            "[Epoch: 15/100] Loss: 0.134024  [89632/60000]\n",
            "[Epoch: 15/100] Loss: 0.082003  [102432/60000]\n",
            "[Epoch: 15/100] Loss: 0.114167  [115232/60000]\n",
            "[Epoch: 15/100] Loss: 0.126614  [128032/60000]\n",
            "[Epoch: 15/100] Loss: 0.246140  [140832/60000]\n",
            "[Epoch: 15/100] Loss: 0.057396  [153632/60000]\n",
            "[Epoch: 15/100] Loss: 0.148831  [166432/60000]\n",
            "[Epoch: 15/100] Loss: 0.110435  [179232/60000]\n",
            "[Epoch: 15/100] Loss: 0.119132  [192032/60000]\n",
            "[Epoch: 15/100] Loss: 0.228967  [204832/60000]\n",
            "[Epoch: 15/100] Loss: 0.340635  [217632/60000]\n",
            "[Epoch: 15/100] Loss: 0.097720  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.253399 \n",
            "\n",
            "[Epoch: 16/100] Loss: 0.283392  [   32/60000]\n",
            "[Epoch: 16/100] Loss: 0.107107  [12832/60000]\n",
            "[Epoch: 16/100] Loss: 0.405490  [25632/60000]\n",
            "[Epoch: 16/100] Loss: 0.028844  [38432/60000]\n",
            "[Epoch: 16/100] Loss: 0.125997  [51232/60000]\n",
            "[Epoch: 16/100] Loss: 0.137846  [64032/60000]\n",
            "[Epoch: 16/100] Loss: 0.040247  [76832/60000]\n",
            "[Epoch: 16/100] Loss: 0.176361  [89632/60000]\n",
            "[Epoch: 16/100] Loss: 0.247568  [102432/60000]\n",
            "[Epoch: 16/100] Loss: 0.052881  [115232/60000]\n",
            "[Epoch: 16/100] Loss: 0.302438  [128032/60000]\n",
            "[Epoch: 16/100] Loss: 0.116847  [140832/60000]\n",
            "[Epoch: 16/100] Loss: 0.259962  [153632/60000]\n",
            "[Epoch: 16/100] Loss: 0.108440  [166432/60000]\n",
            "[Epoch: 16/100] Loss: 0.087787  [179232/60000]\n",
            "[Epoch: 16/100] Loss: 0.081102  [192032/60000]\n",
            "[Epoch: 16/100] Loss: 0.039506  [204832/60000]\n",
            "[Epoch: 16/100] Loss: 0.440846  [217632/60000]\n",
            "[Epoch: 16/100] Loss: 0.294700  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.240698 \n",
            "\n",
            "[Epoch: 17/100] Loss: 0.127375  [   32/60000]\n",
            "[Epoch: 17/100] Loss: 0.068868  [12832/60000]\n",
            "[Epoch: 17/100] Loss: 0.159177  [25632/60000]\n",
            "[Epoch: 17/100] Loss: 0.051453  [38432/60000]\n",
            "[Epoch: 17/100] Loss: 0.496491  [51232/60000]\n",
            "[Epoch: 17/100] Loss: 0.334258  [64032/60000]\n",
            "[Epoch: 17/100] Loss: 0.115854  [76832/60000]\n",
            "[Epoch: 17/100] Loss: 0.150209  [89632/60000]\n",
            "[Epoch: 17/100] Loss: 0.104065  [102432/60000]\n",
            "[Epoch: 17/100] Loss: 0.070428  [115232/60000]\n",
            "[Epoch: 17/100] Loss: 0.135856  [128032/60000]\n",
            "[Epoch: 17/100] Loss: 0.057791  [140832/60000]\n",
            "[Epoch: 17/100] Loss: 0.196423  [153632/60000]\n",
            "[Epoch: 17/100] Loss: 0.049464  [166432/60000]\n",
            "[Epoch: 17/100] Loss: 0.036875  [179232/60000]\n",
            "[Epoch: 17/100] Loss: 0.106202  [192032/60000]\n",
            "[Epoch: 17/100] Loss: 0.164264  [204832/60000]\n",
            "[Epoch: 17/100] Loss: 0.071346  [217632/60000]\n",
            "[Epoch: 17/100] Loss: 0.176440  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.5%, Avg loss: 0.216158 \n",
            "\n",
            "[Epoch: 18/100] Loss: 0.037776  [   32/60000]\n",
            "[Epoch: 18/100] Loss: 0.128814  [12832/60000]\n",
            "[Epoch: 18/100] Loss: 0.090249  [25632/60000]\n",
            "[Epoch: 18/100] Loss: 0.033338  [38432/60000]\n",
            "[Epoch: 18/100] Loss: 0.050581  [51232/60000]\n",
            "[Epoch: 18/100] Loss: 0.061514  [64032/60000]\n",
            "[Epoch: 18/100] Loss: 0.006154  [76832/60000]\n",
            "[Epoch: 18/100] Loss: 0.164400  [89632/60000]\n",
            "[Epoch: 18/100] Loss: 0.292144  [102432/60000]\n",
            "[Epoch: 18/100] Loss: 0.042126  [115232/60000]\n",
            "[Epoch: 18/100] Loss: 0.033903  [128032/60000]\n",
            "[Epoch: 18/100] Loss: 0.145199  [140832/60000]\n",
            "[Epoch: 18/100] Loss: 0.133587  [153632/60000]\n",
            "[Epoch: 18/100] Loss: 0.104748  [166432/60000]\n",
            "[Epoch: 18/100] Loss: 0.083456  [179232/60000]\n",
            "[Epoch: 18/100] Loss: 0.123917  [192032/60000]\n",
            "[Epoch: 18/100] Loss: 0.013212  [204832/60000]\n",
            "[Epoch: 18/100] Loss: 0.054892  [217632/60000]\n",
            "[Epoch: 18/100] Loss: 0.088392  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.219919 \n",
            "\n",
            "[Epoch: 19/100] Loss: 0.043602  [   32/60000]\n",
            "[Epoch: 19/100] Loss: 0.077929  [12832/60000]\n",
            "[Epoch: 19/100] Loss: 0.092049  [25632/60000]\n",
            "[Epoch: 19/100] Loss: 0.023054  [38432/60000]\n",
            "[Epoch: 19/100] Loss: 0.089383  [51232/60000]\n",
            "[Epoch: 19/100] Loss: 0.244531  [64032/60000]\n",
            "[Epoch: 19/100] Loss: 0.108982  [76832/60000]\n",
            "[Epoch: 19/100] Loss: 0.032003  [89632/60000]\n",
            "[Epoch: 19/100] Loss: 0.024711  [102432/60000]\n",
            "[Epoch: 19/100] Loss: 0.154356  [115232/60000]\n",
            "[Epoch: 19/100] Loss: 0.037767  [128032/60000]\n",
            "[Epoch: 19/100] Loss: 0.042044  [140832/60000]\n",
            "[Epoch: 19/100] Loss: 0.022111  [153632/60000]\n",
            "[Epoch: 19/100] Loss: 0.075233  [166432/60000]\n",
            "[Epoch: 19/100] Loss: 0.080364  [179232/60000]\n",
            "[Epoch: 19/100] Loss: 0.010666  [192032/60000]\n",
            "[Epoch: 19/100] Loss: 0.226624  [204832/60000]\n",
            "[Epoch: 19/100] Loss: 0.020758  [217632/60000]\n",
            "[Epoch: 19/100] Loss: 0.123329  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.229734 \n",
            "\n",
            "[Epoch: 20/100] Loss: 0.034276  [   32/60000]\n",
            "[Epoch: 20/100] Loss: 0.034781  [12832/60000]\n",
            "[Epoch: 20/100] Loss: 0.076917  [25632/60000]\n",
            "[Epoch: 20/100] Loss: 0.174857  [38432/60000]\n",
            "[Epoch: 20/100] Loss: 0.165832  [51232/60000]\n",
            "[Epoch: 20/100] Loss: 0.094060  [64032/60000]\n",
            "[Epoch: 20/100] Loss: 0.195123  [76832/60000]\n",
            "[Epoch: 20/100] Loss: 0.125916  [89632/60000]\n",
            "[Epoch: 20/100] Loss: 0.188265  [102432/60000]\n",
            "[Epoch: 20/100] Loss: 0.269230  [115232/60000]\n",
            "[Epoch: 20/100] Loss: 0.069602  [128032/60000]\n",
            "[Epoch: 20/100] Loss: 0.021767  [140832/60000]\n",
            "[Epoch: 20/100] Loss: 0.027192  [153632/60000]\n",
            "[Epoch: 20/100] Loss: 0.390738  [166432/60000]\n",
            "[Epoch: 20/100] Loss: 0.038069  [179232/60000]\n",
            "[Epoch: 20/100] Loss: 0.116417  [192032/60000]\n",
            "[Epoch: 20/100] Loss: 0.010981  [204832/60000]\n",
            "[Epoch: 20/100] Loss: 0.048759  [217632/60000]\n",
            "[Epoch: 20/100] Loss: 0.037271  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.5%, Avg loss: 0.239888 \n",
            "\n",
            "[Epoch: 21/100] Loss: 0.096032  [   32/60000]\n",
            "[Epoch: 21/100] Loss: 0.009995  [12832/60000]\n",
            "[Epoch: 21/100] Loss: 0.088742  [25632/60000]\n",
            "[Epoch: 21/100] Loss: 0.075202  [38432/60000]\n",
            "[Epoch: 21/100] Loss: 0.108768  [51232/60000]\n",
            "[Epoch: 21/100] Loss: 0.111021  [64032/60000]\n",
            "[Epoch: 21/100] Loss: 0.031868  [76832/60000]\n",
            "[Epoch: 21/100] Loss: 0.015540  [89632/60000]\n",
            "[Epoch: 21/100] Loss: 0.083372  [102432/60000]\n",
            "[Epoch: 21/100] Loss: 0.118556  [115232/60000]\n",
            "[Epoch: 21/100] Loss: 0.048266  [128032/60000]\n",
            "[Epoch: 21/100] Loss: 0.200757  [140832/60000]\n",
            "[Epoch: 21/100] Loss: 0.022530  [153632/60000]\n",
            "[Epoch: 21/100] Loss: 0.023003  [166432/60000]\n",
            "[Epoch: 21/100] Loss: 0.043272  [179232/60000]\n",
            "[Epoch: 21/100] Loss: 0.046179  [192032/60000]\n",
            "[Epoch: 21/100] Loss: 0.049673  [204832/60000]\n",
            "[Epoch: 21/100] Loss: 0.034472  [217632/60000]\n",
            "[Epoch: 21/100] Loss: 0.116735  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.244344 \n",
            "\n",
            "[Epoch: 22/100] Loss: 0.048657  [   32/60000]\n",
            "[Epoch: 22/100] Loss: 0.180951  [12832/60000]\n",
            "[Epoch: 22/100] Loss: 0.061889  [25632/60000]\n",
            "[Epoch: 22/100] Loss: 0.057683  [38432/60000]\n",
            "[Epoch: 22/100] Loss: 0.074704  [51232/60000]\n",
            "[Epoch: 22/100] Loss: 0.087995  [64032/60000]\n",
            "[Epoch: 22/100] Loss: 0.052703  [76832/60000]\n",
            "[Epoch: 22/100] Loss: 0.013393  [89632/60000]\n",
            "[Epoch: 22/100] Loss: 0.087500  [102432/60000]\n",
            "[Epoch: 22/100] Loss: 0.066465  [115232/60000]\n",
            "[Epoch: 22/100] Loss: 0.120064  [128032/60000]\n",
            "[Epoch: 22/100] Loss: 0.104154  [140832/60000]\n",
            "[Epoch: 22/100] Loss: 0.027050  [153632/60000]\n",
            "[Epoch: 22/100] Loss: 0.012694  [166432/60000]\n",
            "[Epoch: 22/100] Loss: 0.018677  [179232/60000]\n",
            "[Epoch: 22/100] Loss: 0.038070  [192032/60000]\n",
            "[Epoch: 22/100] Loss: 0.010188  [204832/60000]\n",
            "[Epoch: 22/100] Loss: 0.100234  [217632/60000]\n",
            "[Epoch: 22/100] Loss: 0.091464  [230432/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.241102 \n",
            "\n",
            "Early stopping at epoch 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "3f6ae586-5f56-4fa0-9b22-381ac78a335a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cecf570-b632-4b57-ae49-1a29e896cd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.98798\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ab8e10-7cad-44d6-8600-580735fb58a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.928\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CijDzpKWq7Rl"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DorianGrayPicture/yandex_ml_trainings_season_3.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9YcuJwJ7Bsq",
        "outputId": "8fbb0c68-2f60-4df1-bd16-8f239856248d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yandex_ml_trainings_season_3' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/yandex_ml_trainings_season_3/hw01_classification/yandex_ml_trainings_season_3/hw01_classification\")"
      ],
      "metadata": {
        "id": "oTC2rgJ27t_3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVbvsENmq7Rl",
        "outputId": "bfe987a7-423f-48a5-9007-dc9bf27a9144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPOF11Ipq7Rl"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}