{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorianGrayPicture/yandex_ml_trainings_season_3/blob/main/hw01_classification\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT6AZ6-iKZY3"
      },
      "source": [
        "## Классификация MNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "-NzUxhWNKZY7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTPY35Q6KZY-"
      },
      "source": [
        "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
        "\n",
        "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WpKxzQ_dKZY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "9f33d9a0-85dd-44dc-aae1-1264e77a0a3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 2')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2654ZnFSKZY_"
      },
      "source": [
        "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
        "\n",
        "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
        "\n",
        "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Device for Training"
      ],
      "metadata": {
        "id": "YtcNCz7GMqJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX_2O9i3MpmE",
        "outputId": "28b1b438-c45b-48c3-b9ec-c9907e4fc88a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.fc_stack(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "EXbgVatsMRaX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "UKG0w8dRKZZA"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model = Net().to(\"cpu\") # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCSE69pIKZZA"
      },
      "source": [
        "Ниже доступны локальные тесты для проверки вашей модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "8CseLTyVKZZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b952e208-8a8f-41ba-a59b-9b68a8dde552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkXTNh0YKZZC"
      },
      "source": [
        "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "OxadUrhnKZZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c0d849-846b-422c-d8a9-d388d05d59bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1/100] Loss: 2.297935  [   32/60000]\n",
            "[Epoch: 1/100] Loss: 2.298802  [ 3232/60000]\n",
            "[Epoch: 1/100] Loss: 2.301204  [ 6432/60000]\n",
            "[Epoch: 1/100] Loss: 2.279133  [ 9632/60000]\n",
            "[Epoch: 1/100] Loss: 2.282756  [12832/60000]\n",
            "[Epoch: 1/100] Loss: 2.281724  [16032/60000]\n",
            "[Epoch: 1/100] Loss: 2.281781  [19232/60000]\n",
            "[Epoch: 1/100] Loss: 2.272519  [22432/60000]\n",
            "[Epoch: 1/100] Loss: 2.272085  [25632/60000]\n",
            "[Epoch: 1/100] Loss: 2.271471  [28832/60000]\n",
            "[Epoch: 1/100] Loss: 2.250769  [32032/60000]\n",
            "[Epoch: 1/100] Loss: 2.261169  [35232/60000]\n",
            "[Epoch: 1/100] Loss: 2.239131  [38432/60000]\n",
            "[Epoch: 1/100] Loss: 2.245146  [41632/60000]\n",
            "[Epoch: 1/100] Loss: 2.247639  [44832/60000]\n",
            "[Epoch: 1/100] Loss: 2.246111  [48032/60000]\n",
            "[Epoch: 1/100] Loss: 2.214893  [51232/60000]\n",
            "[Epoch: 1/100] Loss: 2.216470  [54432/60000]\n",
            "[Epoch: 1/100] Loss: 2.186218  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 2.208668 \n",
            "\n",
            "[Epoch: 2/100] Loss: 2.202340  [   32/60000]\n",
            "[Epoch: 2/100] Loss: 2.209841  [ 3232/60000]\n",
            "[Epoch: 2/100] Loss: 2.173954  [ 6432/60000]\n",
            "[Epoch: 2/100] Loss: 2.181197  [ 9632/60000]\n",
            "[Epoch: 2/100] Loss: 2.192985  [12832/60000]\n",
            "[Epoch: 2/100] Loss: 2.139987  [16032/60000]\n",
            "[Epoch: 2/100] Loss: 2.193469  [19232/60000]\n",
            "[Epoch: 2/100] Loss: 2.183073  [22432/60000]\n",
            "[Epoch: 2/100] Loss: 2.133785  [25632/60000]\n",
            "[Epoch: 2/100] Loss: 2.156471  [28832/60000]\n",
            "[Epoch: 2/100] Loss: 2.007325  [32032/60000]\n",
            "[Epoch: 2/100] Loss: 2.104483  [35232/60000]\n",
            "[Epoch: 2/100] Loss: 2.097927  [38432/60000]\n",
            "[Epoch: 2/100] Loss: 2.063465  [41632/60000]\n",
            "[Epoch: 2/100] Loss: 2.048453  [44832/60000]\n",
            "[Epoch: 2/100] Loss: 2.040118  [48032/60000]\n",
            "[Epoch: 2/100] Loss: 2.064349  [51232/60000]\n",
            "[Epoch: 2/100] Loss: 1.955502  [54432/60000]\n",
            "[Epoch: 2/100] Loss: 1.936210  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.7%, Avg loss: 1.958409 \n",
            "\n",
            "[Epoch: 3/100] Loss: 1.863145  [   32/60000]\n",
            "[Epoch: 3/100] Loss: 1.901829  [ 3232/60000]\n",
            "[Epoch: 3/100] Loss: 1.932624  [ 6432/60000]\n",
            "[Epoch: 3/100] Loss: 1.904219  [ 9632/60000]\n",
            "[Epoch: 3/100] Loss: 1.853663  [12832/60000]\n",
            "[Epoch: 3/100] Loss: 1.842582  [16032/60000]\n",
            "[Epoch: 3/100] Loss: 1.802540  [19232/60000]\n",
            "[Epoch: 3/100] Loss: 1.790845  [22432/60000]\n",
            "[Epoch: 3/100] Loss: 1.748971  [25632/60000]\n",
            "[Epoch: 3/100] Loss: 1.784378  [28832/60000]\n",
            "[Epoch: 3/100] Loss: 1.616844  [32032/60000]\n",
            "[Epoch: 3/100] Loss: 1.761228  [35232/60000]\n",
            "[Epoch: 3/100] Loss: 1.754058  [38432/60000]\n",
            "[Epoch: 3/100] Loss: 1.658743  [41632/60000]\n",
            "[Epoch: 3/100] Loss: 1.585608  [44832/60000]\n",
            "[Epoch: 3/100] Loss: 1.604912  [48032/60000]\n",
            "[Epoch: 3/100] Loss: 1.459925  [51232/60000]\n",
            "[Epoch: 3/100] Loss: 1.601730  [54432/60000]\n",
            "[Epoch: 3/100] Loss: 1.416934  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 1.388039 \n",
            "\n",
            "[Epoch: 4/100] Loss: 1.165315  [   32/60000]\n",
            "[Epoch: 4/100] Loss: 1.345521  [ 3232/60000]\n",
            "[Epoch: 4/100] Loss: 1.434694  [ 6432/60000]\n",
            "[Epoch: 4/100] Loss: 1.277269  [ 9632/60000]\n",
            "[Epoch: 4/100] Loss: 1.324939  [12832/60000]\n",
            "[Epoch: 4/100] Loss: 1.333063  [16032/60000]\n",
            "[Epoch: 4/100] Loss: 1.288649  [19232/60000]\n",
            "[Epoch: 4/100] Loss: 1.309200  [22432/60000]\n",
            "[Epoch: 4/100] Loss: 1.318392  [25632/60000]\n",
            "[Epoch: 4/100] Loss: 1.204825  [28832/60000]\n",
            "[Epoch: 4/100] Loss: 1.164712  [32032/60000]\n",
            "[Epoch: 4/100] Loss: 1.150380  [35232/60000]\n",
            "[Epoch: 4/100] Loss: 1.171179  [38432/60000]\n",
            "[Epoch: 4/100] Loss: 0.977901  [41632/60000]\n",
            "[Epoch: 4/100] Loss: 1.030134  [44832/60000]\n",
            "[Epoch: 4/100] Loss: 0.968792  [48032/60000]\n",
            "[Epoch: 4/100] Loss: 0.894127  [51232/60000]\n",
            "[Epoch: 4/100] Loss: 0.934726  [54432/60000]\n",
            "[Epoch: 4/100] Loss: 0.871201  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 0.907668 \n",
            "\n",
            "[Epoch: 5/100] Loss: 0.807319  [   32/60000]\n",
            "[Epoch: 5/100] Loss: 1.053787  [ 3232/60000]\n",
            "[Epoch: 5/100] Loss: 0.968984  [ 6432/60000]\n",
            "[Epoch: 5/100] Loss: 0.947984  [ 9632/60000]\n",
            "[Epoch: 5/100] Loss: 0.785870  [12832/60000]\n",
            "[Epoch: 5/100] Loss: 0.917209  [16032/60000]\n",
            "[Epoch: 5/100] Loss: 0.911314  [19232/60000]\n",
            "[Epoch: 5/100] Loss: 0.730085  [22432/60000]\n",
            "[Epoch: 5/100] Loss: 0.925917  [25632/60000]\n",
            "[Epoch: 5/100] Loss: 0.869928  [28832/60000]\n",
            "[Epoch: 5/100] Loss: 0.838119  [32032/60000]\n",
            "[Epoch: 5/100] Loss: 0.690397  [35232/60000]\n",
            "[Epoch: 5/100] Loss: 0.639138  [38432/60000]\n",
            "[Epoch: 5/100] Loss: 0.677379  [41632/60000]\n",
            "[Epoch: 5/100] Loss: 0.700787  [44832/60000]\n",
            "[Epoch: 5/100] Loss: 0.652885  [48032/60000]\n",
            "[Epoch: 5/100] Loss: 0.702066  [51232/60000]\n",
            "[Epoch: 5/100] Loss: 0.514867  [54432/60000]\n",
            "[Epoch: 5/100] Loss: 0.647628  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.682900 \n",
            "\n",
            "[Epoch: 6/100] Loss: 0.832955  [   32/60000]\n",
            "[Epoch: 6/100] Loss: 0.727316  [ 3232/60000]\n",
            "[Epoch: 6/100] Loss: 0.841748  [ 6432/60000]\n",
            "[Epoch: 6/100] Loss: 0.484443  [ 9632/60000]\n",
            "[Epoch: 6/100] Loss: 0.667278  [12832/60000]\n",
            "[Epoch: 6/100] Loss: 0.761235  [16032/60000]\n",
            "[Epoch: 6/100] Loss: 0.573039  [19232/60000]\n",
            "[Epoch: 6/100] Loss: 0.544644  [22432/60000]\n",
            "[Epoch: 6/100] Loss: 0.584258  [25632/60000]\n",
            "[Epoch: 6/100] Loss: 0.367041  [28832/60000]\n",
            "[Epoch: 6/100] Loss: 0.682200  [32032/60000]\n",
            "[Epoch: 6/100] Loss: 0.580876  [35232/60000]\n",
            "[Epoch: 6/100] Loss: 0.714123  [38432/60000]\n",
            "[Epoch: 6/100] Loss: 0.665339  [41632/60000]\n",
            "[Epoch: 6/100] Loss: 0.637705  [44832/60000]\n",
            "[Epoch: 6/100] Loss: 0.627493  [48032/60000]\n",
            "[Epoch: 6/100] Loss: 0.565851  [51232/60000]\n",
            "[Epoch: 6/100] Loss: 0.547656  [54432/60000]\n",
            "[Epoch: 6/100] Loss: 0.607272  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.566205 \n",
            "\n",
            "[Epoch: 7/100] Loss: 0.668697  [   32/60000]\n",
            "[Epoch: 7/100] Loss: 0.707029  [ 3232/60000]\n",
            "[Epoch: 7/100] Loss: 0.603123  [ 6432/60000]\n",
            "[Epoch: 7/100] Loss: 0.515413  [ 9632/60000]\n",
            "[Epoch: 7/100] Loss: 0.856585  [12832/60000]\n",
            "[Epoch: 7/100] Loss: 0.832187  [16032/60000]\n",
            "[Epoch: 7/100] Loss: 0.414225  [19232/60000]\n",
            "[Epoch: 7/100] Loss: 0.323579  [22432/60000]\n",
            "[Epoch: 7/100] Loss: 0.574306  [25632/60000]\n",
            "[Epoch: 7/100] Loss: 0.526833  [28832/60000]\n",
            "[Epoch: 7/100] Loss: 0.480389  [32032/60000]\n",
            "[Epoch: 7/100] Loss: 0.625752  [35232/60000]\n",
            "[Epoch: 7/100] Loss: 0.701072  [38432/60000]\n",
            "[Epoch: 7/100] Loss: 0.835033  [41632/60000]\n",
            "[Epoch: 7/100] Loss: 0.556994  [44832/60000]\n",
            "[Epoch: 7/100] Loss: 0.529420  [48032/60000]\n",
            "[Epoch: 7/100] Loss: 0.460543  [51232/60000]\n",
            "[Epoch: 7/100] Loss: 0.485679  [54432/60000]\n",
            "[Epoch: 7/100] Loss: 0.730079  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.495191 \n",
            "\n",
            "[Epoch: 8/100] Loss: 0.353122  [   32/60000]\n",
            "[Epoch: 8/100] Loss: 0.511258  [ 3232/60000]\n",
            "[Epoch: 8/100] Loss: 0.473093  [ 6432/60000]\n",
            "[Epoch: 8/100] Loss: 0.377436  [ 9632/60000]\n",
            "[Epoch: 8/100] Loss: 0.413738  [12832/60000]\n",
            "[Epoch: 8/100] Loss: 0.339348  [16032/60000]\n",
            "[Epoch: 8/100] Loss: 0.418242  [19232/60000]\n",
            "[Epoch: 8/100] Loss: 0.405011  [22432/60000]\n",
            "[Epoch: 8/100] Loss: 0.426956  [25632/60000]\n",
            "[Epoch: 8/100] Loss: 0.357891  [28832/60000]\n",
            "[Epoch: 8/100] Loss: 0.304909  [32032/60000]\n",
            "[Epoch: 8/100] Loss: 0.596500  [35232/60000]\n",
            "[Epoch: 8/100] Loss: 0.361541  [38432/60000]\n",
            "[Epoch: 8/100] Loss: 0.502527  [41632/60000]\n",
            "[Epoch: 8/100] Loss: 0.486519  [44832/60000]\n",
            "[Epoch: 8/100] Loss: 0.452657  [48032/60000]\n",
            "[Epoch: 8/100] Loss: 0.668967  [51232/60000]\n",
            "[Epoch: 8/100] Loss: 0.456883  [54432/60000]\n",
            "[Epoch: 8/100] Loss: 0.640085  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.449308 \n",
            "\n",
            "[Epoch: 9/100] Loss: 0.673424  [   32/60000]\n",
            "[Epoch: 9/100] Loss: 0.299374  [ 3232/60000]\n",
            "[Epoch: 9/100] Loss: 0.612652  [ 6432/60000]\n",
            "[Epoch: 9/100] Loss: 0.462441  [ 9632/60000]\n",
            "[Epoch: 9/100] Loss: 0.514167  [12832/60000]\n",
            "[Epoch: 9/100] Loss: 0.503706  [16032/60000]\n",
            "[Epoch: 9/100] Loss: 0.434090  [19232/60000]\n",
            "[Epoch: 9/100] Loss: 0.543731  [22432/60000]\n",
            "[Epoch: 9/100] Loss: 0.634124  [25632/60000]\n",
            "[Epoch: 9/100] Loss: 0.618126  [28832/60000]\n",
            "[Epoch: 9/100] Loss: 0.423181  [32032/60000]\n",
            "[Epoch: 9/100] Loss: 0.707141  [35232/60000]\n",
            "[Epoch: 9/100] Loss: 0.299575  [38432/60000]\n",
            "[Epoch: 9/100] Loss: 0.382874  [41632/60000]\n",
            "[Epoch: 9/100] Loss: 0.419847  [44832/60000]\n",
            "[Epoch: 9/100] Loss: 0.327501  [48032/60000]\n",
            "[Epoch: 9/100] Loss: 0.451098  [51232/60000]\n",
            "[Epoch: 9/100] Loss: 0.322456  [54432/60000]\n",
            "[Epoch: 9/100] Loss: 0.530355  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.415871 \n",
            "\n",
            "[Epoch: 10/100] Loss: 0.710328  [   32/60000]\n",
            "[Epoch: 10/100] Loss: 0.306025  [ 3232/60000]\n",
            "[Epoch: 10/100] Loss: 0.543390  [ 6432/60000]\n",
            "[Epoch: 10/100] Loss: 0.279162  [ 9632/60000]\n",
            "[Epoch: 10/100] Loss: 0.464583  [12832/60000]\n",
            "[Epoch: 10/100] Loss: 0.484314  [16032/60000]\n",
            "[Epoch: 10/100] Loss: 0.288082  [19232/60000]\n",
            "[Epoch: 10/100] Loss: 0.265745  [22432/60000]\n",
            "[Epoch: 10/100] Loss: 0.493621  [25632/60000]\n",
            "[Epoch: 10/100] Loss: 0.424518  [28832/60000]\n",
            "[Epoch: 10/100] Loss: 0.432311  [32032/60000]\n",
            "[Epoch: 10/100] Loss: 0.403669  [35232/60000]\n",
            "[Epoch: 10/100] Loss: 0.312928  [38432/60000]\n",
            "[Epoch: 10/100] Loss: 0.569163  [41632/60000]\n",
            "[Epoch: 10/100] Loss: 0.292775  [44832/60000]\n",
            "[Epoch: 10/100] Loss: 0.434287  [48032/60000]\n",
            "[Epoch: 10/100] Loss: 0.572546  [51232/60000]\n",
            "[Epoch: 10/100] Loss: 0.192616  [54432/60000]\n",
            "[Epoch: 10/100] Loss: 0.412519  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.392181 \n",
            "\n",
            "[Epoch: 11/100] Loss: 0.588398  [   32/60000]\n",
            "[Epoch: 11/100] Loss: 0.711590  [ 3232/60000]\n",
            "[Epoch: 11/100] Loss: 0.639600  [ 6432/60000]\n",
            "[Epoch: 11/100] Loss: 0.559861  [ 9632/60000]\n",
            "[Epoch: 11/100] Loss: 0.298597  [12832/60000]\n",
            "[Epoch: 11/100] Loss: 0.509436  [16032/60000]\n",
            "[Epoch: 11/100] Loss: 0.612872  [19232/60000]\n",
            "[Epoch: 11/100] Loss: 0.319080  [22432/60000]\n",
            "[Epoch: 11/100] Loss: 0.663584  [25632/60000]\n",
            "[Epoch: 11/100] Loss: 0.182516  [28832/60000]\n",
            "[Epoch: 11/100] Loss: 0.382263  [32032/60000]\n",
            "[Epoch: 11/100] Loss: 0.488844  [35232/60000]\n",
            "[Epoch: 11/100] Loss: 0.408780  [38432/60000]\n",
            "[Epoch: 11/100] Loss: 0.323007  [41632/60000]\n",
            "[Epoch: 11/100] Loss: 0.397548  [44832/60000]\n",
            "[Epoch: 11/100] Loss: 0.513418  [48032/60000]\n",
            "[Epoch: 11/100] Loss: 0.500075  [51232/60000]\n",
            "[Epoch: 11/100] Loss: 0.542995  [54432/60000]\n",
            "[Epoch: 11/100] Loss: 0.462174  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.373960 \n",
            "\n",
            "[Epoch: 12/100] Loss: 0.583436  [   32/60000]\n",
            "[Epoch: 12/100] Loss: 0.603555  [ 3232/60000]\n",
            "[Epoch: 12/100] Loss: 0.275739  [ 6432/60000]\n",
            "[Epoch: 12/100] Loss: 0.553668  [ 9632/60000]\n",
            "[Epoch: 12/100] Loss: 0.513654  [12832/60000]\n",
            "[Epoch: 12/100] Loss: 0.211093  [16032/60000]\n",
            "[Epoch: 12/100] Loss: 0.358500  [19232/60000]\n",
            "[Epoch: 12/100] Loss: 0.426377  [22432/60000]\n",
            "[Epoch: 12/100] Loss: 0.268737  [25632/60000]\n",
            "[Epoch: 12/100] Loss: 0.471508  [28832/60000]\n",
            "[Epoch: 12/100] Loss: 0.485658  [32032/60000]\n",
            "[Epoch: 12/100] Loss: 0.340012  [35232/60000]\n",
            "[Epoch: 12/100] Loss: 0.313073  [38432/60000]\n",
            "[Epoch: 12/100] Loss: 0.470806  [41632/60000]\n",
            "[Epoch: 12/100] Loss: 0.555138  [44832/60000]\n",
            "[Epoch: 12/100] Loss: 0.486395  [48032/60000]\n",
            "[Epoch: 12/100] Loss: 0.199854  [51232/60000]\n",
            "[Epoch: 12/100] Loss: 0.268728  [54432/60000]\n",
            "[Epoch: 12/100] Loss: 0.318518  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.359022 \n",
            "\n",
            "[Epoch: 13/100] Loss: 0.341200  [   32/60000]\n",
            "[Epoch: 13/100] Loss: 0.376842  [ 3232/60000]\n",
            "[Epoch: 13/100] Loss: 0.170710  [ 6432/60000]\n",
            "[Epoch: 13/100] Loss: 0.326266  [ 9632/60000]\n",
            "[Epoch: 13/100] Loss: 0.580392  [12832/60000]\n",
            "[Epoch: 13/100] Loss: 0.362964  [16032/60000]\n",
            "[Epoch: 13/100] Loss: 0.328857  [19232/60000]\n",
            "[Epoch: 13/100] Loss: 0.351254  [22432/60000]\n",
            "[Epoch: 13/100] Loss: 0.497315  [25632/60000]\n",
            "[Epoch: 13/100] Loss: 0.188536  [28832/60000]\n",
            "[Epoch: 13/100] Loss: 0.433149  [32032/60000]\n",
            "[Epoch: 13/100] Loss: 0.374164  [35232/60000]\n",
            "[Epoch: 13/100] Loss: 0.181313  [38432/60000]\n",
            "[Epoch: 13/100] Loss: 0.237392  [41632/60000]\n",
            "[Epoch: 13/100] Loss: 0.437733  [44832/60000]\n",
            "[Epoch: 13/100] Loss: 0.237727  [48032/60000]\n",
            "[Epoch: 13/100] Loss: 0.236902  [51232/60000]\n",
            "[Epoch: 13/100] Loss: 0.416512  [54432/60000]\n",
            "[Epoch: 13/100] Loss: 0.383558  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 0.347419 \n",
            "\n",
            "[Epoch: 14/100] Loss: 0.328794  [   32/60000]\n",
            "[Epoch: 14/100] Loss: 0.397679  [ 3232/60000]\n",
            "[Epoch: 14/100] Loss: 0.356509  [ 6432/60000]\n",
            "[Epoch: 14/100] Loss: 0.272519  [ 9632/60000]\n",
            "[Epoch: 14/100] Loss: 0.259968  [12832/60000]\n",
            "[Epoch: 14/100] Loss: 0.497711  [16032/60000]\n",
            "[Epoch: 14/100] Loss: 0.258035  [19232/60000]\n",
            "[Epoch: 14/100] Loss: 0.368974  [22432/60000]\n",
            "[Epoch: 14/100] Loss: 0.447789  [25632/60000]\n",
            "[Epoch: 14/100] Loss: 0.392468  [28832/60000]\n",
            "[Epoch: 14/100] Loss: 0.272030  [32032/60000]\n",
            "[Epoch: 14/100] Loss: 0.353022  [35232/60000]\n",
            "[Epoch: 14/100] Loss: 0.502994  [38432/60000]\n",
            "[Epoch: 14/100] Loss: 0.417278  [41632/60000]\n",
            "[Epoch: 14/100] Loss: 0.326933  [44832/60000]\n",
            "[Epoch: 14/100] Loss: 0.205651  [48032/60000]\n",
            "[Epoch: 14/100] Loss: 0.484061  [51232/60000]\n",
            "[Epoch: 14/100] Loss: 0.266291  [54432/60000]\n",
            "[Epoch: 14/100] Loss: 0.269086  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.337240 \n",
            "\n",
            "[Epoch: 15/100] Loss: 0.621164  [   32/60000]\n",
            "[Epoch: 15/100] Loss: 0.482999  [ 3232/60000]\n",
            "[Epoch: 15/100] Loss: 0.291037  [ 6432/60000]\n",
            "[Epoch: 15/100] Loss: 0.713548  [ 9632/60000]\n",
            "[Epoch: 15/100] Loss: 0.167648  [12832/60000]\n",
            "[Epoch: 15/100] Loss: 0.734471  [16032/60000]\n",
            "[Epoch: 15/100] Loss: 0.939613  [19232/60000]\n",
            "[Epoch: 15/100] Loss: 0.185286  [22432/60000]\n",
            "[Epoch: 15/100] Loss: 0.479834  [25632/60000]\n",
            "[Epoch: 15/100] Loss: 0.357054  [28832/60000]\n",
            "[Epoch: 15/100] Loss: 0.104716  [32032/60000]\n",
            "[Epoch: 15/100] Loss: 0.234939  [35232/60000]\n",
            "[Epoch: 15/100] Loss: 0.382116  [38432/60000]\n",
            "[Epoch: 15/100] Loss: 0.153010  [41632/60000]\n",
            "[Epoch: 15/100] Loss: 0.201152  [44832/60000]\n",
            "[Epoch: 15/100] Loss: 0.517478  [48032/60000]\n",
            "[Epoch: 15/100] Loss: 0.208986  [51232/60000]\n",
            "[Epoch: 15/100] Loss: 0.306399  [54432/60000]\n",
            "[Epoch: 15/100] Loss: 0.335331  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.329817 \n",
            "\n",
            "[Epoch: 16/100] Loss: 0.224701  [   32/60000]\n",
            "[Epoch: 16/100] Loss: 0.289867  [ 3232/60000]\n",
            "[Epoch: 16/100] Loss: 0.206160  [ 6432/60000]\n",
            "[Epoch: 16/100] Loss: 0.247049  [ 9632/60000]\n",
            "[Epoch: 16/100] Loss: 0.155614  [12832/60000]\n",
            "[Epoch: 16/100] Loss: 0.324606  [16032/60000]\n",
            "[Epoch: 16/100] Loss: 0.164876  [19232/60000]\n",
            "[Epoch: 16/100] Loss: 0.262232  [22432/60000]\n",
            "[Epoch: 16/100] Loss: 0.221858  [25632/60000]\n",
            "[Epoch: 16/100] Loss: 0.200844  [28832/60000]\n",
            "[Epoch: 16/100] Loss: 0.447866  [32032/60000]\n",
            "[Epoch: 16/100] Loss: 0.206025  [35232/60000]\n",
            "[Epoch: 16/100] Loss: 0.332712  [38432/60000]\n",
            "[Epoch: 16/100] Loss: 0.478920  [41632/60000]\n",
            "[Epoch: 16/100] Loss: 0.382948  [44832/60000]\n",
            "[Epoch: 16/100] Loss: 0.509770  [48032/60000]\n",
            "[Epoch: 16/100] Loss: 0.317623  [51232/60000]\n",
            "[Epoch: 16/100] Loss: 0.256004  [54432/60000]\n",
            "[Epoch: 16/100] Loss: 0.227943  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.321061 \n",
            "\n",
            "[Epoch: 17/100] Loss: 0.177621  [   32/60000]\n",
            "[Epoch: 17/100] Loss: 0.504185  [ 3232/60000]\n",
            "[Epoch: 17/100] Loss: 0.505893  [ 6432/60000]\n",
            "[Epoch: 17/100] Loss: 0.768481  [ 9632/60000]\n",
            "[Epoch: 17/100] Loss: 0.523085  [12832/60000]\n",
            "[Epoch: 17/100] Loss: 0.537632  [16032/60000]\n",
            "[Epoch: 17/100] Loss: 0.448009  [19232/60000]\n",
            "[Epoch: 17/100] Loss: 0.175263  [22432/60000]\n",
            "[Epoch: 17/100] Loss: 0.329134  [25632/60000]\n",
            "[Epoch: 17/100] Loss: 0.244631  [28832/60000]\n",
            "[Epoch: 17/100] Loss: 0.521110  [32032/60000]\n",
            "[Epoch: 17/100] Loss: 0.194820  [35232/60000]\n",
            "[Epoch: 17/100] Loss: 0.462175  [38432/60000]\n",
            "[Epoch: 17/100] Loss: 0.268771  [41632/60000]\n",
            "[Epoch: 17/100] Loss: 0.354156  [44832/60000]\n",
            "[Epoch: 17/100] Loss: 0.366984  [48032/60000]\n",
            "[Epoch: 17/100] Loss: 0.238312  [51232/60000]\n",
            "[Epoch: 17/100] Loss: 0.507778  [54432/60000]\n",
            "[Epoch: 17/100] Loss: 0.144260  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.9%, Avg loss: 0.314329 \n",
            "\n",
            "[Epoch: 18/100] Loss: 0.175344  [   32/60000]\n",
            "[Epoch: 18/100] Loss: 0.093960  [ 3232/60000]\n",
            "[Epoch: 18/100] Loss: 0.187747  [ 6432/60000]\n",
            "[Epoch: 18/100] Loss: 0.259286  [ 9632/60000]\n",
            "[Epoch: 18/100] Loss: 0.771449  [12832/60000]\n",
            "[Epoch: 18/100] Loss: 0.250539  [16032/60000]\n",
            "[Epoch: 18/100] Loss: 0.431499  [19232/60000]\n",
            "[Epoch: 18/100] Loss: 0.497811  [22432/60000]\n",
            "[Epoch: 18/100] Loss: 0.379722  [25632/60000]\n",
            "[Epoch: 18/100] Loss: 0.338295  [28832/60000]\n",
            "[Epoch: 18/100] Loss: 0.741006  [32032/60000]\n",
            "[Epoch: 18/100] Loss: 0.396686  [35232/60000]\n",
            "[Epoch: 18/100] Loss: 0.350453  [38432/60000]\n",
            "[Epoch: 18/100] Loss: 0.280459  [41632/60000]\n",
            "[Epoch: 18/100] Loss: 0.120525  [44832/60000]\n",
            "[Epoch: 18/100] Loss: 0.319619  [48032/60000]\n",
            "[Epoch: 18/100] Loss: 0.386610  [51232/60000]\n",
            "[Epoch: 18/100] Loss: 0.482057  [54432/60000]\n",
            "[Epoch: 18/100] Loss: 0.298069  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.309079 \n",
            "\n",
            "[Epoch: 19/100] Loss: 0.112129  [   32/60000]\n",
            "[Epoch: 19/100] Loss: 0.683531  [ 3232/60000]\n",
            "[Epoch: 19/100] Loss: 0.692892  [ 6432/60000]\n",
            "[Epoch: 19/100] Loss: 0.158476  [ 9632/60000]\n",
            "[Epoch: 19/100] Loss: 0.341711  [12832/60000]\n",
            "[Epoch: 19/100] Loss: 0.162570  [16032/60000]\n",
            "[Epoch: 19/100] Loss: 0.163344  [19232/60000]\n",
            "[Epoch: 19/100] Loss: 0.166707  [22432/60000]\n",
            "[Epoch: 19/100] Loss: 0.499291  [25632/60000]\n",
            "[Epoch: 19/100] Loss: 0.240970  [28832/60000]\n",
            "[Epoch: 19/100] Loss: 0.513347  [32032/60000]\n",
            "[Epoch: 19/100] Loss: 0.327618  [35232/60000]\n",
            "[Epoch: 19/100] Loss: 0.349547  [38432/60000]\n",
            "[Epoch: 19/100] Loss: 0.360742  [41632/60000]\n",
            "[Epoch: 19/100] Loss: 0.336538  [44832/60000]\n",
            "[Epoch: 19/100] Loss: 0.479237  [48032/60000]\n",
            "[Epoch: 19/100] Loss: 0.736646  [51232/60000]\n",
            "[Epoch: 19/100] Loss: 0.339160  [54432/60000]\n",
            "[Epoch: 19/100] Loss: 0.391399  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.303475 \n",
            "\n",
            "[Epoch: 20/100] Loss: 0.100282  [   32/60000]\n",
            "[Epoch: 20/100] Loss: 0.325117  [ 3232/60000]\n",
            "[Epoch: 20/100] Loss: 0.319651  [ 6432/60000]\n",
            "[Epoch: 20/100] Loss: 0.392094  [ 9632/60000]\n",
            "[Epoch: 20/100] Loss: 0.187624  [12832/60000]\n",
            "[Epoch: 20/100] Loss: 0.443296  [16032/60000]\n",
            "[Epoch: 20/100] Loss: 0.246868  [19232/60000]\n",
            "[Epoch: 20/100] Loss: 0.332975  [22432/60000]\n",
            "[Epoch: 20/100] Loss: 0.209710  [25632/60000]\n",
            "[Epoch: 20/100] Loss: 0.163736  [28832/60000]\n",
            "[Epoch: 20/100] Loss: 0.151294  [32032/60000]\n",
            "[Epoch: 20/100] Loss: 0.564284  [35232/60000]\n",
            "[Epoch: 20/100] Loss: 0.138726  [38432/60000]\n",
            "[Epoch: 20/100] Loss: 0.284570  [41632/60000]\n",
            "[Epoch: 20/100] Loss: 0.256214  [44832/60000]\n",
            "[Epoch: 20/100] Loss: 0.140690  [48032/60000]\n",
            "[Epoch: 20/100] Loss: 0.161339  [51232/60000]\n",
            "[Epoch: 20/100] Loss: 0.298934  [54432/60000]\n",
            "[Epoch: 20/100] Loss: 0.249518  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.297001 \n",
            "\n",
            "[Epoch: 21/100] Loss: 0.366559  [   32/60000]\n",
            "[Epoch: 21/100] Loss: 0.239560  [ 3232/60000]\n",
            "[Epoch: 21/100] Loss: 0.466238  [ 6432/60000]\n",
            "[Epoch: 21/100] Loss: 0.134701  [ 9632/60000]\n",
            "[Epoch: 21/100] Loss: 0.433077  [12832/60000]\n",
            "[Epoch: 21/100] Loss: 0.381238  [16032/60000]\n",
            "[Epoch: 21/100] Loss: 0.243309  [19232/60000]\n",
            "[Epoch: 21/100] Loss: 0.722300  [22432/60000]\n",
            "[Epoch: 21/100] Loss: 0.137753  [25632/60000]\n",
            "[Epoch: 21/100] Loss: 0.137759  [28832/60000]\n",
            "[Epoch: 21/100] Loss: 0.688674  [32032/60000]\n",
            "[Epoch: 21/100] Loss: 0.282329  [35232/60000]\n",
            "[Epoch: 21/100] Loss: 0.313141  [38432/60000]\n",
            "[Epoch: 21/100] Loss: 0.233880  [41632/60000]\n",
            "[Epoch: 21/100] Loss: 0.186440  [44832/60000]\n",
            "[Epoch: 21/100] Loss: 0.129926  [48032/60000]\n",
            "[Epoch: 21/100] Loss: 0.138248  [51232/60000]\n",
            "[Epoch: 21/100] Loss: 0.439365  [54432/60000]\n",
            "[Epoch: 21/100] Loss: 0.635171  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.292467 \n",
            "\n",
            "[Epoch: 22/100] Loss: 0.086627  [   32/60000]\n",
            "[Epoch: 22/100] Loss: 0.263919  [ 3232/60000]\n",
            "[Epoch: 22/100] Loss: 0.344559  [ 6432/60000]\n",
            "[Epoch: 22/100] Loss: 0.131499  [ 9632/60000]\n",
            "[Epoch: 22/100] Loss: 0.300107  [12832/60000]\n",
            "[Epoch: 22/100] Loss: 0.304616  [16032/60000]\n",
            "[Epoch: 22/100] Loss: 0.336413  [19232/60000]\n",
            "[Epoch: 22/100] Loss: 0.180777  [22432/60000]\n",
            "[Epoch: 22/100] Loss: 0.113014  [25632/60000]\n",
            "[Epoch: 22/100] Loss: 0.445016  [28832/60000]\n",
            "[Epoch: 22/100] Loss: 0.113474  [32032/60000]\n",
            "[Epoch: 22/100] Loss: 0.140274  [35232/60000]\n",
            "[Epoch: 22/100] Loss: 0.205315  [38432/60000]\n",
            "[Epoch: 22/100] Loss: 0.171146  [41632/60000]\n",
            "[Epoch: 22/100] Loss: 0.326682  [44832/60000]\n",
            "[Epoch: 22/100] Loss: 0.301829  [48032/60000]\n",
            "[Epoch: 22/100] Loss: 0.296313  [51232/60000]\n",
            "[Epoch: 22/100] Loss: 0.320919  [54432/60000]\n",
            "[Epoch: 22/100] Loss: 0.477471  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.287373 \n",
            "\n",
            "[Epoch: 23/100] Loss: 0.471224  [   32/60000]\n",
            "[Epoch: 23/100] Loss: 0.424935  [ 3232/60000]\n",
            "[Epoch: 23/100] Loss: 0.373527  [ 6432/60000]\n",
            "[Epoch: 23/100] Loss: 0.355097  [ 9632/60000]\n",
            "[Epoch: 23/100] Loss: 0.219676  [12832/60000]\n",
            "[Epoch: 23/100] Loss: 0.224968  [16032/60000]\n",
            "[Epoch: 23/100] Loss: 0.396500  [19232/60000]\n",
            "[Epoch: 23/100] Loss: 0.331690  [22432/60000]\n",
            "[Epoch: 23/100] Loss: 0.469079  [25632/60000]\n",
            "[Epoch: 23/100] Loss: 0.128246  [28832/60000]\n",
            "[Epoch: 23/100] Loss: 0.241739  [32032/60000]\n",
            "[Epoch: 23/100] Loss: 0.194651  [35232/60000]\n",
            "[Epoch: 23/100] Loss: 0.576844  [38432/60000]\n",
            "[Epoch: 23/100] Loss: 0.189021  [41632/60000]\n",
            "[Epoch: 23/100] Loss: 0.254953  [44832/60000]\n",
            "[Epoch: 23/100] Loss: 0.245915  [48032/60000]\n",
            "[Epoch: 23/100] Loss: 0.247320  [51232/60000]\n",
            "[Epoch: 23/100] Loss: 0.338288  [54432/60000]\n",
            "[Epoch: 23/100] Loss: 0.315368  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.9%, Avg loss: 0.283244 \n",
            "\n",
            "[Epoch: 24/100] Loss: 0.111860  [   32/60000]\n",
            "[Epoch: 24/100] Loss: 0.374070  [ 3232/60000]\n",
            "[Epoch: 24/100] Loss: 0.270034  [ 6432/60000]\n",
            "[Epoch: 24/100] Loss: 0.451467  [ 9632/60000]\n",
            "[Epoch: 24/100] Loss: 0.241489  [12832/60000]\n",
            "[Epoch: 24/100] Loss: 0.280343  [16032/60000]\n",
            "[Epoch: 24/100] Loss: 0.214584  [19232/60000]\n",
            "[Epoch: 24/100] Loss: 0.161113  [22432/60000]\n",
            "[Epoch: 24/100] Loss: 0.225100  [25632/60000]\n",
            "[Epoch: 24/100] Loss: 0.540705  [28832/60000]\n",
            "[Epoch: 24/100] Loss: 0.221481  [32032/60000]\n",
            "[Epoch: 24/100] Loss: 0.182206  [35232/60000]\n",
            "[Epoch: 24/100] Loss: 0.282747  [38432/60000]\n",
            "[Epoch: 24/100] Loss: 0.517210  [41632/60000]\n",
            "[Epoch: 24/100] Loss: 0.194128  [44832/60000]\n",
            "[Epoch: 24/100] Loss: 0.222066  [48032/60000]\n",
            "[Epoch: 24/100] Loss: 0.464975  [51232/60000]\n",
            "[Epoch: 24/100] Loss: 0.323230  [54432/60000]\n",
            "[Epoch: 24/100] Loss: 0.267762  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.279471 \n",
            "\n",
            "[Epoch: 25/100] Loss: 0.271819  [   32/60000]\n",
            "[Epoch: 25/100] Loss: 0.372597  [ 3232/60000]\n",
            "[Epoch: 25/100] Loss: 0.150598  [ 6432/60000]\n",
            "[Epoch: 25/100] Loss: 0.307306  [ 9632/60000]\n",
            "[Epoch: 25/100] Loss: 0.292334  [12832/60000]\n",
            "[Epoch: 25/100] Loss: 0.178495  [16032/60000]\n",
            "[Epoch: 25/100] Loss: 0.167305  [19232/60000]\n",
            "[Epoch: 25/100] Loss: 0.429348  [22432/60000]\n",
            "[Epoch: 25/100] Loss: 0.076845  [25632/60000]\n",
            "[Epoch: 25/100] Loss: 0.461533  [28832/60000]\n",
            "[Epoch: 25/100] Loss: 0.357322  [32032/60000]\n",
            "[Epoch: 25/100] Loss: 0.153060  [35232/60000]\n",
            "[Epoch: 25/100] Loss: 0.301845  [38432/60000]\n",
            "[Epoch: 25/100] Loss: 0.200261  [41632/60000]\n",
            "[Epoch: 25/100] Loss: 0.123717  [44832/60000]\n",
            "[Epoch: 25/100] Loss: 0.120646  [48032/60000]\n",
            "[Epoch: 25/100] Loss: 0.219431  [51232/60000]\n",
            "[Epoch: 25/100] Loss: 0.137793  [54432/60000]\n",
            "[Epoch: 25/100] Loss: 0.335645  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.275780 \n",
            "\n",
            "[Epoch: 26/100] Loss: 0.215237  [   32/60000]\n",
            "[Epoch: 26/100] Loss: 0.212618  [ 3232/60000]\n",
            "[Epoch: 26/100] Loss: 0.233470  [ 6432/60000]\n",
            "[Epoch: 26/100] Loss: 0.193082  [ 9632/60000]\n",
            "[Epoch: 26/100] Loss: 0.546014  [12832/60000]\n",
            "[Epoch: 26/100] Loss: 0.173738  [16032/60000]\n",
            "[Epoch: 26/100] Loss: 0.185855  [19232/60000]\n",
            "[Epoch: 26/100] Loss: 0.236351  [22432/60000]\n",
            "[Epoch: 26/100] Loss: 0.376926  [25632/60000]\n",
            "[Epoch: 26/100] Loss: 0.284211  [28832/60000]\n",
            "[Epoch: 26/100] Loss: 0.073266  [32032/60000]\n",
            "[Epoch: 26/100] Loss: 0.074192  [35232/60000]\n",
            "[Epoch: 26/100] Loss: 0.191859  [38432/60000]\n",
            "[Epoch: 26/100] Loss: 0.411362  [41632/60000]\n",
            "[Epoch: 26/100] Loss: 0.296558  [44832/60000]\n",
            "[Epoch: 26/100] Loss: 0.387045  [48032/60000]\n",
            "[Epoch: 26/100] Loss: 0.293408  [51232/60000]\n",
            "[Epoch: 26/100] Loss: 0.263680  [54432/60000]\n",
            "[Epoch: 26/100] Loss: 0.219186  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.270677 \n",
            "\n",
            "[Epoch: 27/100] Loss: 0.148326  [   32/60000]\n",
            "[Epoch: 27/100] Loss: 0.246472  [ 3232/60000]\n",
            "[Epoch: 27/100] Loss: 0.192380  [ 6432/60000]\n",
            "[Epoch: 27/100] Loss: 0.397481  [ 9632/60000]\n",
            "[Epoch: 27/100] Loss: 0.165819  [12832/60000]\n",
            "[Epoch: 27/100] Loss: 0.368065  [16032/60000]\n",
            "[Epoch: 27/100] Loss: 0.110158  [19232/60000]\n",
            "[Epoch: 27/100] Loss: 0.241637  [22432/60000]\n",
            "[Epoch: 27/100] Loss: 0.152403  [25632/60000]\n",
            "[Epoch: 27/100] Loss: 0.138383  [28832/60000]\n",
            "[Epoch: 27/100] Loss: 0.259079  [32032/60000]\n",
            "[Epoch: 27/100] Loss: 0.688820  [35232/60000]\n",
            "[Epoch: 27/100] Loss: 0.324283  [38432/60000]\n",
            "[Epoch: 27/100] Loss: 0.165975  [41632/60000]\n",
            "[Epoch: 27/100] Loss: 0.242690  [44832/60000]\n",
            "[Epoch: 27/100] Loss: 0.162248  [48032/60000]\n",
            "[Epoch: 27/100] Loss: 0.161417  [51232/60000]\n",
            "[Epoch: 27/100] Loss: 0.443395  [54432/60000]\n",
            "[Epoch: 27/100] Loss: 0.222345  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.267412 \n",
            "\n",
            "[Epoch: 28/100] Loss: 0.304725  [   32/60000]\n",
            "[Epoch: 28/100] Loss: 0.203973  [ 3232/60000]\n",
            "[Epoch: 28/100] Loss: 0.373598  [ 6432/60000]\n",
            "[Epoch: 28/100] Loss: 0.280733  [ 9632/60000]\n",
            "[Epoch: 28/100] Loss: 0.525841  [12832/60000]\n",
            "[Epoch: 28/100] Loss: 0.186535  [16032/60000]\n",
            "[Epoch: 28/100] Loss: 0.496939  [19232/60000]\n",
            "[Epoch: 28/100] Loss: 0.248966  [22432/60000]\n",
            "[Epoch: 28/100] Loss: 0.580164  [25632/60000]\n",
            "[Epoch: 28/100] Loss: 0.165233  [28832/60000]\n",
            "[Epoch: 28/100] Loss: 0.370220  [32032/60000]\n",
            "[Epoch: 28/100] Loss: 0.172068  [35232/60000]\n",
            "[Epoch: 28/100] Loss: 0.146258  [38432/60000]\n",
            "[Epoch: 28/100] Loss: 0.455886  [41632/60000]\n",
            "[Epoch: 28/100] Loss: 0.497500  [44832/60000]\n",
            "[Epoch: 28/100] Loss: 0.372859  [48032/60000]\n",
            "[Epoch: 28/100] Loss: 0.326891  [51232/60000]\n",
            "[Epoch: 28/100] Loss: 0.267959  [54432/60000]\n",
            "[Epoch: 28/100] Loss: 0.307725  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.5%, Avg loss: 0.263635 \n",
            "\n",
            "[Epoch: 29/100] Loss: 0.252608  [   32/60000]\n",
            "[Epoch: 29/100] Loss: 0.298141  [ 3232/60000]\n",
            "[Epoch: 29/100] Loss: 0.338296  [ 6432/60000]\n",
            "[Epoch: 29/100] Loss: 0.248255  [ 9632/60000]\n",
            "[Epoch: 29/100] Loss: 0.082238  [12832/60000]\n",
            "[Epoch: 29/100] Loss: 0.155267  [16032/60000]\n",
            "[Epoch: 29/100] Loss: 0.145493  [19232/60000]\n",
            "[Epoch: 29/100] Loss: 0.252649  [22432/60000]\n",
            "[Epoch: 29/100] Loss: 0.199083  [25632/60000]\n",
            "[Epoch: 29/100] Loss: 0.136643  [28832/60000]\n",
            "[Epoch: 29/100] Loss: 0.159255  [32032/60000]\n",
            "[Epoch: 29/100] Loss: 0.214361  [35232/60000]\n",
            "[Epoch: 29/100] Loss: 0.147781  [38432/60000]\n",
            "[Epoch: 29/100] Loss: 0.462483  [41632/60000]\n",
            "[Epoch: 29/100] Loss: 0.287233  [44832/60000]\n",
            "[Epoch: 29/100] Loss: 0.118668  [48032/60000]\n",
            "[Epoch: 29/100] Loss: 0.157135  [51232/60000]\n",
            "[Epoch: 29/100] Loss: 0.513100  [54432/60000]\n",
            "[Epoch: 29/100] Loss: 0.368168  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.260599 \n",
            "\n",
            "[Epoch: 30/100] Loss: 0.325201  [   32/60000]\n",
            "[Epoch: 30/100] Loss: 0.446715  [ 3232/60000]\n",
            "[Epoch: 30/100] Loss: 0.096923  [ 6432/60000]\n",
            "[Epoch: 30/100] Loss: 0.333248  [ 9632/60000]\n",
            "[Epoch: 30/100] Loss: 0.384758  [12832/60000]\n",
            "[Epoch: 30/100] Loss: 0.397531  [16032/60000]\n",
            "[Epoch: 30/100] Loss: 0.313210  [19232/60000]\n",
            "[Epoch: 30/100] Loss: 0.113406  [22432/60000]\n",
            "[Epoch: 30/100] Loss: 0.181484  [25632/60000]\n",
            "[Epoch: 30/100] Loss: 0.760116  [28832/60000]\n",
            "[Epoch: 30/100] Loss: 0.232383  [32032/60000]\n",
            "[Epoch: 30/100] Loss: 0.171465  [35232/60000]\n",
            "[Epoch: 30/100] Loss: 0.197061  [38432/60000]\n",
            "[Epoch: 30/100] Loss: 0.242711  [41632/60000]\n",
            "[Epoch: 30/100] Loss: 0.446649  [44832/60000]\n",
            "[Epoch: 30/100] Loss: 0.326068  [48032/60000]\n",
            "[Epoch: 30/100] Loss: 0.175577  [51232/60000]\n",
            "[Epoch: 30/100] Loss: 0.149240  [54432/60000]\n",
            "[Epoch: 30/100] Loss: 0.139030  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.256657 \n",
            "\n",
            "[Epoch: 31/100] Loss: 0.290096  [   32/60000]\n",
            "[Epoch: 31/100] Loss: 0.248490  [ 3232/60000]\n",
            "[Epoch: 31/100] Loss: 0.157963  [ 6432/60000]\n",
            "[Epoch: 31/100] Loss: 0.282434  [ 9632/60000]\n",
            "[Epoch: 31/100] Loss: 0.080828  [12832/60000]\n",
            "[Epoch: 31/100] Loss: 0.131690  [16032/60000]\n",
            "[Epoch: 31/100] Loss: 0.233319  [19232/60000]\n",
            "[Epoch: 31/100] Loss: 0.370017  [22432/60000]\n",
            "[Epoch: 31/100] Loss: 0.136563  [25632/60000]\n",
            "[Epoch: 31/100] Loss: 0.191747  [28832/60000]\n",
            "[Epoch: 31/100] Loss: 0.059290  [32032/60000]\n",
            "[Epoch: 31/100] Loss: 0.259977  [35232/60000]\n",
            "[Epoch: 31/100] Loss: 0.271074  [38432/60000]\n",
            "[Epoch: 31/100] Loss: 0.401986  [41632/60000]\n",
            "[Epoch: 31/100] Loss: 0.260486  [44832/60000]\n",
            "[Epoch: 31/100] Loss: 0.219132  [48032/60000]\n",
            "[Epoch: 31/100] Loss: 0.570232  [51232/60000]\n",
            "[Epoch: 31/100] Loss: 0.244194  [54432/60000]\n",
            "[Epoch: 31/100] Loss: 0.368936  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.254069 \n",
            "\n",
            "[Epoch: 32/100] Loss: 0.220955  [   32/60000]\n",
            "[Epoch: 32/100] Loss: 0.166107  [ 3232/60000]\n",
            "[Epoch: 32/100] Loss: 0.176399  [ 6432/60000]\n",
            "[Epoch: 32/100] Loss: 0.240834  [ 9632/60000]\n",
            "[Epoch: 32/100] Loss: 0.149364  [12832/60000]\n",
            "[Epoch: 32/100] Loss: 0.255477  [16032/60000]\n",
            "[Epoch: 32/100] Loss: 0.255859  [19232/60000]\n",
            "[Epoch: 32/100] Loss: 0.079677  [22432/60000]\n",
            "[Epoch: 32/100] Loss: 0.094139  [25632/60000]\n",
            "[Epoch: 32/100] Loss: 0.353440  [28832/60000]\n",
            "[Epoch: 32/100] Loss: 0.397032  [32032/60000]\n",
            "[Epoch: 32/100] Loss: 0.264800  [35232/60000]\n",
            "[Epoch: 32/100] Loss: 0.192308  [38432/60000]\n",
            "[Epoch: 32/100] Loss: 0.125304  [41632/60000]\n",
            "[Epoch: 32/100] Loss: 0.574581  [44832/60000]\n",
            "[Epoch: 32/100] Loss: 0.173544  [48032/60000]\n",
            "[Epoch: 32/100] Loss: 0.323128  [51232/60000]\n",
            "[Epoch: 32/100] Loss: 0.245227  [54432/60000]\n",
            "[Epoch: 32/100] Loss: 0.387759  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.251007 \n",
            "\n",
            "[Epoch: 33/100] Loss: 0.219481  [   32/60000]\n",
            "[Epoch: 33/100] Loss: 0.395703  [ 3232/60000]\n",
            "[Epoch: 33/100] Loss: 0.166693  [ 6432/60000]\n",
            "[Epoch: 33/100] Loss: 0.339533  [ 9632/60000]\n",
            "[Epoch: 33/100] Loss: 0.182547  [12832/60000]\n",
            "[Epoch: 33/100] Loss: 0.099134  [16032/60000]\n",
            "[Epoch: 33/100] Loss: 0.229196  [19232/60000]\n",
            "[Epoch: 33/100] Loss: 0.372326  [22432/60000]\n",
            "[Epoch: 33/100] Loss: 0.166513  [25632/60000]\n",
            "[Epoch: 33/100] Loss: 0.141773  [28832/60000]\n",
            "[Epoch: 33/100] Loss: 0.165918  [32032/60000]\n",
            "[Epoch: 33/100] Loss: 0.274902  [35232/60000]\n",
            "[Epoch: 33/100] Loss: 0.294256  [38432/60000]\n",
            "[Epoch: 33/100] Loss: 0.377987  [41632/60000]\n",
            "[Epoch: 33/100] Loss: 0.241876  [44832/60000]\n",
            "[Epoch: 33/100] Loss: 0.177266  [48032/60000]\n",
            "[Epoch: 33/100] Loss: 0.288309  [51232/60000]\n",
            "[Epoch: 33/100] Loss: 0.460321  [54432/60000]\n",
            "[Epoch: 33/100] Loss: 0.203206  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247635 \n",
            "\n",
            "[Epoch: 34/100] Loss: 0.146728  [   32/60000]\n",
            "[Epoch: 34/100] Loss: 0.206840  [ 3232/60000]\n",
            "[Epoch: 34/100] Loss: 0.241992  [ 6432/60000]\n",
            "[Epoch: 34/100] Loss: 0.555226  [ 9632/60000]\n",
            "[Epoch: 34/100] Loss: 0.059708  [12832/60000]\n",
            "[Epoch: 34/100] Loss: 0.062347  [16032/60000]\n",
            "[Epoch: 34/100] Loss: 0.209994  [19232/60000]\n",
            "[Epoch: 34/100] Loss: 0.119581  [22432/60000]\n",
            "[Epoch: 34/100] Loss: 0.138126  [25632/60000]\n",
            "[Epoch: 34/100] Loss: 0.287183  [28832/60000]\n",
            "[Epoch: 34/100] Loss: 0.182306  [32032/60000]\n",
            "[Epoch: 34/100] Loss: 0.477582  [35232/60000]\n",
            "[Epoch: 34/100] Loss: 0.141970  [38432/60000]\n",
            "[Epoch: 34/100] Loss: 0.045829  [41632/60000]\n",
            "[Epoch: 34/100] Loss: 0.422507  [44832/60000]\n",
            "[Epoch: 34/100] Loss: 0.144274  [48032/60000]\n",
            "[Epoch: 34/100] Loss: 0.572837  [51232/60000]\n",
            "[Epoch: 34/100] Loss: 0.157776  [54432/60000]\n",
            "[Epoch: 34/100] Loss: 0.128962  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.244574 \n",
            "\n",
            "[Epoch: 35/100] Loss: 0.285825  [   32/60000]\n",
            "[Epoch: 35/100] Loss: 0.323452  [ 3232/60000]\n",
            "[Epoch: 35/100] Loss: 0.348990  [ 6432/60000]\n",
            "[Epoch: 35/100] Loss: 0.221758  [ 9632/60000]\n",
            "[Epoch: 35/100] Loss: 0.257790  [12832/60000]\n",
            "[Epoch: 35/100] Loss: 0.178553  [16032/60000]\n",
            "[Epoch: 35/100] Loss: 0.171336  [19232/60000]\n",
            "[Epoch: 35/100] Loss: 0.335218  [22432/60000]\n",
            "[Epoch: 35/100] Loss: 0.058339  [25632/60000]\n",
            "[Epoch: 35/100] Loss: 0.382032  [28832/60000]\n",
            "[Epoch: 35/100] Loss: 0.322986  [32032/60000]\n",
            "[Epoch: 35/100] Loss: 0.219055  [35232/60000]\n",
            "[Epoch: 35/100] Loss: 0.618175  [38432/60000]\n",
            "[Epoch: 35/100] Loss: 0.371154  [41632/60000]\n",
            "[Epoch: 35/100] Loss: 0.357502  [44832/60000]\n",
            "[Epoch: 35/100] Loss: 0.168598  [48032/60000]\n",
            "[Epoch: 35/100] Loss: 0.151629  [51232/60000]\n",
            "[Epoch: 35/100] Loss: 0.253684  [54432/60000]\n",
            "[Epoch: 35/100] Loss: 0.207091  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.240826 \n",
            "\n",
            "[Epoch: 36/100] Loss: 0.191080  [   32/60000]\n",
            "[Epoch: 36/100] Loss: 0.173824  [ 3232/60000]\n",
            "[Epoch: 36/100] Loss: 0.396572  [ 6432/60000]\n",
            "[Epoch: 36/100] Loss: 0.459967  [ 9632/60000]\n",
            "[Epoch: 36/100] Loss: 0.334949  [12832/60000]\n",
            "[Epoch: 36/100] Loss: 0.373604  [16032/60000]\n",
            "[Epoch: 36/100] Loss: 0.157535  [19232/60000]\n",
            "[Epoch: 36/100] Loss: 0.202100  [22432/60000]\n",
            "[Epoch: 36/100] Loss: 0.167876  [25632/60000]\n",
            "[Epoch: 36/100] Loss: 0.287384  [28832/60000]\n",
            "[Epoch: 36/100] Loss: 0.224945  [32032/60000]\n",
            "[Epoch: 36/100] Loss: 0.110221  [35232/60000]\n",
            "[Epoch: 36/100] Loss: 0.233066  [38432/60000]\n",
            "[Epoch: 36/100] Loss: 0.135938  [41632/60000]\n",
            "[Epoch: 36/100] Loss: 0.096879  [44832/60000]\n",
            "[Epoch: 36/100] Loss: 0.153138  [48032/60000]\n",
            "[Epoch: 36/100] Loss: 0.060755  [51232/60000]\n",
            "[Epoch: 36/100] Loss: 0.091419  [54432/60000]\n",
            "[Epoch: 36/100] Loss: 0.220616  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.3%, Avg loss: 0.238249 \n",
            "\n",
            "[Epoch: 37/100] Loss: 0.325649  [   32/60000]\n",
            "[Epoch: 37/100] Loss: 0.104292  [ 3232/60000]\n",
            "[Epoch: 37/100] Loss: 0.293822  [ 6432/60000]\n",
            "[Epoch: 37/100] Loss: 0.130746  [ 9632/60000]\n",
            "[Epoch: 37/100] Loss: 0.233634  [12832/60000]\n",
            "[Epoch: 37/100] Loss: 0.410787  [16032/60000]\n",
            "[Epoch: 37/100] Loss: 0.198624  [19232/60000]\n",
            "[Epoch: 37/100] Loss: 0.129894  [22432/60000]\n",
            "[Epoch: 37/100] Loss: 0.270137  [25632/60000]\n",
            "[Epoch: 37/100] Loss: 0.172650  [28832/60000]\n",
            "[Epoch: 37/100] Loss: 0.144896  [32032/60000]\n",
            "[Epoch: 37/100] Loss: 0.327336  [35232/60000]\n",
            "[Epoch: 37/100] Loss: 0.272650  [38432/60000]\n",
            "[Epoch: 37/100] Loss: 0.121136  [41632/60000]\n",
            "[Epoch: 37/100] Loss: 0.236001  [44832/60000]\n",
            "[Epoch: 37/100] Loss: 0.221446  [48032/60000]\n",
            "[Epoch: 37/100] Loss: 0.145436  [51232/60000]\n",
            "[Epoch: 37/100] Loss: 0.123552  [54432/60000]\n",
            "[Epoch: 37/100] Loss: 0.247613  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.3%, Avg loss: 0.235166 \n",
            "\n",
            "[Epoch: 38/100] Loss: 0.269354  [   32/60000]\n",
            "[Epoch: 38/100] Loss: 0.225838  [ 3232/60000]\n",
            "[Epoch: 38/100] Loss: 0.280172  [ 6432/60000]\n",
            "[Epoch: 38/100] Loss: 0.178752  [ 9632/60000]\n",
            "[Epoch: 38/100] Loss: 0.629596  [12832/60000]\n",
            "[Epoch: 38/100] Loss: 0.198268  [16032/60000]\n",
            "[Epoch: 38/100] Loss: 0.377676  [19232/60000]\n",
            "[Epoch: 38/100] Loss: 0.454690  [22432/60000]\n",
            "[Epoch: 38/100] Loss: 0.372993  [25632/60000]\n",
            "[Epoch: 38/100] Loss: 0.304725  [28832/60000]\n",
            "[Epoch: 38/100] Loss: 0.604141  [32032/60000]\n",
            "[Epoch: 38/100] Loss: 0.106763  [35232/60000]\n",
            "[Epoch: 38/100] Loss: 0.042330  [38432/60000]\n",
            "[Epoch: 38/100] Loss: 0.117072  [41632/60000]\n",
            "[Epoch: 38/100] Loss: 0.276160  [44832/60000]\n",
            "[Epoch: 38/100] Loss: 0.180662  [48032/60000]\n",
            "[Epoch: 38/100] Loss: 0.087995  [51232/60000]\n",
            "[Epoch: 38/100] Loss: 0.047989  [54432/60000]\n",
            "[Epoch: 38/100] Loss: 0.349863  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.232398 \n",
            "\n",
            "[Epoch: 39/100] Loss: 0.080862  [   32/60000]\n",
            "[Epoch: 39/100] Loss: 0.219620  [ 3232/60000]\n",
            "[Epoch: 39/100] Loss: 0.071595  [ 6432/60000]\n",
            "[Epoch: 39/100] Loss: 0.473167  [ 9632/60000]\n",
            "[Epoch: 39/100] Loss: 0.330115  [12832/60000]\n",
            "[Epoch: 39/100] Loss: 0.136535  [16032/60000]\n",
            "[Epoch: 39/100] Loss: 0.345292  [19232/60000]\n",
            "[Epoch: 39/100] Loss: 0.131784  [22432/60000]\n",
            "[Epoch: 39/100] Loss: 0.106877  [25632/60000]\n",
            "[Epoch: 39/100] Loss: 0.218559  [28832/60000]\n",
            "[Epoch: 39/100] Loss: 0.212345  [32032/60000]\n",
            "[Epoch: 39/100] Loss: 0.272973  [35232/60000]\n",
            "[Epoch: 39/100] Loss: 0.249554  [38432/60000]\n",
            "[Epoch: 39/100] Loss: 0.098376  [41632/60000]\n",
            "[Epoch: 39/100] Loss: 0.402256  [44832/60000]\n",
            "[Epoch: 39/100] Loss: 0.288240  [48032/60000]\n",
            "[Epoch: 39/100] Loss: 0.139123  [51232/60000]\n",
            "[Epoch: 39/100] Loss: 0.111900  [54432/60000]\n",
            "[Epoch: 39/100] Loss: 0.222083  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.230113 \n",
            "\n",
            "[Epoch: 40/100] Loss: 0.070909  [   32/60000]\n",
            "[Epoch: 40/100] Loss: 0.177611  [ 3232/60000]\n",
            "[Epoch: 40/100] Loss: 0.461583  [ 6432/60000]\n",
            "[Epoch: 40/100] Loss: 0.799156  [ 9632/60000]\n",
            "[Epoch: 40/100] Loss: 0.232159  [12832/60000]\n",
            "[Epoch: 40/100] Loss: 0.343442  [16032/60000]\n",
            "[Epoch: 40/100] Loss: 0.232783  [19232/60000]\n",
            "[Epoch: 40/100] Loss: 0.138709  [22432/60000]\n",
            "[Epoch: 40/100] Loss: 0.442206  [25632/60000]\n",
            "[Epoch: 40/100] Loss: 0.094439  [28832/60000]\n",
            "[Epoch: 40/100] Loss: 0.339032  [32032/60000]\n",
            "[Epoch: 40/100] Loss: 0.262725  [35232/60000]\n",
            "[Epoch: 40/100] Loss: 0.126369  [38432/60000]\n",
            "[Epoch: 40/100] Loss: 0.326832  [41632/60000]\n",
            "[Epoch: 40/100] Loss: 0.349785  [44832/60000]\n",
            "[Epoch: 40/100] Loss: 0.451179  [48032/60000]\n",
            "[Epoch: 40/100] Loss: 0.225723  [51232/60000]\n",
            "[Epoch: 40/100] Loss: 0.281003  [54432/60000]\n",
            "[Epoch: 40/100] Loss: 0.379461  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.227637 \n",
            "\n",
            "[Epoch: 41/100] Loss: 0.197568  [   32/60000]\n",
            "[Epoch: 41/100] Loss: 0.273541  [ 3232/60000]\n",
            "[Epoch: 41/100] Loss: 0.442127  [ 6432/60000]\n",
            "[Epoch: 41/100] Loss: 0.266246  [ 9632/60000]\n",
            "[Epoch: 41/100] Loss: 0.212695  [12832/60000]\n",
            "[Epoch: 41/100] Loss: 0.247262  [16032/60000]\n",
            "[Epoch: 41/100] Loss: 0.302545  [19232/60000]\n",
            "[Epoch: 41/100] Loss: 0.084305  [22432/60000]\n",
            "[Epoch: 41/100] Loss: 0.152333  [25632/60000]\n",
            "[Epoch: 41/100] Loss: 0.342913  [28832/60000]\n",
            "[Epoch: 41/100] Loss: 0.128505  [32032/60000]\n",
            "[Epoch: 41/100] Loss: 0.226421  [35232/60000]\n",
            "[Epoch: 41/100] Loss: 0.182658  [38432/60000]\n",
            "[Epoch: 41/100] Loss: 0.204507  [41632/60000]\n",
            "[Epoch: 41/100] Loss: 0.531950  [44832/60000]\n",
            "[Epoch: 41/100] Loss: 0.284324  [48032/60000]\n",
            "[Epoch: 41/100] Loss: 0.141845  [51232/60000]\n",
            "[Epoch: 41/100] Loss: 0.317918  [54432/60000]\n",
            "[Epoch: 41/100] Loss: 0.165913  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.225176 \n",
            "\n",
            "[Epoch: 42/100] Loss: 0.245517  [   32/60000]\n",
            "[Epoch: 42/100] Loss: 0.168840  [ 3232/60000]\n",
            "[Epoch: 42/100] Loss: 0.190997  [ 6432/60000]\n",
            "[Epoch: 42/100] Loss: 0.515167  [ 9632/60000]\n",
            "[Epoch: 42/100] Loss: 0.121684  [12832/60000]\n",
            "[Epoch: 42/100] Loss: 0.174786  [16032/60000]\n",
            "[Epoch: 42/100] Loss: 0.146695  [19232/60000]\n",
            "[Epoch: 42/100] Loss: 0.092584  [22432/60000]\n",
            "[Epoch: 42/100] Loss: 0.057635  [25632/60000]\n",
            "[Epoch: 42/100] Loss: 0.301064  [28832/60000]\n",
            "[Epoch: 42/100] Loss: 0.331331  [32032/60000]\n",
            "[Epoch: 42/100] Loss: 0.094232  [35232/60000]\n",
            "[Epoch: 42/100] Loss: 0.456377  [38432/60000]\n",
            "[Epoch: 42/100] Loss: 0.261299  [41632/60000]\n",
            "[Epoch: 42/100] Loss: 0.368186  [44832/60000]\n",
            "[Epoch: 42/100] Loss: 0.221089  [48032/60000]\n",
            "[Epoch: 42/100] Loss: 0.305412  [51232/60000]\n",
            "[Epoch: 42/100] Loss: 0.368930  [54432/60000]\n",
            "[Epoch: 42/100] Loss: 0.199881  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.222248 \n",
            "\n",
            "[Epoch: 43/100] Loss: 0.124494  [   32/60000]\n",
            "[Epoch: 43/100] Loss: 0.159298  [ 3232/60000]\n",
            "[Epoch: 43/100] Loss: 0.182674  [ 6432/60000]\n",
            "[Epoch: 43/100] Loss: 0.076005  [ 9632/60000]\n",
            "[Epoch: 43/100] Loss: 0.231634  [12832/60000]\n",
            "[Epoch: 43/100] Loss: 0.361795  [16032/60000]\n",
            "[Epoch: 43/100] Loss: 0.231217  [19232/60000]\n",
            "[Epoch: 43/100] Loss: 0.253672  [22432/60000]\n",
            "[Epoch: 43/100] Loss: 0.196034  [25632/60000]\n",
            "[Epoch: 43/100] Loss: 0.305842  [28832/60000]\n",
            "[Epoch: 43/100] Loss: 0.231887  [32032/60000]\n",
            "[Epoch: 43/100] Loss: 0.206132  [35232/60000]\n",
            "[Epoch: 43/100] Loss: 0.169846  [38432/60000]\n",
            "[Epoch: 43/100] Loss: 0.236405  [41632/60000]\n",
            "[Epoch: 43/100] Loss: 0.081943  [44832/60000]\n",
            "[Epoch: 43/100] Loss: 0.160348  [48032/60000]\n",
            "[Epoch: 43/100] Loss: 0.152574  [51232/60000]\n",
            "[Epoch: 43/100] Loss: 0.191288  [54432/60000]\n",
            "[Epoch: 43/100] Loss: 0.065500  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.219328 \n",
            "\n",
            "[Epoch: 44/100] Loss: 0.102102  [   32/60000]\n",
            "[Epoch: 44/100] Loss: 0.435080  [ 3232/60000]\n",
            "[Epoch: 44/100] Loss: 0.543130  [ 6432/60000]\n",
            "[Epoch: 44/100] Loss: 0.152703  [ 9632/60000]\n",
            "[Epoch: 44/100] Loss: 0.081284  [12832/60000]\n",
            "[Epoch: 44/100] Loss: 0.110979  [16032/60000]\n",
            "[Epoch: 44/100] Loss: 0.087983  [19232/60000]\n",
            "[Epoch: 44/100] Loss: 0.079742  [22432/60000]\n",
            "[Epoch: 44/100] Loss: 0.048606  [25632/60000]\n",
            "[Epoch: 44/100] Loss: 0.408375  [28832/60000]\n",
            "[Epoch: 44/100] Loss: 0.175085  [32032/60000]\n",
            "[Epoch: 44/100] Loss: 0.219107  [35232/60000]\n",
            "[Epoch: 44/100] Loss: 0.210344  [38432/60000]\n",
            "[Epoch: 44/100] Loss: 0.092833  [41632/60000]\n",
            "[Epoch: 44/100] Loss: 0.158727  [44832/60000]\n",
            "[Epoch: 44/100] Loss: 0.349434  [48032/60000]\n",
            "[Epoch: 44/100] Loss: 0.076444  [51232/60000]\n",
            "[Epoch: 44/100] Loss: 0.135772  [54432/60000]\n",
            "[Epoch: 44/100] Loss: 0.179390  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.216556 \n",
            "\n",
            "[Epoch: 45/100] Loss: 0.224164  [   32/60000]\n",
            "[Epoch: 45/100] Loss: 0.153246  [ 3232/60000]\n",
            "[Epoch: 45/100] Loss: 0.241333  [ 6432/60000]\n",
            "[Epoch: 45/100] Loss: 0.159415  [ 9632/60000]\n",
            "[Epoch: 45/100] Loss: 0.344893  [12832/60000]\n",
            "[Epoch: 45/100] Loss: 0.071029  [16032/60000]\n",
            "[Epoch: 45/100] Loss: 0.065602  [19232/60000]\n",
            "[Epoch: 45/100] Loss: 0.113863  [22432/60000]\n",
            "[Epoch: 45/100] Loss: 0.160458  [25632/60000]\n",
            "[Epoch: 45/100] Loss: 0.272750  [28832/60000]\n",
            "[Epoch: 45/100] Loss: 0.199919  [32032/60000]\n",
            "[Epoch: 45/100] Loss: 0.430303  [35232/60000]\n",
            "[Epoch: 45/100] Loss: 0.303282  [38432/60000]\n",
            "[Epoch: 45/100] Loss: 0.064330  [41632/60000]\n",
            "[Epoch: 45/100] Loss: 0.195872  [44832/60000]\n",
            "[Epoch: 45/100] Loss: 0.248613  [48032/60000]\n",
            "[Epoch: 45/100] Loss: 0.482124  [51232/60000]\n",
            "[Epoch: 45/100] Loss: 0.233057  [54432/60000]\n",
            "[Epoch: 45/100] Loss: 0.025690  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.214061 \n",
            "\n",
            "[Epoch: 46/100] Loss: 0.117079  [   32/60000]\n",
            "[Epoch: 46/100] Loss: 0.279191  [ 3232/60000]\n",
            "[Epoch: 46/100] Loss: 0.434101  [ 6432/60000]\n",
            "[Epoch: 46/100] Loss: 0.247472  [ 9632/60000]\n",
            "[Epoch: 46/100] Loss: 0.091606  [12832/60000]\n",
            "[Epoch: 46/100] Loss: 0.128735  [16032/60000]\n",
            "[Epoch: 46/100] Loss: 0.314731  [19232/60000]\n",
            "[Epoch: 46/100] Loss: 0.275911  [22432/60000]\n",
            "[Epoch: 46/100] Loss: 0.127499  [25632/60000]\n",
            "[Epoch: 46/100] Loss: 0.104022  [28832/60000]\n",
            "[Epoch: 46/100] Loss: 0.321863  [32032/60000]\n",
            "[Epoch: 46/100] Loss: 0.178888  [35232/60000]\n",
            "[Epoch: 46/100] Loss: 0.271253  [38432/60000]\n",
            "[Epoch: 46/100] Loss: 0.080267  [41632/60000]\n",
            "[Epoch: 46/100] Loss: 0.444568  [44832/60000]\n",
            "[Epoch: 46/100] Loss: 0.149865  [48032/60000]\n",
            "[Epoch: 46/100] Loss: 0.060266  [51232/60000]\n",
            "[Epoch: 46/100] Loss: 0.186208  [54432/60000]\n",
            "[Epoch: 46/100] Loss: 0.164441  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.212453 \n",
            "\n",
            "[Epoch: 47/100] Loss: 0.054350  [   32/60000]\n",
            "[Epoch: 47/100] Loss: 0.341344  [ 3232/60000]\n",
            "[Epoch: 47/100] Loss: 0.235088  [ 6432/60000]\n",
            "[Epoch: 47/100] Loss: 0.053463  [ 9632/60000]\n",
            "[Epoch: 47/100] Loss: 0.165501  [12832/60000]\n",
            "[Epoch: 47/100] Loss: 0.151167  [16032/60000]\n",
            "[Epoch: 47/100] Loss: 0.208773  [19232/60000]\n",
            "[Epoch: 47/100] Loss: 0.181621  [22432/60000]\n",
            "[Epoch: 47/100] Loss: 0.281530  [25632/60000]\n",
            "[Epoch: 47/100] Loss: 0.272325  [28832/60000]\n",
            "[Epoch: 47/100] Loss: 0.285806  [32032/60000]\n",
            "[Epoch: 47/100] Loss: 0.160864  [35232/60000]\n",
            "[Epoch: 47/100] Loss: 0.320001  [38432/60000]\n",
            "[Epoch: 47/100] Loss: 0.134166  [41632/60000]\n",
            "[Epoch: 47/100] Loss: 0.132602  [44832/60000]\n",
            "[Epoch: 47/100] Loss: 0.304293  [48032/60000]\n",
            "[Epoch: 47/100] Loss: 0.277425  [51232/60000]\n",
            "[Epoch: 47/100] Loss: 0.051063  [54432/60000]\n",
            "[Epoch: 47/100] Loss: 0.232031  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.210039 \n",
            "\n",
            "[Epoch: 48/100] Loss: 0.105123  [   32/60000]\n",
            "[Epoch: 48/100] Loss: 0.079096  [ 3232/60000]\n",
            "[Epoch: 48/100] Loss: 0.210592  [ 6432/60000]\n",
            "[Epoch: 48/100] Loss: 0.104748  [ 9632/60000]\n",
            "[Epoch: 48/100] Loss: 0.311731  [12832/60000]\n",
            "[Epoch: 48/100] Loss: 0.349653  [16032/60000]\n",
            "[Epoch: 48/100] Loss: 0.186735  [19232/60000]\n",
            "[Epoch: 48/100] Loss: 0.172215  [22432/60000]\n",
            "[Epoch: 48/100] Loss: 0.135890  [25632/60000]\n",
            "[Epoch: 48/100] Loss: 0.485900  [28832/60000]\n",
            "[Epoch: 48/100] Loss: 0.183111  [32032/60000]\n",
            "[Epoch: 48/100] Loss: 0.182697  [35232/60000]\n",
            "[Epoch: 48/100] Loss: 0.445558  [38432/60000]\n",
            "[Epoch: 48/100] Loss: 0.084007  [41632/60000]\n",
            "[Epoch: 48/100] Loss: 0.198625  [44832/60000]\n",
            "[Epoch: 48/100] Loss: 0.119135  [48032/60000]\n",
            "[Epoch: 48/100] Loss: 0.217020  [51232/60000]\n",
            "[Epoch: 48/100] Loss: 0.213910  [54432/60000]\n",
            "[Epoch: 48/100] Loss: 0.201298  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.206978 \n",
            "\n",
            "[Epoch: 49/100] Loss: 0.430638  [   32/60000]\n",
            "[Epoch: 49/100] Loss: 0.292277  [ 3232/60000]\n",
            "[Epoch: 49/100] Loss: 0.241682  [ 6432/60000]\n",
            "[Epoch: 49/100] Loss: 0.330305  [ 9632/60000]\n",
            "[Epoch: 49/100] Loss: 0.019217  [12832/60000]\n",
            "[Epoch: 49/100] Loss: 0.347249  [16032/60000]\n",
            "[Epoch: 49/100] Loss: 0.189415  [19232/60000]\n",
            "[Epoch: 49/100] Loss: 0.281166  [22432/60000]\n",
            "[Epoch: 49/100] Loss: 0.278700  [25632/60000]\n",
            "[Epoch: 49/100] Loss: 0.266343  [28832/60000]\n",
            "[Epoch: 49/100] Loss: 0.035993  [32032/60000]\n",
            "[Epoch: 49/100] Loss: 0.114514  [35232/60000]\n",
            "[Epoch: 49/100] Loss: 0.130908  [38432/60000]\n",
            "[Epoch: 49/100] Loss: 0.082267  [41632/60000]\n",
            "[Epoch: 49/100] Loss: 0.257387  [44832/60000]\n",
            "[Epoch: 49/100] Loss: 0.261351  [48032/60000]\n",
            "[Epoch: 49/100] Loss: 0.171103  [51232/60000]\n",
            "[Epoch: 49/100] Loss: 0.179518  [54432/60000]\n",
            "[Epoch: 49/100] Loss: 0.124863  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.204750 \n",
            "\n",
            "[Epoch: 50/100] Loss: 0.441504  [   32/60000]\n",
            "[Epoch: 50/100] Loss: 0.033687  [ 3232/60000]\n",
            "[Epoch: 50/100] Loss: 0.309059  [ 6432/60000]\n",
            "[Epoch: 50/100] Loss: 0.157458  [ 9632/60000]\n",
            "[Epoch: 50/100] Loss: 0.117672  [12832/60000]\n",
            "[Epoch: 50/100] Loss: 0.103080  [16032/60000]\n",
            "[Epoch: 50/100] Loss: 0.204849  [19232/60000]\n",
            "[Epoch: 50/100] Loss: 0.253193  [22432/60000]\n",
            "[Epoch: 50/100] Loss: 0.177091  [25632/60000]\n",
            "[Epoch: 50/100] Loss: 0.197468  [28832/60000]\n",
            "[Epoch: 50/100] Loss: 0.354690  [32032/60000]\n",
            "[Epoch: 50/100] Loss: 0.182567  [35232/60000]\n",
            "[Epoch: 50/100] Loss: 0.434104  [38432/60000]\n",
            "[Epoch: 50/100] Loss: 0.414135  [41632/60000]\n",
            "[Epoch: 50/100] Loss: 0.107385  [44832/60000]\n",
            "[Epoch: 50/100] Loss: 0.060897  [48032/60000]\n",
            "[Epoch: 50/100] Loss: 0.069921  [51232/60000]\n",
            "[Epoch: 50/100] Loss: 0.114280  [54432/60000]\n",
            "[Epoch: 50/100] Loss: 0.387414  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.202619 \n",
            "\n",
            "[Epoch: 51/100] Loss: 0.363791  [   32/60000]\n",
            "[Epoch: 51/100] Loss: 0.173873  [ 3232/60000]\n",
            "[Epoch: 51/100] Loss: 0.104878  [ 6432/60000]\n",
            "[Epoch: 51/100] Loss: 0.288238  [ 9632/60000]\n",
            "[Epoch: 51/100] Loss: 0.111557  [12832/60000]\n",
            "[Epoch: 51/100] Loss: 0.115843  [16032/60000]\n",
            "[Epoch: 51/100] Loss: 0.231327  [19232/60000]\n",
            "[Epoch: 51/100] Loss: 0.096034  [22432/60000]\n",
            "[Epoch: 51/100] Loss: 0.126521  [25632/60000]\n",
            "[Epoch: 51/100] Loss: 0.181042  [28832/60000]\n",
            "[Epoch: 51/100] Loss: 0.502154  [32032/60000]\n",
            "[Epoch: 51/100] Loss: 0.154402  [35232/60000]\n",
            "[Epoch: 51/100] Loss: 0.222430  [38432/60000]\n",
            "[Epoch: 51/100] Loss: 0.089676  [41632/60000]\n",
            "[Epoch: 51/100] Loss: 0.183185  [44832/60000]\n",
            "[Epoch: 51/100] Loss: 0.071896  [48032/60000]\n",
            "[Epoch: 51/100] Loss: 0.324055  [51232/60000]\n",
            "[Epoch: 51/100] Loss: 0.226808  [54432/60000]\n",
            "[Epoch: 51/100] Loss: 0.665108  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.200455 \n",
            "\n",
            "[Epoch: 52/100] Loss: 0.632229  [   32/60000]\n",
            "[Epoch: 52/100] Loss: 0.201653  [ 3232/60000]\n",
            "[Epoch: 52/100] Loss: 0.130393  [ 6432/60000]\n",
            "[Epoch: 52/100] Loss: 0.190350  [ 9632/60000]\n",
            "[Epoch: 52/100] Loss: 0.100738  [12832/60000]\n",
            "[Epoch: 52/100] Loss: 0.130402  [16032/60000]\n",
            "[Epoch: 52/100] Loss: 0.236697  [19232/60000]\n",
            "[Epoch: 52/100] Loss: 0.112526  [22432/60000]\n",
            "[Epoch: 52/100] Loss: 0.313852  [25632/60000]\n",
            "[Epoch: 52/100] Loss: 0.073612  [28832/60000]\n",
            "[Epoch: 52/100] Loss: 0.168722  [32032/60000]\n",
            "[Epoch: 52/100] Loss: 0.100003  [35232/60000]\n",
            "[Epoch: 52/100] Loss: 0.273124  [38432/60000]\n",
            "[Epoch: 52/100] Loss: 0.087639  [41632/60000]\n",
            "[Epoch: 52/100] Loss: 0.136719  [44832/60000]\n",
            "[Epoch: 52/100] Loss: 0.340945  [48032/60000]\n",
            "[Epoch: 52/100] Loss: 0.551520  [51232/60000]\n",
            "[Epoch: 52/100] Loss: 0.201114  [54432/60000]\n",
            "[Epoch: 52/100] Loss: 0.182353  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.198748 \n",
            "\n",
            "[Epoch: 53/100] Loss: 0.184306  [   32/60000]\n",
            "[Epoch: 53/100] Loss: 0.167633  [ 3232/60000]\n",
            "[Epoch: 53/100] Loss: 0.115136  [ 6432/60000]\n",
            "[Epoch: 53/100] Loss: 0.108194  [ 9632/60000]\n",
            "[Epoch: 53/100] Loss: 0.220078  [12832/60000]\n",
            "[Epoch: 53/100] Loss: 0.319712  [16032/60000]\n",
            "[Epoch: 53/100] Loss: 0.408616  [19232/60000]\n",
            "[Epoch: 53/100] Loss: 0.153687  [22432/60000]\n",
            "[Epoch: 53/100] Loss: 0.325624  [25632/60000]\n",
            "[Epoch: 53/100] Loss: 0.336568  [28832/60000]\n",
            "[Epoch: 53/100] Loss: 0.126603  [32032/60000]\n",
            "[Epoch: 53/100] Loss: 0.042250  [35232/60000]\n",
            "[Epoch: 53/100] Loss: 0.131311  [38432/60000]\n",
            "[Epoch: 53/100] Loss: 0.248240  [41632/60000]\n",
            "[Epoch: 53/100] Loss: 0.194726  [44832/60000]\n",
            "[Epoch: 53/100] Loss: 0.182368  [48032/60000]\n",
            "[Epoch: 53/100] Loss: 0.209759  [51232/60000]\n",
            "[Epoch: 53/100] Loss: 0.199848  [54432/60000]\n",
            "[Epoch: 53/100] Loss: 0.176214  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.196029 \n",
            "\n",
            "[Epoch: 54/100] Loss: 0.282056  [   32/60000]\n",
            "[Epoch: 54/100] Loss: 0.076466  [ 3232/60000]\n",
            "[Epoch: 54/100] Loss: 0.137191  [ 6432/60000]\n",
            "[Epoch: 54/100] Loss: 0.437438  [ 9632/60000]\n",
            "[Epoch: 54/100] Loss: 0.090270  [12832/60000]\n",
            "[Epoch: 54/100] Loss: 0.164573  [16032/60000]\n",
            "[Epoch: 54/100] Loss: 0.231324  [19232/60000]\n",
            "[Epoch: 54/100] Loss: 0.171460  [22432/60000]\n",
            "[Epoch: 54/100] Loss: 0.159382  [25632/60000]\n",
            "[Epoch: 54/100] Loss: 0.151776  [28832/60000]\n",
            "[Epoch: 54/100] Loss: 0.143774  [32032/60000]\n",
            "[Epoch: 54/100] Loss: 0.079004  [35232/60000]\n",
            "[Epoch: 54/100] Loss: 0.135923  [38432/60000]\n",
            "[Epoch: 54/100] Loss: 0.199124  [41632/60000]\n",
            "[Epoch: 54/100] Loss: 0.070186  [44832/60000]\n",
            "[Epoch: 54/100] Loss: 0.149917  [48032/60000]\n",
            "[Epoch: 54/100] Loss: 0.199993  [51232/60000]\n",
            "[Epoch: 54/100] Loss: 0.137258  [54432/60000]\n",
            "[Epoch: 54/100] Loss: 0.116659  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.194721 \n",
            "\n",
            "[Epoch: 55/100] Loss: 0.143731  [   32/60000]\n",
            "[Epoch: 55/100] Loss: 0.041045  [ 3232/60000]\n",
            "[Epoch: 55/100] Loss: 0.318122  [ 6432/60000]\n",
            "[Epoch: 55/100] Loss: 0.084706  [ 9632/60000]\n",
            "[Epoch: 55/100] Loss: 0.097333  [12832/60000]\n",
            "[Epoch: 55/100] Loss: 0.270901  [16032/60000]\n",
            "[Epoch: 55/100] Loss: 0.283661  [19232/60000]\n",
            "[Epoch: 55/100] Loss: 0.181450  [22432/60000]\n",
            "[Epoch: 55/100] Loss: 0.139188  [25632/60000]\n",
            "[Epoch: 55/100] Loss: 0.186466  [28832/60000]\n",
            "[Epoch: 55/100] Loss: 0.099365  [32032/60000]\n",
            "[Epoch: 55/100] Loss: 0.299783  [35232/60000]\n",
            "[Epoch: 55/100] Loss: 0.125731  [38432/60000]\n",
            "[Epoch: 55/100] Loss: 0.070686  [41632/60000]\n",
            "[Epoch: 55/100] Loss: 0.096601  [44832/60000]\n",
            "[Epoch: 55/100] Loss: 0.248652  [48032/60000]\n",
            "[Epoch: 55/100] Loss: 0.209039  [51232/60000]\n",
            "[Epoch: 55/100] Loss: 0.112497  [54432/60000]\n",
            "[Epoch: 55/100] Loss: 0.126894  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.192537 \n",
            "\n",
            "[Epoch: 56/100] Loss: 0.185687  [   32/60000]\n",
            "[Epoch: 56/100] Loss: 0.293159  [ 3232/60000]\n",
            "[Epoch: 56/100] Loss: 0.395890  [ 6432/60000]\n",
            "[Epoch: 56/100] Loss: 0.192112  [ 9632/60000]\n",
            "[Epoch: 56/100] Loss: 0.056110  [12832/60000]\n",
            "[Epoch: 56/100] Loss: 0.123783  [16032/60000]\n",
            "[Epoch: 56/100] Loss: 0.059606  [19232/60000]\n",
            "[Epoch: 56/100] Loss: 0.196801  [22432/60000]\n",
            "[Epoch: 56/100] Loss: 0.148097  [25632/60000]\n",
            "[Epoch: 56/100] Loss: 0.030234  [28832/60000]\n",
            "[Epoch: 56/100] Loss: 0.141635  [32032/60000]\n",
            "[Epoch: 56/100] Loss: 0.396430  [35232/60000]\n",
            "[Epoch: 56/100] Loss: 0.147943  [38432/60000]\n",
            "[Epoch: 56/100] Loss: 0.371458  [41632/60000]\n",
            "[Epoch: 56/100] Loss: 0.135221  [44832/60000]\n",
            "[Epoch: 56/100] Loss: 0.082244  [48032/60000]\n",
            "[Epoch: 56/100] Loss: 0.364846  [51232/60000]\n",
            "[Epoch: 56/100] Loss: 0.137385  [54432/60000]\n",
            "[Epoch: 56/100] Loss: 0.149624  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.190983 \n",
            "\n",
            "[Epoch: 57/100] Loss: 0.049818  [   32/60000]\n",
            "[Epoch: 57/100] Loss: 0.156161  [ 3232/60000]\n",
            "[Epoch: 57/100] Loss: 0.093140  [ 6432/60000]\n",
            "[Epoch: 57/100] Loss: 0.062690  [ 9632/60000]\n",
            "[Epoch: 57/100] Loss: 0.119972  [12832/60000]\n",
            "[Epoch: 57/100] Loss: 0.164072  [16032/60000]\n",
            "[Epoch: 57/100] Loss: 0.363299  [19232/60000]\n",
            "[Epoch: 57/100] Loss: 0.097019  [22432/60000]\n",
            "[Epoch: 57/100] Loss: 0.270122  [25632/60000]\n",
            "[Epoch: 57/100] Loss: 0.229056  [28832/60000]\n",
            "[Epoch: 57/100] Loss: 0.615670  [32032/60000]\n",
            "[Epoch: 57/100] Loss: 0.187276  [35232/60000]\n",
            "[Epoch: 57/100] Loss: 0.144576  [38432/60000]\n",
            "[Epoch: 57/100] Loss: 0.160407  [41632/60000]\n",
            "[Epoch: 57/100] Loss: 0.083837  [44832/60000]\n",
            "[Epoch: 57/100] Loss: 0.172035  [48032/60000]\n",
            "[Epoch: 57/100] Loss: 0.419515  [51232/60000]\n",
            "[Epoch: 57/100] Loss: 0.136081  [54432/60000]\n",
            "[Epoch: 57/100] Loss: 0.075281  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.188544 \n",
            "\n",
            "[Epoch: 58/100] Loss: 0.304592  [   32/60000]\n",
            "[Epoch: 58/100] Loss: 0.078238  [ 3232/60000]\n",
            "[Epoch: 58/100] Loss: 0.246269  [ 6432/60000]\n",
            "[Epoch: 58/100] Loss: 0.305448  [ 9632/60000]\n",
            "[Epoch: 58/100] Loss: 0.232718  [12832/60000]\n",
            "[Epoch: 58/100] Loss: 0.289707  [16032/60000]\n",
            "[Epoch: 58/100] Loss: 0.342119  [19232/60000]\n",
            "[Epoch: 58/100] Loss: 0.286079  [22432/60000]\n",
            "[Epoch: 58/100] Loss: 0.239164  [25632/60000]\n",
            "[Epoch: 58/100] Loss: 0.129461  [28832/60000]\n",
            "[Epoch: 58/100] Loss: 0.376292  [32032/60000]\n",
            "[Epoch: 58/100] Loss: 0.443723  [35232/60000]\n",
            "[Epoch: 58/100] Loss: 0.165326  [38432/60000]\n",
            "[Epoch: 58/100] Loss: 0.057355  [41632/60000]\n",
            "[Epoch: 58/100] Loss: 0.242646  [44832/60000]\n",
            "[Epoch: 58/100] Loss: 0.147304  [48032/60000]\n",
            "[Epoch: 58/100] Loss: 0.191637  [51232/60000]\n",
            "[Epoch: 58/100] Loss: 0.188235  [54432/60000]\n",
            "[Epoch: 58/100] Loss: 0.173791  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.186515 \n",
            "\n",
            "[Epoch: 59/100] Loss: 0.258210  [   32/60000]\n",
            "[Epoch: 59/100] Loss: 0.145269  [ 3232/60000]\n",
            "[Epoch: 59/100] Loss: 0.311140  [ 6432/60000]\n",
            "[Epoch: 59/100] Loss: 0.290837  [ 9632/60000]\n",
            "[Epoch: 59/100] Loss: 0.243532  [12832/60000]\n",
            "[Epoch: 59/100] Loss: 0.195296  [16032/60000]\n",
            "[Epoch: 59/100] Loss: 0.164315  [19232/60000]\n",
            "[Epoch: 59/100] Loss: 0.230622  [22432/60000]\n",
            "[Epoch: 59/100] Loss: 0.229042  [25632/60000]\n",
            "[Epoch: 59/100] Loss: 0.302458  [28832/60000]\n",
            "[Epoch: 59/100] Loss: 0.496300  [32032/60000]\n",
            "[Epoch: 59/100] Loss: 0.207266  [35232/60000]\n",
            "[Epoch: 59/100] Loss: 0.195426  [38432/60000]\n",
            "[Epoch: 59/100] Loss: 0.056716  [41632/60000]\n",
            "[Epoch: 59/100] Loss: 0.080761  [44832/60000]\n",
            "[Epoch: 59/100] Loss: 0.459847  [48032/60000]\n",
            "[Epoch: 59/100] Loss: 0.132613  [51232/60000]\n",
            "[Epoch: 59/100] Loss: 0.094818  [54432/60000]\n",
            "[Epoch: 59/100] Loss: 0.319454  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.183869 \n",
            "\n",
            "[Epoch: 60/100] Loss: 0.108470  [   32/60000]\n",
            "[Epoch: 60/100] Loss: 0.346378  [ 3232/60000]\n",
            "[Epoch: 60/100] Loss: 0.072850  [ 6432/60000]\n",
            "[Epoch: 60/100] Loss: 0.089088  [ 9632/60000]\n",
            "[Epoch: 60/100] Loss: 0.089019  [12832/60000]\n",
            "[Epoch: 60/100] Loss: 0.069623  [16032/60000]\n",
            "[Epoch: 60/100] Loss: 0.291657  [19232/60000]\n",
            "[Epoch: 60/100] Loss: 0.328559  [22432/60000]\n",
            "[Epoch: 60/100] Loss: 0.073597  [25632/60000]\n",
            "[Epoch: 60/100] Loss: 0.076919  [28832/60000]\n",
            "[Epoch: 60/100] Loss: 0.200645  [32032/60000]\n",
            "[Epoch: 60/100] Loss: 0.155333  [35232/60000]\n",
            "[Epoch: 60/100] Loss: 0.126686  [38432/60000]\n",
            "[Epoch: 60/100] Loss: 0.273418  [41632/60000]\n",
            "[Epoch: 60/100] Loss: 0.069433  [44832/60000]\n",
            "[Epoch: 60/100] Loss: 0.310698  [48032/60000]\n",
            "[Epoch: 60/100] Loss: 0.083678  [51232/60000]\n",
            "[Epoch: 60/100] Loss: 0.120976  [54432/60000]\n",
            "[Epoch: 60/100] Loss: 0.139640  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.182760 \n",
            "\n",
            "[Epoch: 61/100] Loss: 0.326177  [   32/60000]\n",
            "[Epoch: 61/100] Loss: 0.110413  [ 3232/60000]\n",
            "[Epoch: 61/100] Loss: 0.324789  [ 6432/60000]\n",
            "[Epoch: 61/100] Loss: 0.059764  [ 9632/60000]\n",
            "[Epoch: 61/100] Loss: 0.350360  [12832/60000]\n",
            "[Epoch: 61/100] Loss: 0.243749  [16032/60000]\n",
            "[Epoch: 61/100] Loss: 0.124033  [19232/60000]\n",
            "[Epoch: 61/100] Loss: 0.060304  [22432/60000]\n",
            "[Epoch: 61/100] Loss: 0.091561  [25632/60000]\n",
            "[Epoch: 61/100] Loss: 0.262606  [28832/60000]\n",
            "[Epoch: 61/100] Loss: 0.183623  [32032/60000]\n",
            "[Epoch: 61/100] Loss: 0.034985  [35232/60000]\n",
            "[Epoch: 61/100] Loss: 0.116753  [38432/60000]\n",
            "[Epoch: 61/100] Loss: 0.312688  [41632/60000]\n",
            "[Epoch: 61/100] Loss: 0.073425  [44832/60000]\n",
            "[Epoch: 61/100] Loss: 0.122362  [48032/60000]\n",
            "[Epoch: 61/100] Loss: 0.026735  [51232/60000]\n",
            "[Epoch: 61/100] Loss: 0.187118  [54432/60000]\n",
            "[Epoch: 61/100] Loss: 0.621932  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.180430 \n",
            "\n",
            "[Epoch: 62/100] Loss: 0.338369  [   32/60000]\n",
            "[Epoch: 62/100] Loss: 0.089924  [ 3232/60000]\n",
            "[Epoch: 62/100] Loss: 0.347852  [ 6432/60000]\n",
            "[Epoch: 62/100] Loss: 0.040828  [ 9632/60000]\n",
            "[Epoch: 62/100] Loss: 0.351646  [12832/60000]\n",
            "[Epoch: 62/100] Loss: 0.101591  [16032/60000]\n",
            "[Epoch: 62/100] Loss: 0.098954  [19232/60000]\n",
            "[Epoch: 62/100] Loss: 0.346337  [22432/60000]\n",
            "[Epoch: 62/100] Loss: 0.044130  [25632/60000]\n",
            "[Epoch: 62/100] Loss: 0.163057  [28832/60000]\n",
            "[Epoch: 62/100] Loss: 0.350256  [32032/60000]\n",
            "[Epoch: 62/100] Loss: 0.137767  [35232/60000]\n",
            "[Epoch: 62/100] Loss: 0.076913  [38432/60000]\n",
            "[Epoch: 62/100] Loss: 0.230115  [41632/60000]\n",
            "[Epoch: 62/100] Loss: 0.241796  [44832/60000]\n",
            "[Epoch: 62/100] Loss: 0.114322  [48032/60000]\n",
            "[Epoch: 62/100] Loss: 0.061170  [51232/60000]\n",
            "[Epoch: 62/100] Loss: 0.068928  [54432/60000]\n",
            "[Epoch: 62/100] Loss: 0.135094  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.178739 \n",
            "\n",
            "[Epoch: 63/100] Loss: 0.076484  [   32/60000]\n",
            "[Epoch: 63/100] Loss: 0.199221  [ 3232/60000]\n",
            "[Epoch: 63/100] Loss: 0.189891  [ 6432/60000]\n",
            "[Epoch: 63/100] Loss: 0.231514  [ 9632/60000]\n",
            "[Epoch: 63/100] Loss: 0.113168  [12832/60000]\n",
            "[Epoch: 63/100] Loss: 0.369815  [16032/60000]\n",
            "[Epoch: 63/100] Loss: 0.016694  [19232/60000]\n",
            "[Epoch: 63/100] Loss: 0.074896  [22432/60000]\n",
            "[Epoch: 63/100] Loss: 0.195360  [25632/60000]\n",
            "[Epoch: 63/100] Loss: 0.198568  [28832/60000]\n",
            "[Epoch: 63/100] Loss: 0.167007  [32032/60000]\n",
            "[Epoch: 63/100] Loss: 0.123902  [35232/60000]\n",
            "[Epoch: 63/100] Loss: 0.171214  [38432/60000]\n",
            "[Epoch: 63/100] Loss: 0.087461  [41632/60000]\n",
            "[Epoch: 63/100] Loss: 0.117808  [44832/60000]\n",
            "[Epoch: 63/100] Loss: 0.241477  [48032/60000]\n",
            "[Epoch: 63/100] Loss: 0.109005  [51232/60000]\n",
            "[Epoch: 63/100] Loss: 0.274625  [54432/60000]\n",
            "[Epoch: 63/100] Loss: 0.258771  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.177060 \n",
            "\n",
            "[Epoch: 64/100] Loss: 0.077083  [   32/60000]\n",
            "[Epoch: 64/100] Loss: 0.073842  [ 3232/60000]\n",
            "[Epoch: 64/100] Loss: 0.107169  [ 6432/60000]\n",
            "[Epoch: 64/100] Loss: 0.220645  [ 9632/60000]\n",
            "[Epoch: 64/100] Loss: 0.100973  [12832/60000]\n",
            "[Epoch: 64/100] Loss: 0.185676  [16032/60000]\n",
            "[Epoch: 64/100] Loss: 0.486284  [19232/60000]\n",
            "[Epoch: 64/100] Loss: 0.135362  [22432/60000]\n",
            "[Epoch: 64/100] Loss: 0.065572  [25632/60000]\n",
            "[Epoch: 64/100] Loss: 0.066862  [28832/60000]\n",
            "[Epoch: 64/100] Loss: 0.198455  [32032/60000]\n",
            "[Epoch: 64/100] Loss: 0.130899  [35232/60000]\n",
            "[Epoch: 64/100] Loss: 0.075862  [38432/60000]\n",
            "[Epoch: 64/100] Loss: 0.114622  [41632/60000]\n",
            "[Epoch: 64/100] Loss: 0.255003  [44832/60000]\n",
            "[Epoch: 64/100] Loss: 0.393440  [48032/60000]\n",
            "[Epoch: 64/100] Loss: 0.211682  [51232/60000]\n",
            "[Epoch: 64/100] Loss: 0.091717  [54432/60000]\n",
            "[Epoch: 64/100] Loss: 0.212678  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.175296 \n",
            "\n",
            "[Epoch: 65/100] Loss: 0.495366  [   32/60000]\n",
            "[Epoch: 65/100] Loss: 0.228675  [ 3232/60000]\n",
            "[Epoch: 65/100] Loss: 0.062014  [ 6432/60000]\n",
            "[Epoch: 65/100] Loss: 0.061806  [ 9632/60000]\n",
            "[Epoch: 65/100] Loss: 0.128924  [12832/60000]\n",
            "[Epoch: 65/100] Loss: 0.301942  [16032/60000]\n",
            "[Epoch: 65/100] Loss: 0.210962  [19232/60000]\n",
            "[Epoch: 65/100] Loss: 0.230664  [22432/60000]\n",
            "[Epoch: 65/100] Loss: 0.185901  [25632/60000]\n",
            "[Epoch: 65/100] Loss: 0.216586  [28832/60000]\n",
            "[Epoch: 65/100] Loss: 0.077503  [32032/60000]\n",
            "[Epoch: 65/100] Loss: 0.170500  [35232/60000]\n",
            "[Epoch: 65/100] Loss: 0.165804  [38432/60000]\n",
            "[Epoch: 65/100] Loss: 0.152981  [41632/60000]\n",
            "[Epoch: 65/100] Loss: 0.273457  [44832/60000]\n",
            "[Epoch: 65/100] Loss: 0.138486  [48032/60000]\n",
            "[Epoch: 65/100] Loss: 0.208477  [51232/60000]\n",
            "[Epoch: 65/100] Loss: 0.074921  [54432/60000]\n",
            "[Epoch: 65/100] Loss: 0.271395  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.173417 \n",
            "\n",
            "[Epoch: 66/100] Loss: 0.083987  [   32/60000]\n",
            "[Epoch: 66/100] Loss: 0.244004  [ 3232/60000]\n",
            "[Epoch: 66/100] Loss: 0.116870  [ 6432/60000]\n",
            "[Epoch: 66/100] Loss: 0.026191  [ 9632/60000]\n",
            "[Epoch: 66/100] Loss: 0.197053  [12832/60000]\n",
            "[Epoch: 66/100] Loss: 0.128026  [16032/60000]\n",
            "[Epoch: 66/100] Loss: 0.045563  [19232/60000]\n",
            "[Epoch: 66/100] Loss: 0.063856  [22432/60000]\n",
            "[Epoch: 66/100] Loss: 0.112699  [25632/60000]\n",
            "[Epoch: 66/100] Loss: 0.153494  [28832/60000]\n",
            "[Epoch: 66/100] Loss: 0.260567  [32032/60000]\n",
            "[Epoch: 66/100] Loss: 0.113272  [35232/60000]\n",
            "[Epoch: 66/100] Loss: 0.154498  [38432/60000]\n",
            "[Epoch: 66/100] Loss: 0.185479  [41632/60000]\n",
            "[Epoch: 66/100] Loss: 0.300031  [44832/60000]\n",
            "[Epoch: 66/100] Loss: 0.232712  [48032/60000]\n",
            "[Epoch: 66/100] Loss: 0.119413  [51232/60000]\n",
            "[Epoch: 66/100] Loss: 0.161381  [54432/60000]\n",
            "[Epoch: 66/100] Loss: 0.252919  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.172423 \n",
            "\n",
            "[Epoch: 67/100] Loss: 0.194670  [   32/60000]\n",
            "[Epoch: 67/100] Loss: 0.058654  [ 3232/60000]\n",
            "[Epoch: 67/100] Loss: 0.032416  [ 6432/60000]\n",
            "[Epoch: 67/100] Loss: 0.060071  [ 9632/60000]\n",
            "[Epoch: 67/100] Loss: 0.049647  [12832/60000]\n",
            "[Epoch: 67/100] Loss: 0.120614  [16032/60000]\n",
            "[Epoch: 67/100] Loss: 0.144884  [19232/60000]\n",
            "[Epoch: 67/100] Loss: 0.333257  [22432/60000]\n",
            "[Epoch: 67/100] Loss: 0.307220  [25632/60000]\n",
            "[Epoch: 67/100] Loss: 0.314213  [28832/60000]\n",
            "[Epoch: 67/100] Loss: 0.105620  [32032/60000]\n",
            "[Epoch: 67/100] Loss: 0.096021  [35232/60000]\n",
            "[Epoch: 67/100] Loss: 0.049499  [38432/60000]\n",
            "[Epoch: 67/100] Loss: 0.222977  [41632/60000]\n",
            "[Epoch: 67/100] Loss: 0.104526  [44832/60000]\n",
            "[Epoch: 67/100] Loss: 0.054698  [48032/60000]\n",
            "[Epoch: 67/100] Loss: 0.094303  [51232/60000]\n",
            "[Epoch: 67/100] Loss: 0.100908  [54432/60000]\n",
            "[Epoch: 67/100] Loss: 0.027136  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170796 \n",
            "\n",
            "[Epoch: 68/100] Loss: 0.054046  [   32/60000]\n",
            "[Epoch: 68/100] Loss: 0.481056  [ 3232/60000]\n",
            "[Epoch: 68/100] Loss: 0.128529  [ 6432/60000]\n",
            "[Epoch: 68/100] Loss: 0.285823  [ 9632/60000]\n",
            "[Epoch: 68/100] Loss: 0.203720  [12832/60000]\n",
            "[Epoch: 68/100] Loss: 0.110555  [16032/60000]\n",
            "[Epoch: 68/100] Loss: 0.134500  [19232/60000]\n",
            "[Epoch: 68/100] Loss: 0.285476  [22432/60000]\n",
            "[Epoch: 68/100] Loss: 0.193971  [25632/60000]\n",
            "[Epoch: 68/100] Loss: 0.200297  [28832/60000]\n",
            "[Epoch: 68/100] Loss: 0.150232  [32032/60000]\n",
            "[Epoch: 68/100] Loss: 0.131966  [35232/60000]\n",
            "[Epoch: 68/100] Loss: 0.036251  [38432/60000]\n",
            "[Epoch: 68/100] Loss: 0.179803  [41632/60000]\n",
            "[Epoch: 68/100] Loss: 0.085888  [44832/60000]\n",
            "[Epoch: 68/100] Loss: 0.358234  [48032/60000]\n",
            "[Epoch: 68/100] Loss: 0.190627  [51232/60000]\n",
            "[Epoch: 68/100] Loss: 0.357550  [54432/60000]\n",
            "[Epoch: 68/100] Loss: 0.593595  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.168624 \n",
            "\n",
            "[Epoch: 69/100] Loss: 0.120657  [   32/60000]\n",
            "[Epoch: 69/100] Loss: 0.072200  [ 3232/60000]\n",
            "[Epoch: 69/100] Loss: 0.138761  [ 6432/60000]\n",
            "[Epoch: 69/100] Loss: 0.398466  [ 9632/60000]\n",
            "[Epoch: 69/100] Loss: 0.391298  [12832/60000]\n",
            "[Epoch: 69/100] Loss: 0.063606  [16032/60000]\n",
            "[Epoch: 69/100] Loss: 0.037333  [19232/60000]\n",
            "[Epoch: 69/100] Loss: 0.175314  [22432/60000]\n",
            "[Epoch: 69/100] Loss: 0.031076  [25632/60000]\n",
            "[Epoch: 69/100] Loss: 0.240444  [28832/60000]\n",
            "[Epoch: 69/100] Loss: 0.220964  [32032/60000]\n",
            "[Epoch: 69/100] Loss: 0.258863  [35232/60000]\n",
            "[Epoch: 69/100] Loss: 0.274433  [38432/60000]\n",
            "[Epoch: 69/100] Loss: 0.268102  [41632/60000]\n",
            "[Epoch: 69/100] Loss: 0.252533  [44832/60000]\n",
            "[Epoch: 69/100] Loss: 0.186948  [48032/60000]\n",
            "[Epoch: 69/100] Loss: 0.094002  [51232/60000]\n",
            "[Epoch: 69/100] Loss: 0.422385  [54432/60000]\n",
            "[Epoch: 69/100] Loss: 0.062916  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.166942 \n",
            "\n",
            "[Epoch: 70/100] Loss: 0.074067  [   32/60000]\n",
            "[Epoch: 70/100] Loss: 0.243927  [ 3232/60000]\n",
            "[Epoch: 70/100] Loss: 0.199679  [ 6432/60000]\n",
            "[Epoch: 70/100] Loss: 0.053824  [ 9632/60000]\n",
            "[Epoch: 70/100] Loss: 0.074628  [12832/60000]\n",
            "[Epoch: 70/100] Loss: 0.046355  [16032/60000]\n",
            "[Epoch: 70/100] Loss: 0.053830  [19232/60000]\n",
            "[Epoch: 70/100] Loss: 0.130595  [22432/60000]\n",
            "[Epoch: 70/100] Loss: 0.119063  [25632/60000]\n",
            "[Epoch: 70/100] Loss: 0.262180  [28832/60000]\n",
            "[Epoch: 70/100] Loss: 0.427209  [32032/60000]\n",
            "[Epoch: 70/100] Loss: 0.325554  [35232/60000]\n",
            "[Epoch: 70/100] Loss: 0.145165  [38432/60000]\n",
            "[Epoch: 70/100] Loss: 0.116003  [41632/60000]\n",
            "[Epoch: 70/100] Loss: 0.123793  [44832/60000]\n",
            "[Epoch: 70/100] Loss: 0.131198  [48032/60000]\n",
            "[Epoch: 70/100] Loss: 0.156083  [51232/60000]\n",
            "[Epoch: 70/100] Loss: 0.244310  [54432/60000]\n",
            "[Epoch: 70/100] Loss: 0.041582  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.165463 \n",
            "\n",
            "[Epoch: 71/100] Loss: 0.055873  [   32/60000]\n",
            "[Epoch: 71/100] Loss: 0.094027  [ 3232/60000]\n",
            "[Epoch: 71/100] Loss: 0.110170  [ 6432/60000]\n",
            "[Epoch: 71/100] Loss: 0.516307  [ 9632/60000]\n",
            "[Epoch: 71/100] Loss: 0.133783  [12832/60000]\n",
            "[Epoch: 71/100] Loss: 0.071594  [16032/60000]\n",
            "[Epoch: 71/100] Loss: 0.048863  [19232/60000]\n",
            "[Epoch: 71/100] Loss: 0.151573  [22432/60000]\n",
            "[Epoch: 71/100] Loss: 0.363032  [25632/60000]\n",
            "[Epoch: 71/100] Loss: 0.196419  [28832/60000]\n",
            "[Epoch: 71/100] Loss: 0.181009  [32032/60000]\n",
            "[Epoch: 71/100] Loss: 0.091837  [35232/60000]\n",
            "[Epoch: 71/100] Loss: 0.090739  [38432/60000]\n",
            "[Epoch: 71/100] Loss: 0.233053  [41632/60000]\n",
            "[Epoch: 71/100] Loss: 0.194090  [44832/60000]\n",
            "[Epoch: 71/100] Loss: 0.081457  [48032/60000]\n",
            "[Epoch: 71/100] Loss: 0.284684  [51232/60000]\n",
            "[Epoch: 71/100] Loss: 0.081290  [54432/60000]\n",
            "[Epoch: 71/100] Loss: 0.246999  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.164048 \n",
            "\n",
            "[Epoch: 72/100] Loss: 0.197036  [   32/60000]\n",
            "[Epoch: 72/100] Loss: 0.168490  [ 3232/60000]\n",
            "[Epoch: 72/100] Loss: 0.054986  [ 6432/60000]\n",
            "[Epoch: 72/100] Loss: 0.148703  [ 9632/60000]\n",
            "[Epoch: 72/100] Loss: 0.184060  [12832/60000]\n",
            "[Epoch: 72/100] Loss: 0.132811  [16032/60000]\n",
            "[Epoch: 72/100] Loss: 0.289171  [19232/60000]\n",
            "[Epoch: 72/100] Loss: 0.254219  [22432/60000]\n",
            "[Epoch: 72/100] Loss: 0.098307  [25632/60000]\n",
            "[Epoch: 72/100] Loss: 0.293321  [28832/60000]\n",
            "[Epoch: 72/100] Loss: 0.064523  [32032/60000]\n",
            "[Epoch: 72/100] Loss: 0.190506  [35232/60000]\n",
            "[Epoch: 72/100] Loss: 0.158156  [38432/60000]\n",
            "[Epoch: 72/100] Loss: 0.188584  [41632/60000]\n",
            "[Epoch: 72/100] Loss: 0.185693  [44832/60000]\n",
            "[Epoch: 72/100] Loss: 0.203865  [48032/60000]\n",
            "[Epoch: 72/100] Loss: 0.135143  [51232/60000]\n",
            "[Epoch: 72/100] Loss: 0.081490  [54432/60000]\n",
            "[Epoch: 72/100] Loss: 0.060964  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.162471 \n",
            "\n",
            "[Epoch: 73/100] Loss: 0.241159  [   32/60000]\n",
            "[Epoch: 73/100] Loss: 0.112790  [ 3232/60000]\n",
            "[Epoch: 73/100] Loss: 0.092683  [ 6432/60000]\n",
            "[Epoch: 73/100] Loss: 0.145218  [ 9632/60000]\n",
            "[Epoch: 73/100] Loss: 0.221598  [12832/60000]\n",
            "[Epoch: 73/100] Loss: 0.163292  [16032/60000]\n",
            "[Epoch: 73/100] Loss: 0.362575  [19232/60000]\n",
            "[Epoch: 73/100] Loss: 0.179870  [22432/60000]\n",
            "[Epoch: 73/100] Loss: 0.199825  [25632/60000]\n",
            "[Epoch: 73/100] Loss: 0.245832  [28832/60000]\n",
            "[Epoch: 73/100] Loss: 0.092372  [32032/60000]\n",
            "[Epoch: 73/100] Loss: 0.172836  [35232/60000]\n",
            "[Epoch: 73/100] Loss: 0.061297  [38432/60000]\n",
            "[Epoch: 73/100] Loss: 0.172632  [41632/60000]\n",
            "[Epoch: 73/100] Loss: 0.351156  [44832/60000]\n",
            "[Epoch: 73/100] Loss: 0.048861  [48032/60000]\n",
            "[Epoch: 73/100] Loss: 0.381029  [51232/60000]\n",
            "[Epoch: 73/100] Loss: 0.143244  [54432/60000]\n",
            "[Epoch: 73/100] Loss: 0.183983  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.161294 \n",
            "\n",
            "[Epoch: 74/100] Loss: 0.017872  [   32/60000]\n",
            "[Epoch: 74/100] Loss: 0.056107  [ 3232/60000]\n",
            "[Epoch: 74/100] Loss: 0.212620  [ 6432/60000]\n",
            "[Epoch: 74/100] Loss: 0.082224  [ 9632/60000]\n",
            "[Epoch: 74/100] Loss: 0.094621  [12832/60000]\n",
            "[Epoch: 74/100] Loss: 0.075060  [16032/60000]\n",
            "[Epoch: 74/100] Loss: 0.052317  [19232/60000]\n",
            "[Epoch: 74/100] Loss: 0.087684  [22432/60000]\n",
            "[Epoch: 74/100] Loss: 0.102770  [25632/60000]\n",
            "[Epoch: 74/100] Loss: 0.115630  [28832/60000]\n",
            "[Epoch: 74/100] Loss: 0.113214  [32032/60000]\n",
            "[Epoch: 74/100] Loss: 0.139628  [35232/60000]\n",
            "[Epoch: 74/100] Loss: 0.065938  [38432/60000]\n",
            "[Epoch: 74/100] Loss: 0.222696  [41632/60000]\n",
            "[Epoch: 74/100] Loss: 0.137338  [44832/60000]\n",
            "[Epoch: 74/100] Loss: 0.179416  [48032/60000]\n",
            "[Epoch: 74/100] Loss: 0.109759  [51232/60000]\n",
            "[Epoch: 74/100] Loss: 0.084540  [54432/60000]\n",
            "[Epoch: 74/100] Loss: 0.130511  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.160373 \n",
            "\n",
            "[Epoch: 75/100] Loss: 0.074691  [   32/60000]\n",
            "[Epoch: 75/100] Loss: 0.320719  [ 3232/60000]\n",
            "[Epoch: 75/100] Loss: 0.288680  [ 6432/60000]\n",
            "[Epoch: 75/100] Loss: 0.033963  [ 9632/60000]\n",
            "[Epoch: 75/100] Loss: 0.032570  [12832/60000]\n",
            "[Epoch: 75/100] Loss: 0.068064  [16032/60000]\n",
            "[Epoch: 75/100] Loss: 0.469476  [19232/60000]\n",
            "[Epoch: 75/100] Loss: 0.335008  [22432/60000]\n",
            "[Epoch: 75/100] Loss: 0.030048  [25632/60000]\n",
            "[Epoch: 75/100] Loss: 0.068968  [28832/60000]\n",
            "[Epoch: 75/100] Loss: 0.205458  [32032/60000]\n",
            "[Epoch: 75/100] Loss: 0.059295  [35232/60000]\n",
            "[Epoch: 75/100] Loss: 0.056677  [38432/60000]\n",
            "[Epoch: 75/100] Loss: 0.302006  [41632/60000]\n",
            "[Epoch: 75/100] Loss: 0.112506  [44832/60000]\n",
            "[Epoch: 75/100] Loss: 0.200982  [48032/60000]\n",
            "[Epoch: 75/100] Loss: 0.063026  [51232/60000]\n",
            "[Epoch: 75/100] Loss: 0.408841  [54432/60000]\n",
            "[Epoch: 75/100] Loss: 0.192536  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.158523 \n",
            "\n",
            "[Epoch: 76/100] Loss: 0.339664  [   32/60000]\n",
            "[Epoch: 76/100] Loss: 0.098877  [ 3232/60000]\n",
            "[Epoch: 76/100] Loss: 0.187106  [ 6432/60000]\n",
            "[Epoch: 76/100] Loss: 0.095378  [ 9632/60000]\n",
            "[Epoch: 76/100] Loss: 0.196602  [12832/60000]\n",
            "[Epoch: 76/100] Loss: 0.261239  [16032/60000]\n",
            "[Epoch: 76/100] Loss: 0.373729  [19232/60000]\n",
            "[Epoch: 76/100] Loss: 0.302803  [22432/60000]\n",
            "[Epoch: 76/100] Loss: 0.093294  [25632/60000]\n",
            "[Epoch: 76/100] Loss: 0.220302  [28832/60000]\n",
            "[Epoch: 76/100] Loss: 0.222200  [32032/60000]\n",
            "[Epoch: 76/100] Loss: 0.214673  [35232/60000]\n",
            "[Epoch: 76/100] Loss: 0.187333  [38432/60000]\n",
            "[Epoch: 76/100] Loss: 0.223829  [41632/60000]\n",
            "[Epoch: 76/100] Loss: 0.150799  [44832/60000]\n",
            "[Epoch: 76/100] Loss: 0.110532  [48032/60000]\n",
            "[Epoch: 76/100] Loss: 0.179631  [51232/60000]\n",
            "[Epoch: 76/100] Loss: 0.161366  [54432/60000]\n",
            "[Epoch: 76/100] Loss: 0.100253  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.3%, Avg loss: 0.156687 \n",
            "\n",
            "[Epoch: 77/100] Loss: 0.249631  [   32/60000]\n",
            "[Epoch: 77/100] Loss: 0.202445  [ 3232/60000]\n",
            "[Epoch: 77/100] Loss: 0.206023  [ 6432/60000]\n",
            "[Epoch: 77/100] Loss: 0.111956  [ 9632/60000]\n",
            "[Epoch: 77/100] Loss: 0.419901  [12832/60000]\n",
            "[Epoch: 77/100] Loss: 0.094586  [16032/60000]\n",
            "[Epoch: 77/100] Loss: 0.148079  [19232/60000]\n",
            "[Epoch: 77/100] Loss: 0.081179  [22432/60000]\n",
            "[Epoch: 77/100] Loss: 0.350496  [25632/60000]\n",
            "[Epoch: 77/100] Loss: 0.124927  [28832/60000]\n",
            "[Epoch: 77/100] Loss: 0.392255  [32032/60000]\n",
            "[Epoch: 77/100] Loss: 0.216230  [35232/60000]\n",
            "[Epoch: 77/100] Loss: 0.264380  [38432/60000]\n",
            "[Epoch: 77/100] Loss: 0.063982  [41632/60000]\n",
            "[Epoch: 77/100] Loss: 0.050301  [44832/60000]\n",
            "[Epoch: 77/100] Loss: 0.049794  [48032/60000]\n",
            "[Epoch: 77/100] Loss: 0.219912  [51232/60000]\n",
            "[Epoch: 77/100] Loss: 0.080493  [54432/60000]\n",
            "[Epoch: 77/100] Loss: 0.047052  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.155206 \n",
            "\n",
            "[Epoch: 78/100] Loss: 0.070199  [   32/60000]\n",
            "[Epoch: 78/100] Loss: 0.217036  [ 3232/60000]\n",
            "[Epoch: 78/100] Loss: 0.057510  [ 6432/60000]\n",
            "[Epoch: 78/100] Loss: 0.057514  [ 9632/60000]\n",
            "[Epoch: 78/100] Loss: 0.154031  [12832/60000]\n",
            "[Epoch: 78/100] Loss: 0.090376  [16032/60000]\n",
            "[Epoch: 78/100] Loss: 0.092651  [19232/60000]\n",
            "[Epoch: 78/100] Loss: 0.298879  [22432/60000]\n",
            "[Epoch: 78/100] Loss: 0.127247  [25632/60000]\n",
            "[Epoch: 78/100] Loss: 0.069083  [28832/60000]\n",
            "[Epoch: 78/100] Loss: 0.248874  [32032/60000]\n",
            "[Epoch: 78/100] Loss: 0.150890  [35232/60000]\n",
            "[Epoch: 78/100] Loss: 0.175302  [38432/60000]\n",
            "[Epoch: 78/100] Loss: 0.556361  [41632/60000]\n",
            "[Epoch: 78/100] Loss: 0.139820  [44832/60000]\n",
            "[Epoch: 78/100] Loss: 0.054966  [48032/60000]\n",
            "[Epoch: 78/100] Loss: 0.253797  [51232/60000]\n",
            "[Epoch: 78/100] Loss: 0.161441  [54432/60000]\n",
            "[Epoch: 78/100] Loss: 0.209630  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.154689 \n",
            "\n",
            "[Epoch: 79/100] Loss: 0.160007  [   32/60000]\n",
            "[Epoch: 79/100] Loss: 0.087017  [ 3232/60000]\n",
            "[Epoch: 79/100] Loss: 0.127702  [ 6432/60000]\n",
            "[Epoch: 79/100] Loss: 0.217084  [ 9632/60000]\n",
            "[Epoch: 79/100] Loss: 0.025760  [12832/60000]\n",
            "[Epoch: 79/100] Loss: 0.041584  [16032/60000]\n",
            "[Epoch: 79/100] Loss: 0.023847  [19232/60000]\n",
            "[Epoch: 79/100] Loss: 0.067311  [22432/60000]\n",
            "[Epoch: 79/100] Loss: 0.145388  [25632/60000]\n",
            "[Epoch: 79/100] Loss: 0.080140  [28832/60000]\n",
            "[Epoch: 79/100] Loss: 0.216582  [32032/60000]\n",
            "[Epoch: 79/100] Loss: 0.081136  [35232/60000]\n",
            "[Epoch: 79/100] Loss: 0.121531  [38432/60000]\n",
            "[Epoch: 79/100] Loss: 0.176243  [41632/60000]\n",
            "[Epoch: 79/100] Loss: 0.083090  [44832/60000]\n",
            "[Epoch: 79/100] Loss: 0.202719  [48032/60000]\n",
            "[Epoch: 79/100] Loss: 0.131986  [51232/60000]\n",
            "[Epoch: 79/100] Loss: 0.067709  [54432/60000]\n",
            "[Epoch: 79/100] Loss: 0.067257  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.153015 \n",
            "\n",
            "[Epoch: 80/100] Loss: 0.097325  [   32/60000]\n",
            "[Epoch: 80/100] Loss: 0.211174  [ 3232/60000]\n",
            "[Epoch: 80/100] Loss: 0.050879  [ 6432/60000]\n",
            "[Epoch: 80/100] Loss: 0.098102  [ 9632/60000]\n",
            "[Epoch: 80/100] Loss: 0.179594  [12832/60000]\n",
            "[Epoch: 80/100] Loss: 0.175451  [16032/60000]\n",
            "[Epoch: 80/100] Loss: 0.043633  [19232/60000]\n",
            "[Epoch: 80/100] Loss: 0.265797  [22432/60000]\n",
            "[Epoch: 80/100] Loss: 0.177804  [25632/60000]\n",
            "[Epoch: 80/100] Loss: 0.175427  [28832/60000]\n",
            "[Epoch: 80/100] Loss: 0.027553  [32032/60000]\n",
            "[Epoch: 80/100] Loss: 0.132521  [35232/60000]\n",
            "[Epoch: 80/100] Loss: 0.133410  [38432/60000]\n",
            "[Epoch: 80/100] Loss: 0.225103  [41632/60000]\n",
            "[Epoch: 80/100] Loss: 0.246242  [44832/60000]\n",
            "[Epoch: 80/100] Loss: 0.075368  [48032/60000]\n",
            "[Epoch: 80/100] Loss: 0.151082  [51232/60000]\n",
            "[Epoch: 80/100] Loss: 0.120965  [54432/60000]\n",
            "[Epoch: 80/100] Loss: 0.107591  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.151828 \n",
            "\n",
            "[Epoch: 81/100] Loss: 0.146787  [   32/60000]\n",
            "[Epoch: 81/100] Loss: 0.052303  [ 3232/60000]\n",
            "[Epoch: 81/100] Loss: 0.090386  [ 6432/60000]\n",
            "[Epoch: 81/100] Loss: 0.251968  [ 9632/60000]\n",
            "[Epoch: 81/100] Loss: 0.353954  [12832/60000]\n",
            "[Epoch: 81/100] Loss: 0.182398  [16032/60000]\n",
            "[Epoch: 81/100] Loss: 0.104138  [19232/60000]\n",
            "[Epoch: 81/100] Loss: 0.101060  [22432/60000]\n",
            "[Epoch: 81/100] Loss: 0.205031  [25632/60000]\n",
            "[Epoch: 81/100] Loss: 0.202347  [28832/60000]\n",
            "[Epoch: 81/100] Loss: 0.028454  [32032/60000]\n",
            "[Epoch: 81/100] Loss: 0.203245  [35232/60000]\n",
            "[Epoch: 81/100] Loss: 0.277097  [38432/60000]\n",
            "[Epoch: 81/100] Loss: 0.200100  [41632/60000]\n",
            "[Epoch: 81/100] Loss: 0.163655  [44832/60000]\n",
            "[Epoch: 81/100] Loss: 0.064587  [48032/60000]\n",
            "[Epoch: 81/100] Loss: 0.073022  [51232/60000]\n",
            "[Epoch: 81/100] Loss: 0.090567  [54432/60000]\n",
            "[Epoch: 81/100] Loss: 0.242253  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.150668 \n",
            "\n",
            "[Epoch: 82/100] Loss: 0.085598  [   32/60000]\n",
            "[Epoch: 82/100] Loss: 0.377206  [ 3232/60000]\n",
            "[Epoch: 82/100] Loss: 0.164063  [ 6432/60000]\n",
            "[Epoch: 82/100] Loss: 0.058660  [ 9632/60000]\n",
            "[Epoch: 82/100] Loss: 0.173454  [12832/60000]\n",
            "[Epoch: 82/100] Loss: 0.188479  [16032/60000]\n",
            "[Epoch: 82/100] Loss: 0.064043  [19232/60000]\n",
            "[Epoch: 82/100] Loss: 0.086881  [22432/60000]\n",
            "[Epoch: 82/100] Loss: 0.054785  [25632/60000]\n",
            "[Epoch: 82/100] Loss: 0.198602  [28832/60000]\n",
            "[Epoch: 82/100] Loss: 0.175425  [32032/60000]\n",
            "[Epoch: 82/100] Loss: 0.111793  [35232/60000]\n",
            "[Epoch: 82/100] Loss: 0.068204  [38432/60000]\n",
            "[Epoch: 82/100] Loss: 0.117107  [41632/60000]\n",
            "[Epoch: 82/100] Loss: 0.102836  [44832/60000]\n",
            "[Epoch: 82/100] Loss: 0.092328  [48032/60000]\n",
            "[Epoch: 82/100] Loss: 0.178435  [51232/60000]\n",
            "[Epoch: 82/100] Loss: 0.178215  [54432/60000]\n",
            "[Epoch: 82/100] Loss: 0.362008  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.148647 \n",
            "\n",
            "[Epoch: 83/100] Loss: 0.177453  [   32/60000]\n",
            "[Epoch: 83/100] Loss: 0.274025  [ 3232/60000]\n",
            "[Epoch: 83/100] Loss: 0.133027  [ 6432/60000]\n",
            "[Epoch: 83/100] Loss: 0.195859  [ 9632/60000]\n",
            "[Epoch: 83/100] Loss: 0.271385  [12832/60000]\n",
            "[Epoch: 83/100] Loss: 0.207762  [16032/60000]\n",
            "[Epoch: 83/100] Loss: 0.083881  [19232/60000]\n",
            "[Epoch: 83/100] Loss: 0.033970  [22432/60000]\n",
            "[Epoch: 83/100] Loss: 0.189840  [25632/60000]\n",
            "[Epoch: 83/100] Loss: 0.064176  [28832/60000]\n",
            "[Epoch: 83/100] Loss: 0.066419  [32032/60000]\n",
            "[Epoch: 83/100] Loss: 0.187469  [35232/60000]\n",
            "[Epoch: 83/100] Loss: 0.039324  [38432/60000]\n",
            "[Epoch: 83/100] Loss: 0.171379  [41632/60000]\n",
            "[Epoch: 83/100] Loss: 0.231383  [44832/60000]\n",
            "[Epoch: 83/100] Loss: 0.112023  [48032/60000]\n",
            "[Epoch: 83/100] Loss: 0.221076  [51232/60000]\n",
            "[Epoch: 83/100] Loss: 0.040213  [54432/60000]\n",
            "[Epoch: 83/100] Loss: 0.130733  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.147810 \n",
            "\n",
            "[Epoch: 84/100] Loss: 0.041388  [   32/60000]\n",
            "[Epoch: 84/100] Loss: 0.039985  [ 3232/60000]\n",
            "[Epoch: 84/100] Loss: 0.165719  [ 6432/60000]\n",
            "[Epoch: 84/100] Loss: 0.181635  [ 9632/60000]\n",
            "[Epoch: 84/100] Loss: 0.036624  [12832/60000]\n",
            "[Epoch: 84/100] Loss: 0.235059  [16032/60000]\n",
            "[Epoch: 84/100] Loss: 0.052715  [19232/60000]\n",
            "[Epoch: 84/100] Loss: 0.256811  [22432/60000]\n",
            "[Epoch: 84/100] Loss: 0.055707  [25632/60000]\n",
            "[Epoch: 84/100] Loss: 0.027258  [28832/60000]\n",
            "[Epoch: 84/100] Loss: 0.231163  [32032/60000]\n",
            "[Epoch: 84/100] Loss: 0.184852  [35232/60000]\n",
            "[Epoch: 84/100] Loss: 0.132559  [38432/60000]\n",
            "[Epoch: 84/100] Loss: 0.063160  [41632/60000]\n",
            "[Epoch: 84/100] Loss: 0.151168  [44832/60000]\n",
            "[Epoch: 84/100] Loss: 0.089950  [48032/60000]\n",
            "[Epoch: 84/100] Loss: 0.070468  [51232/60000]\n",
            "[Epoch: 84/100] Loss: 0.179129  [54432/60000]\n",
            "[Epoch: 84/100] Loss: 0.213227  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.147491 \n",
            "\n",
            "[Epoch: 85/100] Loss: 0.142439  [   32/60000]\n",
            "[Epoch: 85/100] Loss: 0.116070  [ 3232/60000]\n",
            "[Epoch: 85/100] Loss: 0.262319  [ 6432/60000]\n",
            "[Epoch: 85/100] Loss: 0.052492  [ 9632/60000]\n",
            "[Epoch: 85/100] Loss: 0.196109  [12832/60000]\n",
            "[Epoch: 85/100] Loss: 0.040513  [16032/60000]\n",
            "[Epoch: 85/100] Loss: 0.270166  [19232/60000]\n",
            "[Epoch: 85/100] Loss: 0.086010  [22432/60000]\n",
            "[Epoch: 85/100] Loss: 0.235892  [25632/60000]\n",
            "[Epoch: 85/100] Loss: 0.354689  [28832/60000]\n",
            "[Epoch: 85/100] Loss: 0.035755  [32032/60000]\n",
            "[Epoch: 85/100] Loss: 0.217750  [35232/60000]\n",
            "[Epoch: 85/100] Loss: 0.160632  [38432/60000]\n",
            "[Epoch: 85/100] Loss: 0.214173  [41632/60000]\n",
            "[Epoch: 85/100] Loss: 0.149987  [44832/60000]\n",
            "[Epoch: 85/100] Loss: 0.077223  [48032/60000]\n",
            "[Epoch: 85/100] Loss: 0.179900  [51232/60000]\n",
            "[Epoch: 85/100] Loss: 0.286241  [54432/60000]\n",
            "[Epoch: 85/100] Loss: 0.329001  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.145316 \n",
            "\n",
            "[Epoch: 86/100] Loss: 0.157634  [   32/60000]\n",
            "[Epoch: 86/100] Loss: 0.156042  [ 3232/60000]\n",
            "[Epoch: 86/100] Loss: 0.268193  [ 6432/60000]\n",
            "[Epoch: 86/100] Loss: 0.134195  [ 9632/60000]\n",
            "[Epoch: 86/100] Loss: 0.093678  [12832/60000]\n",
            "[Epoch: 86/100] Loss: 0.189525  [16032/60000]\n",
            "[Epoch: 86/100] Loss: 0.025398  [19232/60000]\n",
            "[Epoch: 86/100] Loss: 0.113935  [22432/60000]\n",
            "[Epoch: 86/100] Loss: 0.250066  [25632/60000]\n",
            "[Epoch: 86/100] Loss: 0.113034  [28832/60000]\n",
            "[Epoch: 86/100] Loss: 0.110852  [32032/60000]\n",
            "[Epoch: 86/100] Loss: 0.153641  [35232/60000]\n",
            "[Epoch: 86/100] Loss: 0.086198  [38432/60000]\n",
            "[Epoch: 86/100] Loss: 0.020613  [41632/60000]\n",
            "[Epoch: 86/100] Loss: 0.086458  [44832/60000]\n",
            "[Epoch: 86/100] Loss: 0.068887  [48032/60000]\n",
            "[Epoch: 86/100] Loss: 0.031657  [51232/60000]\n",
            "[Epoch: 86/100] Loss: 0.210845  [54432/60000]\n",
            "[Epoch: 86/100] Loss: 0.147823  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.143927 \n",
            "\n",
            "[Epoch: 87/100] Loss: 0.096270  [   32/60000]\n",
            "[Epoch: 87/100] Loss: 0.342498  [ 3232/60000]\n",
            "[Epoch: 87/100] Loss: 0.184685  [ 6432/60000]\n",
            "[Epoch: 87/100] Loss: 0.033982  [ 9632/60000]\n",
            "[Epoch: 87/100] Loss: 0.159124  [12832/60000]\n",
            "[Epoch: 87/100] Loss: 0.131418  [16032/60000]\n",
            "[Epoch: 87/100] Loss: 0.195635  [19232/60000]\n",
            "[Epoch: 87/100] Loss: 0.053357  [22432/60000]\n",
            "[Epoch: 87/100] Loss: 0.020531  [25632/60000]\n",
            "[Epoch: 87/100] Loss: 0.104955  [28832/60000]\n",
            "[Epoch: 87/100] Loss: 0.072020  [32032/60000]\n",
            "[Epoch: 87/100] Loss: 0.151083  [35232/60000]\n",
            "[Epoch: 87/100] Loss: 0.174387  [38432/60000]\n",
            "[Epoch: 87/100] Loss: 0.274438  [41632/60000]\n",
            "[Epoch: 87/100] Loss: 0.203707  [44832/60000]\n",
            "[Epoch: 87/100] Loss: 0.084899  [48032/60000]\n",
            "[Epoch: 87/100] Loss: 0.153990  [51232/60000]\n",
            "[Epoch: 87/100] Loss: 0.131653  [54432/60000]\n",
            "[Epoch: 87/100] Loss: 0.079251  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.142841 \n",
            "\n",
            "[Epoch: 88/100] Loss: 0.164248  [   32/60000]\n",
            "[Epoch: 88/100] Loss: 0.122673  [ 3232/60000]\n",
            "[Epoch: 88/100] Loss: 0.162565  [ 6432/60000]\n",
            "[Epoch: 88/100] Loss: 0.059963  [ 9632/60000]\n",
            "[Epoch: 88/100] Loss: 0.058177  [12832/60000]\n",
            "[Epoch: 88/100] Loss: 0.018155  [16032/60000]\n",
            "[Epoch: 88/100] Loss: 0.039624  [19232/60000]\n",
            "[Epoch: 88/100] Loss: 0.070570  [22432/60000]\n",
            "[Epoch: 88/100] Loss: 0.051562  [25632/60000]\n",
            "[Epoch: 88/100] Loss: 0.207543  [28832/60000]\n",
            "[Epoch: 88/100] Loss: 0.107778  [32032/60000]\n",
            "[Epoch: 88/100] Loss: 0.167770  [35232/60000]\n",
            "[Epoch: 88/100] Loss: 0.020507  [38432/60000]\n",
            "[Epoch: 88/100] Loss: 0.142884  [41632/60000]\n",
            "[Epoch: 88/100] Loss: 0.026289  [44832/60000]\n",
            "[Epoch: 88/100] Loss: 0.056519  [48032/60000]\n",
            "[Epoch: 88/100] Loss: 0.315132  [51232/60000]\n",
            "[Epoch: 88/100] Loss: 0.160702  [54432/60000]\n",
            "[Epoch: 88/100] Loss: 0.377077  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.141635 \n",
            "\n",
            "[Epoch: 89/100] Loss: 0.051166  [   32/60000]\n",
            "[Epoch: 89/100] Loss: 0.047594  [ 3232/60000]\n",
            "[Epoch: 89/100] Loss: 0.070633  [ 6432/60000]\n",
            "[Epoch: 89/100] Loss: 0.084894  [ 9632/60000]\n",
            "[Epoch: 89/100] Loss: 0.133407  [12832/60000]\n",
            "[Epoch: 89/100] Loss: 0.432955  [16032/60000]\n",
            "[Epoch: 89/100] Loss: 0.202496  [19232/60000]\n",
            "[Epoch: 89/100] Loss: 0.194321  [22432/60000]\n",
            "[Epoch: 89/100] Loss: 0.135553  [25632/60000]\n",
            "[Epoch: 89/100] Loss: 0.041815  [28832/60000]\n",
            "[Epoch: 89/100] Loss: 0.068082  [32032/60000]\n",
            "[Epoch: 89/100] Loss: 0.282379  [35232/60000]\n",
            "[Epoch: 89/100] Loss: 0.156852  [38432/60000]\n",
            "[Epoch: 89/100] Loss: 0.093254  [41632/60000]\n",
            "[Epoch: 89/100] Loss: 0.053411  [44832/60000]\n",
            "[Epoch: 89/100] Loss: 0.111379  [48032/60000]\n",
            "[Epoch: 89/100] Loss: 0.191589  [51232/60000]\n",
            "[Epoch: 89/100] Loss: 0.060244  [54432/60000]\n",
            "[Epoch: 89/100] Loss: 0.127136  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.140839 \n",
            "\n",
            "[Epoch: 90/100] Loss: 0.061556  [   32/60000]\n",
            "[Epoch: 90/100] Loss: 0.036351  [ 3232/60000]\n",
            "[Epoch: 90/100] Loss: 0.105120  [ 6432/60000]\n",
            "[Epoch: 90/100] Loss: 0.060553  [ 9632/60000]\n",
            "[Epoch: 90/100] Loss: 0.134228  [12832/60000]\n",
            "[Epoch: 90/100] Loss: 0.043727  [16032/60000]\n",
            "[Epoch: 90/100] Loss: 0.122941  [19232/60000]\n",
            "[Epoch: 90/100] Loss: 0.031573  [22432/60000]\n",
            "[Epoch: 90/100] Loss: 0.066815  [25632/60000]\n",
            "[Epoch: 90/100] Loss: 0.312267  [28832/60000]\n",
            "[Epoch: 90/100] Loss: 0.190980  [32032/60000]\n",
            "[Epoch: 90/100] Loss: 0.099950  [35232/60000]\n",
            "[Epoch: 90/100] Loss: 0.029504  [38432/60000]\n",
            "[Epoch: 90/100] Loss: 0.020672  [41632/60000]\n",
            "[Epoch: 90/100] Loss: 0.043080  [44832/60000]\n",
            "[Epoch: 90/100] Loss: 0.214233  [48032/60000]\n",
            "[Epoch: 90/100] Loss: 0.093760  [51232/60000]\n",
            "[Epoch: 90/100] Loss: 0.059160  [54432/60000]\n",
            "[Epoch: 90/100] Loss: 0.149470  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.139331 \n",
            "\n",
            "[Epoch: 91/100] Loss: 0.167227  [   32/60000]\n",
            "[Epoch: 91/100] Loss: 0.049142  [ 3232/60000]\n",
            "[Epoch: 91/100] Loss: 0.124634  [ 6432/60000]\n",
            "[Epoch: 91/100] Loss: 0.029484  [ 9632/60000]\n",
            "[Epoch: 91/100] Loss: 0.077651  [12832/60000]\n",
            "[Epoch: 91/100] Loss: 0.029996  [16032/60000]\n",
            "[Epoch: 91/100] Loss: 0.160140  [19232/60000]\n",
            "[Epoch: 91/100] Loss: 0.228803  [22432/60000]\n",
            "[Epoch: 91/100] Loss: 0.438410  [25632/60000]\n",
            "[Epoch: 91/100] Loss: 0.075833  [28832/60000]\n",
            "[Epoch: 91/100] Loss: 0.094807  [32032/60000]\n",
            "[Epoch: 91/100] Loss: 0.169782  [35232/60000]\n",
            "[Epoch: 91/100] Loss: 0.160591  [38432/60000]\n",
            "[Epoch: 91/100] Loss: 0.046362  [41632/60000]\n",
            "[Epoch: 91/100] Loss: 0.187233  [44832/60000]\n",
            "[Epoch: 91/100] Loss: 0.077333  [48032/60000]\n",
            "[Epoch: 91/100] Loss: 0.033837  [51232/60000]\n",
            "[Epoch: 91/100] Loss: 0.128159  [54432/60000]\n",
            "[Epoch: 91/100] Loss: 0.271313  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.138121 \n",
            "\n",
            "[Epoch: 92/100] Loss: 0.029074  [   32/60000]\n",
            "[Epoch: 92/100] Loss: 0.059230  [ 3232/60000]\n",
            "[Epoch: 92/100] Loss: 0.058706  [ 6432/60000]\n",
            "[Epoch: 92/100] Loss: 0.073220  [ 9632/60000]\n",
            "[Epoch: 92/100] Loss: 0.069393  [12832/60000]\n",
            "[Epoch: 92/100] Loss: 0.090637  [16032/60000]\n",
            "[Epoch: 92/100] Loss: 0.220150  [19232/60000]\n",
            "[Epoch: 92/100] Loss: 0.126780  [22432/60000]\n",
            "[Epoch: 92/100] Loss: 0.226309  [25632/60000]\n",
            "[Epoch: 92/100] Loss: 0.109438  [28832/60000]\n",
            "[Epoch: 92/100] Loss: 0.213178  [32032/60000]\n",
            "[Epoch: 92/100] Loss: 0.184442  [35232/60000]\n",
            "[Epoch: 92/100] Loss: 0.159946  [38432/60000]\n",
            "[Epoch: 92/100] Loss: 0.143683  [41632/60000]\n",
            "[Epoch: 92/100] Loss: 0.172763  [44832/60000]\n",
            "[Epoch: 92/100] Loss: 0.043707  [48032/60000]\n",
            "[Epoch: 92/100] Loss: 0.090681  [51232/60000]\n",
            "[Epoch: 92/100] Loss: 0.103247  [54432/60000]\n",
            "[Epoch: 92/100] Loss: 0.075859  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.137605 \n",
            "\n",
            "[Epoch: 93/100] Loss: 0.160264  [   32/60000]\n",
            "[Epoch: 93/100] Loss: 0.055049  [ 3232/60000]\n",
            "[Epoch: 93/100] Loss: 0.054396  [ 6432/60000]\n",
            "[Epoch: 93/100] Loss: 0.131458  [ 9632/60000]\n",
            "[Epoch: 93/100] Loss: 0.085474  [12832/60000]\n",
            "[Epoch: 93/100] Loss: 0.104739  [16032/60000]\n",
            "[Epoch: 93/100] Loss: 0.198125  [19232/60000]\n",
            "[Epoch: 93/100] Loss: 0.077741  [22432/60000]\n",
            "[Epoch: 93/100] Loss: 0.169453  [25632/60000]\n",
            "[Epoch: 93/100] Loss: 0.096469  [28832/60000]\n",
            "[Epoch: 93/100] Loss: 0.130108  [32032/60000]\n",
            "[Epoch: 93/100] Loss: 0.281424  [35232/60000]\n",
            "[Epoch: 93/100] Loss: 0.025814  [38432/60000]\n",
            "[Epoch: 93/100] Loss: 0.052857  [41632/60000]\n",
            "[Epoch: 93/100] Loss: 0.318075  [44832/60000]\n",
            "[Epoch: 93/100] Loss: 0.068056  [48032/60000]\n",
            "[Epoch: 93/100] Loss: 0.030650  [51232/60000]\n",
            "[Epoch: 93/100] Loss: 0.188335  [54432/60000]\n",
            "[Epoch: 93/100] Loss: 0.097705  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.136231 \n",
            "\n",
            "[Epoch: 94/100] Loss: 0.054564  [   32/60000]\n",
            "[Epoch: 94/100] Loss: 0.129659  [ 3232/60000]\n",
            "[Epoch: 94/100] Loss: 0.119015  [ 6432/60000]\n",
            "[Epoch: 94/100] Loss: 0.021455  [ 9632/60000]\n",
            "[Epoch: 94/100] Loss: 0.063565  [12832/60000]\n",
            "[Epoch: 94/100] Loss: 0.045300  [16032/60000]\n",
            "[Epoch: 94/100] Loss: 0.025470  [19232/60000]\n",
            "[Epoch: 94/100] Loss: 0.116352  [22432/60000]\n",
            "[Epoch: 94/100] Loss: 0.102299  [25632/60000]\n",
            "[Epoch: 94/100] Loss: 0.101734  [28832/60000]\n",
            "[Epoch: 94/100] Loss: 0.224590  [32032/60000]\n",
            "[Epoch: 94/100] Loss: 0.039713  [35232/60000]\n",
            "[Epoch: 94/100] Loss: 0.128659  [38432/60000]\n",
            "[Epoch: 94/100] Loss: 0.210719  [41632/60000]\n",
            "[Epoch: 94/100] Loss: 0.269892  [44832/60000]\n",
            "[Epoch: 94/100] Loss: 0.035115  [48032/60000]\n",
            "[Epoch: 94/100] Loss: 0.081927  [51232/60000]\n",
            "[Epoch: 94/100] Loss: 0.038703  [54432/60000]\n",
            "[Epoch: 94/100] Loss: 0.053697  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.134890 \n",
            "\n",
            "[Epoch: 95/100] Loss: 0.025694  [   32/60000]\n",
            "[Epoch: 95/100] Loss: 0.019281  [ 3232/60000]\n",
            "[Epoch: 95/100] Loss: 0.227402  [ 6432/60000]\n",
            "[Epoch: 95/100] Loss: 0.101242  [ 9632/60000]\n",
            "[Epoch: 95/100] Loss: 0.135131  [12832/60000]\n",
            "[Epoch: 95/100] Loss: 0.061757  [16032/60000]\n",
            "[Epoch: 95/100] Loss: 0.362764  [19232/60000]\n",
            "[Epoch: 95/100] Loss: 0.025213  [22432/60000]\n",
            "[Epoch: 95/100] Loss: 0.068133  [25632/60000]\n",
            "[Epoch: 95/100] Loss: 0.074131  [28832/60000]\n",
            "[Epoch: 95/100] Loss: 0.182867  [32032/60000]\n",
            "[Epoch: 95/100] Loss: 0.034125  [35232/60000]\n",
            "[Epoch: 95/100] Loss: 0.055973  [38432/60000]\n",
            "[Epoch: 95/100] Loss: 0.093417  [41632/60000]\n",
            "[Epoch: 95/100] Loss: 0.079120  [44832/60000]\n",
            "[Epoch: 95/100] Loss: 0.064944  [48032/60000]\n",
            "[Epoch: 95/100] Loss: 0.255385  [51232/60000]\n",
            "[Epoch: 95/100] Loss: 0.140461  [54432/60000]\n",
            "[Epoch: 95/100] Loss: 0.204629  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.134346 \n",
            "\n",
            "[Epoch: 96/100] Loss: 0.091549  [   32/60000]\n",
            "[Epoch: 96/100] Loss: 0.117696  [ 3232/60000]\n",
            "[Epoch: 96/100] Loss: 0.285600  [ 6432/60000]\n",
            "[Epoch: 96/100] Loss: 0.074897  [ 9632/60000]\n",
            "[Epoch: 96/100] Loss: 0.043096  [12832/60000]\n",
            "[Epoch: 96/100] Loss: 0.201098  [16032/60000]\n",
            "[Epoch: 96/100] Loss: 0.120531  [19232/60000]\n",
            "[Epoch: 96/100] Loss: 0.020141  [22432/60000]\n",
            "[Epoch: 96/100] Loss: 0.067298  [25632/60000]\n",
            "[Epoch: 96/100] Loss: 0.030903  [28832/60000]\n",
            "[Epoch: 96/100] Loss: 0.168352  [32032/60000]\n",
            "[Epoch: 96/100] Loss: 0.067110  [35232/60000]\n",
            "[Epoch: 96/100] Loss: 0.119602  [38432/60000]\n",
            "[Epoch: 96/100] Loss: 0.114771  [41632/60000]\n",
            "[Epoch: 96/100] Loss: 0.036225  [44832/60000]\n",
            "[Epoch: 96/100] Loss: 0.124193  [48032/60000]\n",
            "[Epoch: 96/100] Loss: 0.093538  [51232/60000]\n",
            "[Epoch: 96/100] Loss: 0.061041  [54432/60000]\n",
            "[Epoch: 96/100] Loss: 0.274895  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.132968 \n",
            "\n",
            "[Epoch: 97/100] Loss: 0.080933  [   32/60000]\n",
            "[Epoch: 97/100] Loss: 0.123874  [ 3232/60000]\n",
            "[Epoch: 97/100] Loss: 0.200825  [ 6432/60000]\n",
            "[Epoch: 97/100] Loss: 0.106139  [ 9632/60000]\n",
            "[Epoch: 97/100] Loss: 0.048260  [12832/60000]\n",
            "[Epoch: 97/100] Loss: 0.139078  [16032/60000]\n",
            "[Epoch: 97/100] Loss: 0.103402  [19232/60000]\n",
            "[Epoch: 97/100] Loss: 0.084705  [22432/60000]\n",
            "[Epoch: 97/100] Loss: 0.032999  [25632/60000]\n",
            "[Epoch: 97/100] Loss: 0.142564  [28832/60000]\n",
            "[Epoch: 97/100] Loss: 0.044826  [32032/60000]\n",
            "[Epoch: 97/100] Loss: 0.254542  [35232/60000]\n",
            "[Epoch: 97/100] Loss: 0.503819  [38432/60000]\n",
            "[Epoch: 97/100] Loss: 0.177130  [41632/60000]\n",
            "[Epoch: 97/100] Loss: 0.133173  [44832/60000]\n",
            "[Epoch: 97/100] Loss: 0.162691  [48032/60000]\n",
            "[Epoch: 97/100] Loss: 0.084878  [51232/60000]\n",
            "[Epoch: 97/100] Loss: 0.062082  [54432/60000]\n",
            "[Epoch: 97/100] Loss: 0.203341  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.131923 \n",
            "\n",
            "[Epoch: 98/100] Loss: 0.036715  [   32/60000]\n",
            "[Epoch: 98/100] Loss: 0.050541  [ 3232/60000]\n",
            "[Epoch: 98/100] Loss: 0.031694  [ 6432/60000]\n",
            "[Epoch: 98/100] Loss: 0.369858  [ 9632/60000]\n",
            "[Epoch: 98/100] Loss: 0.210139  [12832/60000]\n",
            "[Epoch: 98/100] Loss: 0.043769  [16032/60000]\n",
            "[Epoch: 98/100] Loss: 0.035592  [19232/60000]\n",
            "[Epoch: 98/100] Loss: 0.149026  [22432/60000]\n",
            "[Epoch: 98/100] Loss: 0.124541  [25632/60000]\n",
            "[Epoch: 98/100] Loss: 0.138456  [28832/60000]\n",
            "[Epoch: 98/100] Loss: 0.039954  [32032/60000]\n",
            "[Epoch: 98/100] Loss: 0.051553  [35232/60000]\n",
            "[Epoch: 98/100] Loss: 0.143339  [38432/60000]\n",
            "[Epoch: 98/100] Loss: 0.100791  [41632/60000]\n",
            "[Epoch: 98/100] Loss: 0.032198  [44832/60000]\n",
            "[Epoch: 98/100] Loss: 0.057566  [48032/60000]\n",
            "[Epoch: 98/100] Loss: 0.188335  [51232/60000]\n",
            "[Epoch: 98/100] Loss: 0.099666  [54432/60000]\n",
            "[Epoch: 98/100] Loss: 0.164603  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.130631 \n",
            "\n",
            "[Epoch: 99/100] Loss: 0.027012  [   32/60000]\n",
            "[Epoch: 99/100] Loss: 0.042160  [ 3232/60000]\n",
            "[Epoch: 99/100] Loss: 0.263343  [ 6432/60000]\n",
            "[Epoch: 99/100] Loss: 0.043430  [ 9632/60000]\n",
            "[Epoch: 99/100] Loss: 0.230921  [12832/60000]\n",
            "[Epoch: 99/100] Loss: 0.214138  [16032/60000]\n",
            "[Epoch: 99/100] Loss: 0.025396  [19232/60000]\n",
            "[Epoch: 99/100] Loss: 0.110139  [22432/60000]\n",
            "[Epoch: 99/100] Loss: 0.278514  [25632/60000]\n",
            "[Epoch: 99/100] Loss: 0.150944  [28832/60000]\n",
            "[Epoch: 99/100] Loss: 0.104928  [32032/60000]\n",
            "[Epoch: 99/100] Loss: 0.119796  [35232/60000]\n",
            "[Epoch: 99/100] Loss: 0.071109  [38432/60000]\n",
            "[Epoch: 99/100] Loss: 0.142615  [41632/60000]\n",
            "[Epoch: 99/100] Loss: 0.075220  [44832/60000]\n",
            "[Epoch: 99/100] Loss: 0.061880  [48032/60000]\n",
            "[Epoch: 99/100] Loss: 0.035467  [51232/60000]\n",
            "[Epoch: 99/100] Loss: 0.097257  [54432/60000]\n",
            "[Epoch: 99/100] Loss: 0.037617  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.132002 \n",
            "\n",
            "[Epoch: 100/100] Loss: 0.048532  [   32/60000]\n",
            "[Epoch: 100/100] Loss: 0.278104  [ 3232/60000]\n",
            "[Epoch: 100/100] Loss: 0.387966  [ 6432/60000]\n",
            "[Epoch: 100/100] Loss: 0.285156  [ 9632/60000]\n",
            "[Epoch: 100/100] Loss: 0.118893  [12832/60000]\n",
            "[Epoch: 100/100] Loss: 0.097704  [16032/60000]\n",
            "[Epoch: 100/100] Loss: 0.014191  [19232/60000]\n",
            "[Epoch: 100/100] Loss: 0.204988  [22432/60000]\n",
            "[Epoch: 100/100] Loss: 0.110617  [25632/60000]\n",
            "[Epoch: 100/100] Loss: 0.098864  [28832/60000]\n",
            "[Epoch: 100/100] Loss: 0.051579  [32032/60000]\n",
            "[Epoch: 100/100] Loss: 0.053613  [35232/60000]\n",
            "[Epoch: 100/100] Loss: 0.162489  [38432/60000]\n",
            "[Epoch: 100/100] Loss: 0.063921  [41632/60000]\n",
            "[Epoch: 100/100] Loss: 0.050217  [44832/60000]\n",
            "[Epoch: 100/100] Loss: 0.036892  [48032/60000]\n",
            "[Epoch: 100/100] Loss: 0.058724  [51232/60000]\n",
            "[Epoch: 100/100] Loss: 0.080041  [54432/60000]\n",
            "[Epoch: 100/100] Loss: 0.044393  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.129041 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = nn.DataParallel(Net().to(device))\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "tolerance = 5\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(device)\n",
        "best_train_loss = float(\"inf\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    # training loop\n",
        "    for batch, (X, y) in enumerate(train_data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * BATCH_SIZE + len(X)\n",
        "            print(f\"[Epoch: {epoch+1}/{NUM_EPOCHS}] Loss: {loss:>7f}  [{current:>5d}/{len(train_data_loader.dataset):>5d}]\")\n",
        "\n",
        "\n",
        "    # eval loop\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            logits = model(X)\n",
        "            loss = criterion(logits, y)\n",
        "            test_loss += loss.item()\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    test_loss /= len(test_data_loader)\n",
        "    correct /= len(test_data_loader.dataset)\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if test_loss < best_train_loss:\n",
        "        best_train_loss = test_loss\n",
        "    else:\n",
        "        tolerance -= 1\n",
        "        if tolerance == 0:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdFYzC50KZZE"
      },
      "source": [
        "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzG-pn3CKZZE"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "-vIxT1ItKZZE"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784).to(device))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels).to(device)\n",
        "real_labels = torch.cat(real_labels).to(device)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "L9nEQ4VtKZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e0a3f1-d849-4d9d-aef6-021ef2749068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.96532\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "771UGdQSKZZF"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784).to(device))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels).to(device)\n",
        "real_labels = torch.cat(real_labels).to(device)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "e75zqgxoKZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354a7f0d-9a2b-44b6-ce64-01b7aba6156d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9626\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI10zPNXKZZG"
      },
      "source": [
        "Проверка, что пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "H-ziy_kqKZZG"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU8RegyvKZZG"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ayxM_rn6KZZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "06579c35-c861-4fc8-fe4a-989b0f4db37a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Please, download `hw_mnist_data_dict.npy` and place it in the working directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-4815f13c1a10>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hw_mnist_data_dict.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please, download `hw_mnist_data_dict.npy` and place it in the working directory"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "assert os.path.exists('hw_mnist_data_dict.npy'), 'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "loaded_data_dict = np.load('hw_mnist_data_dict.npy', allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
        "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
        "}\n",
        "\n",
        "with open('submission_dict_mnist_task_1.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict_mnist_task_1.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B3xgIcSKZZG"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuN81tNjKZZH"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}